{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b3a7bf",
   "metadata": {},
   "source": [
    "# PROBLEM 1: Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2e037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d34c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 18846\n",
      "Number of preprocessed documents: 18846\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "\n",
    "# Fetch the complete 20 Newsgroups dataset while removing headers, footers, and quotes\n",
    "newsgroups_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "raw_documents = newsgroups_data.data         # List of raw text documents\n",
    "document_labels = newsgroups_data.target       # Corresponding labels for documents\n",
    "\n",
    "# Print the total number of documents retrieved\n",
    "print(f\"Number of documents: {len(raw_documents)}\")\n",
    "\n",
    "# Define a set of English stop words for filtering tokens\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_document(document):\n",
    "    \"\"\"\n",
    "    Preprocess a single text document by:\n",
    "      - Converting the text to lowercase.\n",
    "      - Tokenizing the text into words.\n",
    "      - Removing tokens that are non-alphabetic.\n",
    "      - Removing common stop words.\n",
    "      \n",
    "    Returns:\n",
    "        A single string where tokens are joined by spaces.\n",
    "    \"\"\"\n",
    "    # Tokenize the lowercased document\n",
    "    tokens = word_tokenize(document.lower())\n",
    "    # Keep only alphabetic tokens (remove numbers, punctuation, etc.)\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words_set]\n",
    "    # Return the processed tokens as a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents in the dataset\n",
    "preprocessed_documents = [preprocess_document(doc) for doc in raw_documents]\n",
    "\n",
    "# Print the number of preprocessed documents (should match the raw count)\n",
    "print(f\"Number of preprocessed documents: {len(preprocessed_documents)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Feature Extraction\n",
    "# -------------------------------\n",
    "\n",
    "# Create a CountVectorizer to convert text documents into a document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "document_term_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
    "# Retrieve the feature names (i.e., the words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# -------------------------------\n",
    "# Topic Modeling Display Function\n",
    "# -------------------------------\n",
    "\n",
    "def display_top_words(topic_model, feature_names, n_top_words):\n",
    "    \"\"\"\n",
    "    Print the top n words for each topic in the topic model.\n",
    "    \n",
    "    Parameters:\n",
    "        topic_model: A fitted topic model (e.g., LDA) with a 'components_' attribute.\n",
    "        feature_names: Array of feature names corresponding to the columns of the document-term matrix.\n",
    "        n_top_words: The number of top words to display per topic.\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(topic_model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        # Identify the indices of the top words for this topic\n",
    "        top_word_indices = topic.argsort()[-n_top_words:][::-1]\n",
    "        # Print each word and its corresponding weight\n",
    "        for idx in top_word_indices:\n",
    "            word = feature_names[idx]\n",
    "            weight = topic[idx]\n",
    "            print(f\"{word}: {weight:.2f}\")\n",
    "        print()  # Newline for better readability between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22dabf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latent Dirichlet Allocation (LDA) with 10 topics\n",
      "Topic #1:\n",
      "god: 2056.11\n",
      "jesus: 1176.80\n",
      "christ: 676.90\n",
      "one: 555.39\n",
      "church: 538.18\n",
      "lord: 516.38\n",
      "sin: 410.32\n",
      "bible: 406.49\n",
      "also: 366.23\n",
      "father: 338.83\n",
      "said: 320.87\n",
      "faith: 314.09\n",
      "man: 304.59\n",
      "john: 303.49\n",
      "spirit: 293.81\n",
      "son: 284.34\n",
      "us: 270.29\n",
      "may: 268.53\n",
      "shall: 262.98\n",
      "holy: 250.27\n",
      "\n",
      "Topic #2:\n",
      "people: 900.55\n",
      "armenian: 839.90\n",
      "israel: 749.32\n",
      "government: 740.28\n",
      "turkish: 658.68\n",
      "war: 633.73\n",
      "armenians: 633.54\n",
      "state: 620.78\n",
      "states: 614.71\n",
      "jews: 613.22\n",
      "gun: 555.22\n",
      "university: 469.74\n",
      "new: 466.34\n",
      "national: 465.42\n",
      "united: 461.91\n",
      "one: 461.78\n",
      "israeli: 457.16\n",
      "said: 436.01\n",
      "world: 409.99\n",
      "american: 399.45\n",
      "\n",
      "Topic #3:\n",
      "would: 1372.58\n",
      "use: 1339.06\n",
      "also: 1299.70\n",
      "information: 1243.69\n",
      "available: 1226.36\n",
      "key: 1221.85\n",
      "space: 1217.70\n",
      "data: 1129.48\n",
      "one: 1057.93\n",
      "system: 1049.26\n",
      "may: 958.74\n",
      "send: 825.21\n",
      "list: 819.82\n",
      "used: 768.41\n",
      "get: 760.79\n",
      "new: 743.05\n",
      "mail: 720.49\n",
      "could: 716.93\n",
      "please: 712.11\n",
      "like: 681.15\n",
      "\n",
      "Topic #4:\n",
      "new: 475.04\n",
      "san: 252.88\n",
      "april: 238.56\n",
      "adl: 201.69\n",
      "art: 188.78\n",
      "earth: 187.51\n",
      "vs: 179.49\n",
      "planet: 171.96\n",
      "appears: 164.59\n",
      "venus: 157.03\n",
      "la: 149.42\n",
      "first: 146.26\n",
      "cover: 146.12\n",
      "francisco: 141.20\n",
      "spacecraft: 140.29\n",
      "moon: 134.54\n",
      "york: 132.77\n",
      "wolverine: 131.10\n",
      "university: 130.72\n",
      "istanbul: 125.44\n",
      "\n",
      "Topic #5:\n",
      "use: 2389.21\n",
      "file: 2114.37\n",
      "windows: 1858.13\n",
      "one: 1758.47\n",
      "would: 1666.25\n",
      "get: 1648.38\n",
      "drive: 1528.18\n",
      "system: 1513.84\n",
      "like: 1435.89\n",
      "know: 1338.94\n",
      "thanks: 1320.25\n",
      "program: 1282.69\n",
      "also: 1270.09\n",
      "using: 1264.40\n",
      "problem: 1208.06\n",
      "card: 1190.46\n",
      "software: 1168.50\n",
      "anyone: 1093.15\n",
      "need: 1069.60\n",
      "please: 1050.59\n",
      "\n",
      "Topic #6:\n",
      "max: 4592.82\n",
      "db: 621.55\n",
      "bhj: 452.10\n",
      "giz: 422.10\n",
      "widget: 304.61\n",
      "wm: 286.10\n",
      "ah: 251.46\n",
      "gk: 235.10\n",
      "bj: 186.10\n",
      "bh: 181.10\n",
      "ax: 160.10\n",
      "mr: 153.72\n",
      "mv: 152.10\n",
      "image: 151.63\n",
      "air: 151.07\n",
      "mov: 142.10\n",
      "ql: 138.10\n",
      "pl: 138.10\n",
      "mk: 137.94\n",
      "qax: 127.10\n",
      "\n",
      "Topic #7:\n",
      "would: 3015.92\n",
      "one: 2451.16\n",
      "get: 2314.62\n",
      "like: 2215.54\n",
      "think: 2098.63\n",
      "know: 1993.58\n",
      "people: 1617.83\n",
      "time: 1577.39\n",
      "good: 1573.70\n",
      "well: 1534.21\n",
      "could: 1478.85\n",
      "going: 1419.80\n",
      "much: 1395.79\n",
      "even: 1263.52\n",
      "car: 1241.38\n",
      "go: 1150.23\n",
      "back: 1128.63\n",
      "make: 1099.08\n",
      "also: 1094.82\n",
      "right: 1040.59\n",
      "\n",
      "Topic #8:\n",
      "would: 3600.93\n",
      "one: 2903.72\n",
      "people: 2902.97\n",
      "think: 1900.71\n",
      "say: 1423.39\n",
      "like: 1412.21\n",
      "believe: 1351.77\n",
      "know: 1307.28\n",
      "god: 1228.66\n",
      "even: 1186.88\n",
      "see: 1162.85\n",
      "many: 1135.74\n",
      "way: 1100.03\n",
      "us: 1040.89\n",
      "right: 978.89\n",
      "could: 958.91\n",
      "point: 952.99\n",
      "time: 945.15\n",
      "may: 899.85\n",
      "well: 874.98\n",
      "\n",
      "Topic #9:\n",
      "us: 590.69\n",
      "one: 487.75\n",
      "said: 445.10\n",
      "people: 335.18\n",
      "went: 292.79\n",
      "know: 291.29\n",
      "came: 257.07\n",
      "could: 243.87\n",
      "go: 243.34\n",
      "gm: 235.77\n",
      "told: 207.77\n",
      "says: 207.02\n",
      "time: 206.13\n",
      "started: 195.23\n",
      "home: 192.99\n",
      "saw: 191.04\n",
      "armenians: 183.65\n",
      "bos: 182.28\n",
      "apartment: 177.81\n",
      "would: 171.21\n",
      "\n",
      "Topic #10:\n",
      "game: 1377.10\n",
      "team: 990.78\n",
      "games: 825.38\n",
      "year: 747.79\n",
      "play: 609.78\n",
      "season: 542.35\n",
      "players: 522.18\n",
      "last: 521.66\n",
      "first: 508.12\n",
      "hockey: 490.40\n",
      "would: 451.33\n",
      "win: 448.66\n",
      "period: 401.87\n",
      "league: 398.63\n",
      "player: 391.91\n",
      "baseball: 360.67\n",
      "one: 337.76\n",
      "teams: 329.86\n",
      "good: 324.48\n",
      "get: 297.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# LDA Topic Modeling\n",
    "# -------------------------------\n",
    "\n",
    "# Define the number of top words to display for each topic and the different topic counts to explore\n",
    "number_of_top_words = 20\n",
    "topic_counts = [10, 20, 50]\n",
    "\n",
    "# Run the LDA topic modeling for different numbers of topics\n",
    "\n",
    "print(f\"\\nLatent Dirichlet Allocation (LDA) with {topic_counts[0]} topics\")\n",
    "lda_model = LatentDirichletAllocation(n_components=topic_counts[0], random_state=0)\n",
    "lda_model.fit(document_term_matrix)\n",
    "display_top_words(lda_model, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cb6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latent Dirichlet Allocation (LDA) with 20 topics\n",
      "Topic #1:\n",
      "station: 96.63\n",
      "said: 88.75\n",
      "april: 86.81\n",
      "space: 85.38\n",
      "could: 71.34\n",
      "turkey: 63.76\n",
      "redesign: 55.79\n",
      "may: 48.91\n",
      "three: 47.85\n",
      "command: 47.84\n",
      "one: 46.44\n",
      "bob: 46.12\n",
      "visual: 45.20\n",
      "option: 44.73\n",
      "also: 43.46\n",
      "status: 41.80\n",
      "university: 41.09\n",
      "following: 40.03\n",
      "options: 39.16\n",
      "article: 36.47\n",
      "\n",
      "Topic #2:\n",
      "armenian: 883.30\n",
      "armenians: 676.88\n",
      "turkish: 658.99\n",
      "people: 630.60\n",
      "jews: 607.67\n",
      "war: 571.04\n",
      "government: 465.04\n",
      "world: 367.19\n",
      "history: 361.14\n",
      "muslim: 343.86\n",
      "russian: 339.33\n",
      "genocide: 338.05\n",
      "muslims: 337.31\n",
      "armenia: 336.99\n",
      "university: 330.93\n",
      "population: 327.48\n",
      "state: 322.89\n",
      "turkey: 320.74\n",
      "turks: 312.05\n",
      "states: 310.95\n",
      "\n",
      "Topic #3:\n",
      "available: 1151.26\n",
      "key: 1112.40\n",
      "information: 1107.56\n",
      "use: 956.60\n",
      "also: 889.25\n",
      "list: 851.88\n",
      "send: 828.13\n",
      "get: 700.49\n",
      "ftp: 694.05\n",
      "system: 691.38\n",
      "mail: 682.64\n",
      "would: 670.07\n",
      "please: 650.71\n",
      "may: 648.31\n",
      "data: 620.17\n",
      "number: 612.80\n",
      "file: 596.93\n",
      "message: 567.17\n",
      "files: 535.83\n",
      "code: 534.98\n",
      "\n",
      "Topic #4:\n",
      "government: 625.77\n",
      "new: 412.64\n",
      "encryption: 384.47\n",
      "chip: 293.22\n",
      "clipper: 280.44\n",
      "administration: 277.13\n",
      "technology: 270.92\n",
      "law: 217.41\n",
      "privacy: 200.84\n",
      "president: 193.91\n",
      "art: 190.69\n",
      "appears: 174.35\n",
      "enforcement: 172.39\n",
      "security: 171.73\n",
      "private: 164.69\n",
      "elohim: 146.05\n",
      "use: 145.49\n",
      "jehovah: 143.09\n",
      "clinton: 137.75\n",
      "dos: 135.93\n",
      "\n",
      "Topic #5:\n",
      "windows: 1798.47\n",
      "use: 1680.53\n",
      "would: 1561.51\n",
      "drive: 1492.64\n",
      "one: 1394.24\n",
      "get: 1375.96\n",
      "thanks: 1324.47\n",
      "like: 1298.97\n",
      "system: 1298.78\n",
      "know: 1257.79\n",
      "card: 1183.59\n",
      "problem: 1142.41\n",
      "anyone: 1065.28\n",
      "using: 1001.50\n",
      "file: 993.53\n",
      "disk: 953.99\n",
      "also: 913.74\n",
      "please: 911.65\n",
      "need: 891.08\n",
      "work: 876.30\n",
      "\n",
      "Topic #6:\n",
      "widget: 296.72\n",
      "ah: 202.82\n",
      "openwindows: 170.53\n",
      "mv: 151.25\n",
      "air: 143.57\n",
      "xt: 126.66\n",
      "ar: 116.04\n",
      "bh: 101.67\n",
      "md: 93.87\n",
      "mk: 91.87\n",
      "xview: 88.35\n",
      "mm: 83.41\n",
      "mj: 73.65\n",
      "null: 72.66\n",
      "ahf: 72.05\n",
      "kh: 71.25\n",
      "shell: 69.26\n",
      "sq: 67.58\n",
      "mu: 66.74\n",
      "vw: 66.28\n",
      "\n",
      "Topic #7:\n",
      "get: 715.89\n",
      "jpeg: 669.00\n",
      "like: 600.48\n",
      "car: 597.08\n",
      "people: 566.29\n",
      "one: 549.15\n",
      "much: 542.60\n",
      "good: 542.01\n",
      "would: 529.64\n",
      "even: 479.11\n",
      "make: 462.95\n",
      "well: 438.88\n",
      "also: 438.36\n",
      "see: 397.36\n",
      "think: 377.19\n",
      "better: 370.22\n",
      "time: 360.92\n",
      "could: 357.07\n",
      "know: 355.17\n",
      "money: 333.31\n",
      "\n",
      "Topic #8:\n",
      "would: 824.11\n",
      "government: 578.69\n",
      "people: 512.59\n",
      "fbi: 505.33\n",
      "one: 433.96\n",
      "fire: 395.49\n",
      "koresh: 376.11\n",
      "police: 347.92\n",
      "like: 310.39\n",
      "batf: 301.50\n",
      "law: 268.46\n",
      "could: 256.63\n",
      "children: 247.34\n",
      "court: 240.24\n",
      "evidence: 238.61\n",
      "compound: 218.31\n",
      "federal: 216.97\n",
      "first: 205.61\n",
      "time: 194.23\n",
      "get: 193.30\n",
      "\n",
      "Topic #9:\n",
      "la: 266.15\n",
      "gm: 239.66\n",
      "bos: 192.97\n",
      "det: 191.28\n",
      "pit: 186.83\n",
      "tor: 177.62\n",
      "van: 169.76\n",
      "nyi: 159.92\n",
      "chi: 159.69\n",
      "que: 154.80\n",
      "vs: 152.29\n",
      "cal: 147.23\n",
      "stl: 140.97\n",
      "mon: 140.73\n",
      "nj: 131.91\n",
      "min: 130.45\n",
      "nyr: 116.96\n",
      "buf: 112.52\n",
      "tb: 110.41\n",
      "gordon: 103.67\n",
      "\n",
      "Topic #10:\n",
      "gun: 694.58\n",
      "file: 264.50\n",
      "guns: 253.04\n",
      "firearms: 239.91\n",
      "control: 227.19\n",
      "crime: 224.29\n",
      "bill: 169.90\n",
      "would: 148.40\n",
      "weapons: 141.01\n",
      "weapon: 135.39\n",
      "firearm: 128.05\n",
      "use: 123.83\n",
      "handgun: 110.00\n",
      "state: 108.26\n",
      "laws: 106.33\n",
      "criminal: 105.64\n",
      "law: 105.51\n",
      "carry: 103.74\n",
      "amendment: 99.39\n",
      "criminals: 98.59\n",
      "\n",
      "Topic #11:\n",
      "insurance: 205.08\n",
      "adl: 202.05\n",
      "san: 197.55\n",
      "ed: 162.81\n",
      "istanbul: 128.04\n",
      "bullock: 124.05\n",
      "francisco: 118.12\n",
      "office: 115.42\n",
      "canada: 109.89\n",
      "april: 105.09\n",
      "new: 102.62\n",
      "gerard: 92.05\n",
      "california: 89.10\n",
      "university: 86.91\n",
      "information: 85.18\n",
      "health: 83.27\n",
      "private: 80.15\n",
      "ankara: 75.23\n",
      "york: 71.84\n",
      "germany: 68.78\n",
      "\n",
      "Topic #12:\n",
      "know: 1533.16\n",
      "think: 1479.70\n",
      "would: 1420.17\n",
      "one: 1361.05\n",
      "said: 1278.06\n",
      "going: 1124.54\n",
      "get: 1043.29\n",
      "people: 1039.90\n",
      "time: 1008.06\n",
      "could: 1003.98\n",
      "like: 964.23\n",
      "go: 934.02\n",
      "us: 859.91\n",
      "back: 850.41\n",
      "well: 838.61\n",
      "got: 793.39\n",
      "something: 731.09\n",
      "say: 691.81\n",
      "president: 679.53\n",
      "went: 659.19\n",
      "\n",
      "Topic #13:\n",
      "god: 2473.56\n",
      "jesus: 1304.75\n",
      "one: 862.45\n",
      "would: 832.97\n",
      "christ: 754.82\n",
      "church: 632.32\n",
      "bible: 608.25\n",
      "israel: 582.40\n",
      "us: 561.00\n",
      "lord: 529.45\n",
      "also: 487.98\n",
      "people: 457.96\n",
      "man: 433.79\n",
      "sin: 427.66\n",
      "know: 426.76\n",
      "good: 411.29\n",
      "faith: 388.46\n",
      "christian: 380.22\n",
      "time: 377.25\n",
      "life: 369.81\n",
      "\n",
      "Topic #14:\n",
      "noise: 48.12\n",
      "aiu: 48.05\n",
      "team: 47.33\n",
      "cd: 42.87\n",
      "schism: 42.38\n",
      "dpy: 41.59\n",
      "salonica: 40.05\n",
      "go: 34.26\n",
      "andrew: 31.05\n",
      "wip: 30.05\n",
      "de: 28.46\n",
      "sega: 27.77\n",
      "blah: 26.67\n",
      "zionism: 26.67\n",
      "april: 26.60\n",
      "games: 26.26\n",
      "fan: 25.76\n",
      "great: 25.73\n",
      "genesis: 24.71\n",
      "ice: 23.27\n",
      "\n",
      "Topic #15:\n",
      "game: 1073.81\n",
      "team: 958.30\n",
      "year: 865.56\n",
      "games: 744.96\n",
      "season: 531.89\n",
      "players: 520.03\n",
      "last: 510.43\n",
      "hockey: 484.40\n",
      "would: 446.48\n",
      "league: 435.52\n",
      "play: 373.22\n",
      "good: 368.66\n",
      "baseball: 359.14\n",
      "player: 353.31\n",
      "one: 327.24\n",
      "first: 325.00\n",
      "teams: 320.04\n",
      "new: 315.57\n",
      "win: 315.16\n",
      "better: 301.18\n",
      "\n",
      "Topic #16:\n",
      "image: 1208.04\n",
      "db: 614.78\n",
      "data: 603.80\n",
      "images: 526.46\n",
      "display: 325.75\n",
      "software: 294.65\n",
      "color: 266.07\n",
      "format: 256.27\n",
      "use: 246.52\n",
      "program: 226.39\n",
      "processing: 222.23\n",
      "also: 214.56\n",
      "graphics: 207.02\n",
      "file: 199.95\n",
      "include: 198.37\n",
      "formats: 183.82\n",
      "used: 179.89\n",
      "package: 170.03\n",
      "bit: 163.22\n",
      "xv: 155.90\n",
      "\n",
      "Topic #17:\n",
      "would: 2776.15\n",
      "one: 2687.65\n",
      "people: 2646.36\n",
      "think: 1872.23\n",
      "say: 1376.12\n",
      "believe: 1183.64\n",
      "even: 1183.20\n",
      "like: 1178.73\n",
      "may: 1143.87\n",
      "know: 1140.38\n",
      "many: 1128.46\n",
      "way: 1108.40\n",
      "see: 1066.05\n",
      "right: 989.55\n",
      "make: 931.04\n",
      "well: 907.00\n",
      "point: 902.24\n",
      "question: 857.19\n",
      "god: 856.78\n",
      "must: 820.69\n",
      "\n",
      "Topic #18:\n",
      "max: 4594.03\n",
      "giz: 422.05\n",
      "bhj: 420.06\n",
      "period: 357.78\n",
      "entry: 321.29\n",
      "output: 291.70\n",
      "game: 271.80\n",
      "file: 264.40\n",
      "pts: 250.93\n",
      "wm: 246.21\n",
      "gk: 224.37\n",
      "play: 202.88\n",
      "goal: 189.10\n",
      "pp: 188.56\n",
      "power: 169.26\n",
      "bj: 169.14\n",
      "shots: 154.72\n",
      "printf: 148.20\n",
      "int: 146.79\n",
      "char: 145.57\n",
      "\n",
      "Topic #19:\n",
      "medical: 482.57\n",
      "health: 388.00\n",
      "disease: 363.39\n",
      "cancer: 318.42\n",
      "patients: 317.99\n",
      "drug: 313.52\n",
      "research: 251.18\n",
      "treatment: 240.95\n",
      "drugs: 226.09\n",
      "aids: 216.41\n",
      "study: 214.67\n",
      "use: 178.30\n",
      "doctor: 177.81\n",
      "medicine: 172.65\n",
      "number: 168.49\n",
      "dod: 164.13\n",
      "patient: 163.32\n",
      "hiv: 160.05\n",
      "information: 158.14\n",
      "diet: 157.54\n",
      "\n",
      "Topic #20:\n",
      "one: 1306.40\n",
      "would: 1282.45\n",
      "space: 940.43\n",
      "like: 820.98\n",
      "new: 737.83\n",
      "also: 711.87\n",
      "get: 702.59\n",
      "time: 634.28\n",
      "power: 628.53\n",
      "much: 595.16\n",
      "good: 587.75\n",
      "used: 550.64\n",
      "car: 548.33\n",
      "two: 490.55\n",
      "bike: 457.86\n",
      "could: 456.71\n",
      "well: 446.93\n",
      "years: 438.45\n",
      "may: 436.51\n",
      "use: 421.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLatent Dirichlet Allocation (LDA) with {topic_counts[1]} topics\")\n",
    "lda_model = LatentDirichletAllocation(n_components=topic_counts[1], random_state=0)\n",
    "lda_model.fit(document_term_matrix)\n",
    "display_top_words(lda_model, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69bb4da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latent Dirichlet Allocation (LDA) with 50 topics\n",
      "Topic #1:\n",
      "ra: 116.56\n",
      "slave: 114.01\n",
      "master: 94.47\n",
      "drive: 90.37\n",
      "jumper: 57.30\n",
      "votes: 41.57\n",
      "vote: 41.47\n",
      "led: 37.03\n",
      "pin: 35.43\n",
      "water: 30.74\n",
      "dreams: 29.86\n",
      "heads: 28.22\n",
      "jumpers: 27.92\n",
      "wright: 26.24\n",
      "single: 25.36\n",
      "conner: 25.18\n",
      "swap: 25.04\n",
      "tom: 24.15\n",
      "type: 23.71\n",
      "set: 21.39\n",
      "\n",
      "Topic #2:\n",
      "turkish: 238.42\n",
      "jews: 238.27\n",
      "muslims: 235.10\n",
      "genocide: 230.45\n",
      "armenian: 223.07\n",
      "muslim: 192.74\n",
      "armenians: 156.71\n",
      "nazi: 154.47\n",
      "nazis: 147.93\n",
      "german: 129.84\n",
      "government: 102.19\n",
      "serdar: 97.36\n",
      "million: 91.64\n",
      "argic: 89.82\n",
      "history: 89.08\n",
      "book: 84.81\n",
      "germany: 80.54\n",
      "apr: 80.28\n",
      "people: 79.34\n",
      "war: 78.05\n",
      "\n",
      "Topic #3:\n",
      "key: 1007.41\n",
      "message: 322.87\n",
      "des: 290.49\n",
      "keys: 265.17\n",
      "one: 226.99\n",
      "number: 208.95\n",
      "chip: 199.95\n",
      "algorithm: 199.63\n",
      "used: 196.18\n",
      "encryption: 186.03\n",
      "use: 178.09\n",
      "could: 178.01\n",
      "would: 163.92\n",
      "pgp: 160.22\n",
      "block: 154.26\n",
      "rsa: 151.57\n",
      "two: 149.66\n",
      "bits: 148.63\n",
      "encrypted: 147.52\n",
      "public: 139.53\n",
      "\n",
      "Topic #4:\n",
      "dos: 143.08\n",
      "oil: 113.14\n",
      "money: 93.86\n",
      "cd: 82.75\n",
      "russia: 80.70\n",
      "official: 66.91\n",
      "like: 66.11\n",
      "funds: 65.72\n",
      "administration: 64.03\n",
      "senior: 63.95\n",
      "get: 59.13\n",
      "music: 51.46\n",
      "think: 50.11\n",
      "water: 44.81\n",
      "important: 44.15\n",
      "time: 40.40\n",
      "good: 39.86\n",
      "make: 37.87\n",
      "mpc: 35.02\n",
      "biker: 34.91\n",
      "\n",
      "Topic #5:\n",
      "card: 985.81\n",
      "drive: 702.22\n",
      "one: 628.43\n",
      "scsi: 533.83\n",
      "monitor: 525.25\n",
      "problem: 523.59\n",
      "video: 511.21\n",
      "get: 495.29\n",
      "would: 472.26\n",
      "use: 464.29\n",
      "bus: 411.40\n",
      "board: 399.69\n",
      "system: 398.74\n",
      "like: 380.04\n",
      "work: 374.28\n",
      "drivers: 361.39\n",
      "know: 357.19\n",
      "modem: 339.56\n",
      "ide: 334.46\n",
      "ram: 331.80\n",
      "\n",
      "Topic #6:\n",
      "ah: 187.48\n",
      "mv: 148.93\n",
      "air: 131.81\n",
      "ar: 116.01\n",
      "md: 80.05\n",
      "mm: 76.91\n",
      "ahf: 71.35\n",
      "hz: 68.17\n",
      "mk: 67.88\n",
      "mj: 67.24\n",
      "kh: 66.67\n",
      "ri: 66.00\n",
      "sq: 64.64\n",
      "qs: 62.00\n",
      "mu: 61.66\n",
      "mc: 59.91\n",
      "mt: 59.27\n",
      "mw: 58.77\n",
      "mp: 58.37\n",
      "mo: 57.31\n",
      "\n",
      "Topic #7:\n",
      "image: 718.62\n",
      "jpeg: 689.66\n",
      "images: 387.18\n",
      "gif: 377.13\n",
      "file: 342.28\n",
      "quality: 291.84\n",
      "color: 273.70\n",
      "format: 270.14\n",
      "use: 236.08\n",
      "version: 216.57\n",
      "also: 212.89\n",
      "see: 197.64\n",
      "files: 180.18\n",
      "cars: 174.79\n",
      "available: 173.05\n",
      "free: 172.15\n",
      "one: 170.60\n",
      "much: 167.29\n",
      "programs: 166.84\n",
      "better: 166.60\n",
      "\n",
      "Topic #8:\n",
      "de: 65.25\n",
      "yassin: 47.02\n",
      "van: 39.38\n",
      "uv: 37.16\n",
      "irgun: 36.02\n",
      "maria: 35.94\n",
      "books: 32.76\n",
      "deir: 32.02\n",
      "atheist: 30.38\n",
      "stan: 28.19\n",
      "het: 26.99\n",
      "village: 26.59\n",
      "one: 26.12\n",
      "revolver: 25.74\n",
      "kt: 25.72\n",
      "many: 21.73\n",
      "boswell: 21.04\n",
      "een: 21.02\n",
      "en: 20.95\n",
      "benefactor: 20.02\n",
      "\n",
      "Topic #9:\n",
      "banks: 114.65\n",
      "gordon: 103.11\n",
      "skepticism: 87.48\n",
      "soon: 85.95\n",
      "intellect: 84.02\n",
      "surrender: 82.01\n",
      "shameful: 78.82\n",
      "geb: 78.02\n",
      "chastity: 77.02\n",
      "drugs: 74.70\n",
      "one: 54.39\n",
      "wsh: 50.02\n",
      "mtl: 48.14\n",
      "women: 47.58\n",
      "service: 42.23\n",
      "time: 38.47\n",
      "ago: 34.38\n",
      "min: 34.02\n",
      "hfd: 34.02\n",
      "cgy: 34.02\n",
      "\n",
      "Topic #10:\n",
      "goal: 190.07\n",
      "puck: 135.31\n",
      "game: 114.48\n",
      "shot: 94.46\n",
      "ripem: 70.17\n",
      "penalty: 69.55\n",
      "kings: 66.71\n",
      "goals: 64.99\n",
      "zone: 64.12\n",
      "net: 63.27\n",
      "flames: 62.69\n",
      "period: 60.30\n",
      "took: 58.19\n",
      "play: 57.53\n",
      "went: 57.28\n",
      "soderstrom: 54.57\n",
      "penalties: 53.68\n",
      "first: 53.32\n",
      "lead: 51.81\n",
      "line: 48.18\n",
      "\n",
      "Topic #11:\n",
      "battery: 224.00\n",
      "batteries: 64.63\n",
      "deleted: 64.62\n",
      "stuff: 44.59\n",
      "would: 42.27\n",
      "one: 41.70\n",
      "discharge: 38.51\n",
      "dirt: 37.12\n",
      "concrete: 36.07\n",
      "current: 34.38\n",
      "lead: 30.64\n",
      "bell: 29.56\n",
      "solution: 28.97\n",
      "know: 26.48\n",
      "company: 26.23\n",
      "charged: 25.97\n",
      "use: 24.77\n",
      "years: 24.03\n",
      "charger: 23.02\n",
      "water: 22.13\n",
      "\n",
      "Topic #12:\n",
      "ball: 81.36\n",
      "one: 76.02\n",
      "pain: 72.55\n",
      "years: 67.34\n",
      "first: 62.97\n",
      "got: 62.28\n",
      "still: 61.38\n",
      "back: 60.74\n",
      "friend: 55.05\n",
      "think: 54.70\n",
      "internet: 52.35\n",
      "ago: 51.77\n",
      "get: 51.56\n",
      "time: 51.51\n",
      "two: 51.25\n",
      "third: 51.06\n",
      "runner: 50.98\n",
      "phone: 49.66\n",
      "fly: 46.27\n",
      "good: 45.43\n",
      "\n",
      "Topic #13:\n",
      "god: 1299.56\n",
      "jesus: 1063.64\n",
      "christ: 559.32\n",
      "lord: 482.72\n",
      "one: 408.79\n",
      "would: 324.43\n",
      "us: 323.74\n",
      "bible: 320.43\n",
      "man: 272.13\n",
      "father: 243.95\n",
      "also: 243.48\n",
      "said: 235.81\n",
      "shall: 231.68\n",
      "heaven: 231.57\n",
      "john: 228.16\n",
      "life: 221.66\n",
      "day: 219.51\n",
      "matthew: 217.90\n",
      "love: 201.05\n",
      "spirit: 190.46\n",
      "\n",
      "Topic #14:\n",
      "doug: 67.22\n",
      "canon: 44.30\n",
      "bob: 42.02\n",
      "schism: 41.23\n",
      "team: 38.85\n",
      "symbol: 38.29\n",
      "andrew: 35.07\n",
      "pope: 33.38\n",
      "go: 24.60\n",
      "archbishop: 23.02\n",
      "ice: 20.07\n",
      "schismatic: 20.02\n",
      "les: 19.62\n",
      "inkjet: 18.91\n",
      "de: 17.11\n",
      "lefebvre: 17.02\n",
      "scott: 16.26\n",
      "needles: 15.99\n",
      "hockey: 15.97\n",
      "great: 15.87\n",
      "\n",
      "Topic #15:\n",
      "hockey: 463.16\n",
      "team: 395.65\n",
      "nhl: 273.01\n",
      "university: 246.89\n",
      "season: 237.16\n",
      "league: 192.46\n",
      "games: 179.43\n",
      "game: 164.61\n",
      "new: 159.12\n",
      "professor: 154.80\n",
      "cup: 151.42\n",
      "division: 149.14\n",
      "teams: 143.55\n",
      "go: 134.72\n",
      "players: 130.41\n",
      "play: 118.58\n",
      "leafs: 118.38\n",
      "canada: 114.44\n",
      "draft: 114.19\n",
      "pens: 106.57\n",
      "\n",
      "Topic #16:\n",
      "mhz: 182.03\n",
      "cpu: 138.41\n",
      "heat: 93.16\n",
      "clock: 88.91\n",
      "gamma: 58.51\n",
      "fpu: 58.43\n",
      "define: 56.49\n",
      "iisi: 55.91\n",
      "sink: 54.47\n",
      "defined: 48.72\n",
      "character: 47.94\n",
      "include: 47.28\n",
      "fan: 46.26\n",
      "correction: 45.12\n",
      "oscillator: 43.95\n",
      "used: 41.48\n",
      "use: 41.00\n",
      "dtr: 35.84\n",
      "midi: 34.93\n",
      "operational: 33.00\n",
      "\n",
      "Topic #17:\n",
      "one: 1865.08\n",
      "would: 1737.33\n",
      "people: 1396.50\n",
      "think: 1310.77\n",
      "like: 977.42\n",
      "say: 974.17\n",
      "know: 846.82\n",
      "see: 807.11\n",
      "way: 764.33\n",
      "many: 680.68\n",
      "question: 679.74\n",
      "point: 648.85\n",
      "really: 625.40\n",
      "good: 605.72\n",
      "something: 603.35\n",
      "even: 594.35\n",
      "believe: 580.38\n",
      "much: 571.92\n",
      "could: 569.87\n",
      "things: 565.95\n",
      "\n",
      "Topic #18:\n",
      "max: 4595.02\n",
      "bhj: 452.02\n",
      "giz: 422.02\n",
      "wm: 270.38\n",
      "gk: 235.02\n",
      "bj: 186.02\n",
      "ax: 155.02\n",
      "ql: 138.02\n",
      "qax: 127.02\n",
      "kn: 120.02\n",
      "lj: 115.89\n",
      "nrhj: 112.02\n",
      "mr: 106.07\n",
      "uy: 96.02\n",
      "km: 94.42\n",
      "biz: 94.02\n",
      "pl: 93.80\n",
      "lg: 84.19\n",
      "qq: 81.02\n",
      "nuy: 78.02\n",
      "\n",
      "Topic #19:\n",
      "good: 114.79\n",
      "excellent: 49.82\n",
      "missing: 35.69\n",
      "kent: 34.67\n",
      "easter: 33.41\n",
      "david: 31.28\n",
      "module: 29.88\n",
      "lines: 29.57\n",
      "cheers: 28.91\n",
      "feustel: 28.01\n",
      "br: 27.90\n",
      "two: 27.17\n",
      "gc: 26.99\n",
      "pin: 26.52\n",
      "sternlight: 25.02\n",
      "poster: 23.38\n",
      "data: 22.96\n",
      "points: 22.01\n",
      "geoffrey: 21.94\n",
      "draw: 21.54\n",
      "\n",
      "Topic #20:\n",
      "earth: 408.28\n",
      "space: 378.42\n",
      "one: 358.98\n",
      "would: 289.10\n",
      "moon: 261.39\n",
      "time: 230.22\n",
      "solar: 227.76\n",
      "orbit: 225.03\n",
      "first: 222.16\n",
      "years: 218.42\n",
      "system: 216.31\n",
      "energy: 215.78\n",
      "new: 212.12\n",
      "surface: 207.95\n",
      "lunar: 193.93\n",
      "planet: 192.94\n",
      "also: 182.48\n",
      "two: 180.36\n",
      "spacecraft: 178.65\n",
      "venus: 172.57\n",
      "\n",
      "Topic #21:\n",
      "people: 583.98\n",
      "would: 467.45\n",
      "one: 337.09\n",
      "like: 286.04\n",
      "think: 284.59\n",
      "sex: 197.66\n",
      "men: 182.17\n",
      "also: 180.66\n",
      "homosexual: 179.48\n",
      "even: 179.01\n",
      "get: 178.02\n",
      "know: 172.24\n",
      "gay: 168.77\n",
      "said: 160.29\n",
      "well: 158.57\n",
      "say: 145.60\n",
      "homosexuals: 144.88\n",
      "many: 144.48\n",
      "see: 137.00\n",
      "may: 135.82\n",
      "\n",
      "Topic #22:\n",
      "greek: 292.43\n",
      "turkish: 231.25\n",
      "turkey: 225.18\n",
      "greece: 184.79\n",
      "istanbul: 183.10\n",
      "greeks: 117.90\n",
      "turks: 110.01\n",
      "ankara: 97.40\n",
      "ed: 78.96\n",
      "university: 77.29\n",
      "new: 73.13\n",
      "cyprus: 67.30\n",
      "york: 62.36\n",
      "london: 59.49\n",
      "history: 58.50\n",
      "ermeni: 56.98\n",
      "empire: 55.00\n",
      "jewish: 54.60\n",
      "osmanli: 54.02\n",
      "ottoman: 52.28\n",
      "\n",
      "Topic #23:\n",
      "drive: 750.03\n",
      "disk: 676.44\n",
      "system: 609.03\n",
      "software: 532.50\n",
      "sale: 486.62\n",
      "price: 478.86\n",
      "hard: 450.61\n",
      "new: 419.62\n",
      "mac: 408.36\n",
      "drives: 353.65\n",
      "offer: 349.85\n",
      "pc: 343.94\n",
      "shipping: 337.68\n",
      "apple: 296.21\n",
      "disks: 264.45\n",
      "one: 262.63\n",
      "condition: 256.40\n",
      "used: 256.26\n",
      "floppy: 250.77\n",
      "asking: 250.74\n",
      "\n",
      "Topic #24:\n",
      "san: 187.00\n",
      "lost: 180.98\n",
      "cubs: 117.80\n",
      "york: 117.41\n",
      "new: 103.82\n",
      "city: 80.94\n",
      "red: 79.20\n",
      "chicago: 76.44\n",
      "west: 75.34\n",
      "blue: 70.56\n",
      "east: 69.97\n",
      "idle: 68.97\n",
      "houston: 68.31\n",
      "sox: 65.47\n",
      "francisco: 64.13\n",
      "phillies: 62.64\n",
      "louis: 54.53\n",
      "philadelphia: 54.35\n",
      "jose: 51.92\n",
      "gb: 51.80\n",
      "\n",
      "Topic #25:\n",
      "government: 940.33\n",
      "would: 732.85\n",
      "encryption: 456.19\n",
      "law: 448.55\n",
      "clipper: 433.34\n",
      "chip: 400.63\n",
      "one: 382.31\n",
      "use: 364.33\n",
      "even: 351.58\n",
      "people: 332.07\n",
      "us: 320.30\n",
      "phone: 300.17\n",
      "may: 296.86\n",
      "get: 281.26\n",
      "court: 274.79\n",
      "security: 267.29\n",
      "could: 255.57\n",
      "new: 247.08\n",
      "privacy: 246.42\n",
      "time: 243.61\n",
      "\n",
      "Topic #26:\n",
      "food: 183.71\n",
      "msg: 174.90\n",
      "like: 140.06\n",
      "think: 114.80\n",
      "ford: 105.40\n",
      "would: 96.67\n",
      "time: 93.31\n",
      "people: 92.95\n",
      "one: 90.06\n",
      "go: 85.44\n",
      "eat: 78.73\n",
      "also: 73.40\n",
      "much: 73.38\n",
      "get: 67.46\n",
      "us: 65.38\n",
      "yeah: 62.48\n",
      "problem: 62.26\n",
      "back: 61.80\n",
      "new: 59.57\n",
      "still: 59.31\n",
      "\n",
      "Topic #27:\n",
      "game: 1089.06\n",
      "year: 899.01\n",
      "would: 783.16\n",
      "last: 638.53\n",
      "good: 571.63\n",
      "games: 566.77\n",
      "think: 550.31\n",
      "team: 544.36\n",
      "one: 542.54\n",
      "like: 477.80\n",
      "get: 457.26\n",
      "well: 440.96\n",
      "time: 432.59\n",
      "better: 403.70\n",
      "players: 382.33\n",
      "first: 378.95\n",
      "could: 372.52\n",
      "baseball: 345.38\n",
      "two: 335.51\n",
      "much: 335.33\n",
      "\n",
      "Topic #28:\n",
      "available: 1057.21\n",
      "data: 857.72\n",
      "information: 816.69\n",
      "ftp: 711.00\n",
      "software: 646.81\n",
      "also: 623.57\n",
      "image: 615.41\n",
      "graphics: 591.85\n",
      "system: 531.14\n",
      "computer: 508.35\n",
      "mail: 499.63\n",
      "anonymous: 479.89\n",
      "send: 479.13\n",
      "version: 471.39\n",
      "internet: 469.84\n",
      "use: 469.63\n",
      "systems: 443.72\n",
      "package: 395.00\n",
      "files: 391.33\n",
      "program: 386.02\n",
      "\n",
      "Topic #29:\n",
      "window: 506.10\n",
      "widget: 395.60\n",
      "use: 357.67\n",
      "get: 324.40\n",
      "motif: 311.80\n",
      "application: 297.28\n",
      "server: 270.18\n",
      "one: 260.55\n",
      "set: 257.03\n",
      "sun: 225.45\n",
      "also: 219.62\n",
      "openwindows: 208.69\n",
      "using: 201.66\n",
      "file: 199.94\n",
      "open: 194.71\n",
      "subject: 191.33\n",
      "display: 171.79\n",
      "work: 170.63\n",
      "look: 166.45\n",
      "xt: 165.00\n",
      "\n",
      "Topic #30:\n",
      "make: 45.51\n",
      "bobby: 40.51\n",
      "rick: 34.41\n",
      "mom: 32.75\n",
      "dk: 29.97\n",
      "one: 26.71\n",
      "know: 25.76\n",
      "mike: 24.89\n",
      "tom: 24.20\n",
      "would: 24.12\n",
      "andy: 22.53\n",
      "oo: 21.04\n",
      "ndw: 20.66\n",
      "pat: 20.11\n",
      "paul: 19.55\n",
      "anything: 19.05\n",
      "stats: 18.56\n",
      "mozumder: 18.02\n",
      "diesels: 17.56\n",
      "say: 16.96\n",
      "\n",
      "Topic #31:\n",
      "period: 306.16\n",
      "pts: 258.11\n",
      "la: 229.62\n",
      "play: 180.80\n",
      "pp: 179.48\n",
      "power: 141.40\n",
      "shots: 127.39\n",
      "pt: 103.23\n",
      "second: 97.03\n",
      "third: 93.31\n",
      "saves: 92.76\n",
      "scorer: 91.02\n",
      "ny: 86.19\n",
      "first: 83.44\n",
      "lemieux: 77.47\n",
      "calgary: 76.67\n",
      "pittsburgh: 75.55\n",
      "new: 67.34\n",
      "murphy: 66.90\n",
      "leads: 62.01\n",
      "\n",
      "Topic #32:\n",
      "would: 1714.16\n",
      "anyone: 1330.31\n",
      "thanks: 1329.24\n",
      "know: 1275.85\n",
      "please: 1174.96\n",
      "like: 1038.42\n",
      "could: 699.52\n",
      "get: 687.49\n",
      "looking: 591.04\n",
      "help: 507.47\n",
      "car: 484.51\n",
      "one: 427.21\n",
      "good: 426.06\n",
      "someone: 420.77\n",
      "info: 407.16\n",
      "interested: 406.15\n",
      "much: 405.59\n",
      "email: 400.06\n",
      "also: 395.82\n",
      "need: 386.13\n",
      "\n",
      "Topic #33:\n",
      "bike: 448.30\n",
      "car: 397.02\n",
      "get: 296.35\n",
      "front: 253.83\n",
      "right: 219.05\n",
      "ride: 195.09\n",
      "road: 178.97\n",
      "dog: 176.15\n",
      "back: 167.51\n",
      "riding: 157.42\n",
      "left: 145.60\n",
      "like: 144.80\n",
      "turn: 126.09\n",
      "driving: 126.00\n",
      "rear: 123.48\n",
      "side: 122.23\n",
      "one: 120.09\n",
      "motorcycle: 103.07\n",
      "well: 100.62\n",
      "behind: 100.05\n",
      "\n",
      "Topic #34:\n",
      "file: 392.28\n",
      "bill: 247.96\n",
      "dod: 145.95\n",
      "states: 123.23\n",
      "national: 112.24\n",
      "united: 99.26\n",
      "house: 97.46\n",
      "gun: 92.95\n",
      "control: 91.26\n",
      "firearms: 85.49\n",
      "washington: 75.39\n",
      "april: 73.33\n",
      "list: 72.77\n",
      "committee: 71.14\n",
      "public: 68.48\n",
      "american: 66.74\n",
      "state: 64.39\n",
      "james: 63.86\n",
      "name: 63.86\n",
      "information: 63.72\n",
      "\n",
      "Topic #35:\n",
      "gm: 292.29\n",
      "vs: 179.93\n",
      "st: 108.67\n",
      "john: 78.77\n",
      "rochester: 74.57\n",
      "weaver: 70.02\n",
      "baltimore: 65.28\n",
      "moncton: 61.67\n",
      "springfield: 58.80\n",
      "trial: 56.81\n",
      "providence: 56.80\n",
      "cape: 54.14\n",
      "utica: 54.01\n",
      "adirondack: 51.02\n",
      "cooper: 49.76\n",
      "binghamton: 48.88\n",
      "breton: 46.02\n",
      "gant: 44.98\n",
      "list: 43.49\n",
      "fredericton: 42.02\n",
      "\n",
      "Topic #36:\n",
      "henrik: 92.02\n",
      "jews: 82.66\n",
      "bm: 73.20\n",
      "would: 59.23\n",
      "one: 58.65\n",
      "said: 57.42\n",
      "turkey: 44.48\n",
      "away: 41.86\n",
      "inches: 40.48\n",
      "armenians: 40.29\n",
      "pom: 38.32\n",
      "sea: 38.25\n",
      "oort: 36.71\n",
      "years: 36.61\n",
      "armenia: 36.31\n",
      "stay: 35.28\n",
      "see: 34.24\n",
      "like: 31.65\n",
      "manhattan: 29.91\n",
      "world: 29.23\n",
      "\n",
      "Topic #37:\n",
      "people: 1593.05\n",
      "said: 1275.71\n",
      "would: 1094.73\n",
      "one: 1023.65\n",
      "president: 920.21\n",
      "us: 901.00\n",
      "know: 896.83\n",
      "think: 829.78\n",
      "going: 757.42\n",
      "could: 709.10\n",
      "time: 615.95\n",
      "go: 585.97\n",
      "well: 567.73\n",
      "say: 546.04\n",
      "government: 482.38\n",
      "like: 475.20\n",
      "went: 455.24\n",
      "stephanopoulos: 450.02\n",
      "children: 444.26\n",
      "get: 433.99\n",
      "\n",
      "Topic #38:\n",
      "israel: 778.63\n",
      "israeli: 459.88\n",
      "file: 328.84\n",
      "arab: 302.27\n",
      "output: 295.98\n",
      "entry: 291.81\n",
      "jews: 228.09\n",
      "jewish: 222.48\n",
      "state: 205.49\n",
      "arabs: 192.28\n",
      "program: 191.17\n",
      "palestinian: 177.29\n",
      "rules: 157.55\n",
      "people: 156.50\n",
      "ed: 155.11\n",
      "section: 153.39\n",
      "may: 151.68\n",
      "right: 150.97\n",
      "must: 148.62\n",
      "one: 143.65\n",
      "\n",
      "Topic #39:\n",
      "file: 844.97\n",
      "files: 639.42\n",
      "program: 637.18\n",
      "problem: 563.13\n",
      "using: 413.91\n",
      "window: 403.39\n",
      "use: 400.75\n",
      "windows: 396.36\n",
      "know: 339.96\n",
      "help: 330.58\n",
      "thanks: 325.88\n",
      "get: 302.42\n",
      "like: 252.92\n",
      "would: 250.83\n",
      "font: 226.13\n",
      "anyone: 220.07\n",
      "printer: 217.88\n",
      "fonts: 214.98\n",
      "print: 192.80\n",
      "directory: 186.37\n",
      "\n",
      "Topic #40:\n",
      "gun: 730.34\n",
      "would: 522.32\n",
      "fbi: 395.56\n",
      "guns: 391.24\n",
      "koresh: 360.92\n",
      "right: 338.79\n",
      "people: 334.51\n",
      "law: 312.56\n",
      "batf: 303.94\n",
      "fire: 293.80\n",
      "weapons: 287.77\n",
      "crime: 272.78\n",
      "control: 256.34\n",
      "one: 237.11\n",
      "government: 221.73\n",
      "rights: 207.53\n",
      "police: 207.07\n",
      "state: 202.92\n",
      "amendment: 197.51\n",
      "laws: 192.00\n",
      "\n",
      "Topic #41:\n",
      "god: 1927.40\n",
      "one: 800.40\n",
      "church: 737.64\n",
      "people: 652.27\n",
      "christian: 641.74\n",
      "believe: 640.78\n",
      "would: 605.67\n",
      "christians: 570.98\n",
      "may: 500.02\n",
      "bible: 467.93\n",
      "religion: 441.42\n",
      "us: 419.55\n",
      "faith: 414.17\n",
      "even: 409.45\n",
      "law: 398.45\n",
      "paul: 381.02\n",
      "think: 380.33\n",
      "say: 380.25\n",
      "many: 340.78\n",
      "religious: 336.37\n",
      "\n",
      "Topic #42:\n",
      "windows: 1217.06\n",
      "dos: 668.13\n",
      "mouse: 264.88\n",
      "ms: 255.08\n",
      "version: 217.03\n",
      "memory: 202.62\n",
      "nt: 201.19\n",
      "network: 200.49\n",
      "run: 195.63\n",
      "use: 190.24\n",
      "microsoft: 183.09\n",
      "system: 167.58\n",
      "running: 164.25\n",
      "software: 158.02\n",
      "driver: 152.94\n",
      "support: 125.43\n",
      "copy: 123.00\n",
      "apps: 103.27\n",
      "unix: 94.81\n",
      "tape: 94.65\n",
      "\n",
      "Topic #43:\n",
      "vitamin: 163.39\n",
      "colour: 64.75\n",
      "planes: 53.94\n",
      "time: 51.07\n",
      "would: 50.67\n",
      "retinol: 49.02\n",
      "extra: 48.00\n",
      "probably: 43.08\n",
      "bit: 42.17\n",
      "acid: 40.91\n",
      "one: 38.07\n",
      "liver: 37.82\n",
      "colours: 36.31\n",
      "per: 32.64\n",
      "stolen: 32.33\n",
      "hits: 31.78\n",
      "average: 30.32\n",
      "like: 29.32\n",
      "pocklington: 28.27\n",
      "much: 27.22\n",
      "\n",
      "Topic #44:\n",
      "medical: 444.13\n",
      "health: 443.49\n",
      "disease: 359.17\n",
      "patients: 311.64\n",
      "cancer: 308.08\n",
      "information: 240.99\n",
      "treatment: 236.04\n",
      "research: 229.89\n",
      "study: 225.55\n",
      "aids: 215.58\n",
      "use: 215.49\n",
      "drug: 211.59\n",
      "adl: 202.02\n",
      "new: 186.48\n",
      "number: 185.55\n",
      "also: 169.11\n",
      "medicine: 168.39\n",
      "years: 164.56\n",
      "may: 164.20\n",
      "hiv: 160.02\n",
      "\n",
      "Topic #45:\n",
      "space: 876.71\n",
      "nasa: 300.72\n",
      "launch: 285.16\n",
      "shuttle: 283.18\n",
      "program: 219.04\n",
      "station: 172.05\n",
      "also: 157.21\n",
      "mission: 138.82\n",
      "year: 119.68\n",
      "flight: 118.28\n",
      "april: 113.80\n",
      "hst: 112.85\n",
      "science: 109.52\n",
      "cost: 107.86\n",
      "one: 107.01\n",
      "use: 106.27\n",
      "us: 97.07\n",
      "center: 94.08\n",
      "technology: 93.14\n",
      "list: 90.67\n",
      "\n",
      "Topic #46:\n",
      "would: 524.10\n",
      "one: 304.27\n",
      "could: 255.88\n",
      "people: 227.30\n",
      "think: 186.45\n",
      "make: 174.03\n",
      "get: 161.68\n",
      "us: 158.55\n",
      "like: 137.89\n",
      "insurance: 125.79\n",
      "know: 122.54\n",
      "even: 117.80\n",
      "since: 107.91\n",
      "much: 103.81\n",
      "good: 102.60\n",
      "canada: 99.80\n",
      "something: 95.78\n",
      "made: 92.47\n",
      "point: 91.15\n",
      "system: 90.22\n",
      "\n",
      "Topic #47:\n",
      "armenian: 445.82\n",
      "armenians: 299.09\n",
      "van: 212.00\n",
      "russian: 186.09\n",
      "det: 185.50\n",
      "bos: 183.98\n",
      "population: 180.30\n",
      "tor: 164.58\n",
      "chi: 154.95\n",
      "buf: 147.63\n",
      "nyi: 145.57\n",
      "que: 145.03\n",
      "turkish: 143.26\n",
      "pit: 134.59\n",
      "nj: 130.89\n",
      "armenia: 130.70\n",
      "cal: 130.10\n",
      "ottoman: 126.91\n",
      "villages: 125.48\n",
      "turks: 113.01\n",
      "\n",
      "Topic #48:\n",
      "son: 149.98\n",
      "radar: 118.12\n",
      "blues: 115.12\n",
      "detector: 84.16\n",
      "father: 69.48\n",
      "hawks: 64.98\n",
      "detectors: 54.08\n",
      "spirit: 52.50\n",
      "joseph: 46.88\n",
      "launch: 46.01\n",
      "rw: 43.50\n",
      "bullets: 38.37\n",
      "creed: 37.23\n",
      "two: 34.34\n",
      "holy: 33.98\n",
      "may: 33.29\n",
      "usa: 31.64\n",
      "orthodox: 28.85\n",
      "hull: 28.72\n",
      "lw: 28.65\n",
      "\n",
      "Topic #49:\n",
      "db: 609.12\n",
      "appears: 197.06\n",
      "art: 171.16\n",
      "new: 169.78\n",
      "mov: 142.02\n",
      "wolverine: 131.02\n",
      "server: 129.51\n",
      "cover: 123.79\n",
      "int: 121.24\n",
      "one: 118.33\n",
      "comics: 117.02\n",
      "hulk: 111.02\n",
      "app: 107.49\n",
      "cs: 106.72\n",
      "xterm: 105.33\n",
      "copies: 103.11\n",
      "byte: 101.07\n",
      "vs: 99.65\n",
      "annual: 96.58\n",
      "resources: 87.40\n",
      "\n",
      "Topic #50:\n",
      "use: 413.78\n",
      "power: 367.31\n",
      "one: 314.36\n",
      "used: 294.47\n",
      "wire: 220.09\n",
      "need: 214.87\n",
      "ground: 213.25\n",
      "circuit: 212.41\n",
      "output: 171.10\n",
      "may: 169.02\n",
      "like: 168.22\n",
      "current: 163.96\n",
      "also: 161.46\n",
      "time: 159.06\n",
      "cable: 156.60\n",
      "line: 150.60\n",
      "radio: 148.54\n",
      "two: 147.77\n",
      "voltage: 147.63\n",
      "signal: 146.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLatent Dirichlet Allocation (LDA) with {topic_counts[2]} topics\")\n",
    "lda_model = LatentDirichletAllocation(n_components=topic_counts[2], random_state=0)\n",
    "lda_model.fit(document_term_matrix)\n",
    "display_top_words(lda_model, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ae7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF with K=10 Topics\n",
      "Topic #1:\n",
      "max: 39.16\n",
      "bhj: 3.12\n",
      "giz: 3.00\n",
      "gk: 1.51\n",
      "bj: 1.31\n",
      "wm: 1.17\n",
      "qax: 1.05\n",
      "kn: 0.92\n",
      "ax: 0.89\n",
      "nrhj: 0.83\n",
      "ql: 0.78\n",
      "lj: 0.76\n",
      "uy: 0.69\n",
      "biz: 0.69\n",
      "mr: 0.66\n",
      "qq: 0.62\n",
      "ghj: 0.61\n",
      "km: 0.58\n",
      "nuy: 0.58\n",
      "lg: 0.55\n",
      "\n",
      "Topic #2:\n",
      "available: 7.17\n",
      "data: 5.82\n",
      "system: 5.79\n",
      "also: 5.60\n",
      "use: 5.04\n",
      "software: 4.97\n",
      "image: 4.65\n",
      "ftp: 4.36\n",
      "version: 4.30\n",
      "server: 4.03\n",
      "graphics: 3.76\n",
      "information: 3.62\n",
      "get: 3.61\n",
      "window: 3.28\n",
      "files: 3.27\n",
      "program: 2.91\n",
      "set: 2.90\n",
      "sun: 2.89\n",
      "display: 2.81\n",
      "windows: 2.74\n",
      "\n",
      "Topic #3:\n",
      "db: 22.38\n",
      "mov: 5.58\n",
      "cs: 3.50\n",
      "bh: 2.97\n",
      "byte: 2.45\n",
      "al: 1.96\n",
      "si: 1.96\n",
      "di: 1.71\n",
      "bl: 1.55\n",
      "bits: 1.51\n",
      "cx: 1.47\n",
      "push: 1.14\n",
      "pop: 1.06\n",
      "one: 1.05\n",
      "inc: 0.98\n",
      "offset: 0.90\n",
      "ptr: 0.77\n",
      "loop: 0.69\n",
      "assembled: 0.69\n",
      "bx: 0.65\n",
      "\n",
      "Topic #4:\n",
      "people: 6.33\n",
      "one: 6.30\n",
      "said: 5.02\n",
      "would: 4.92\n",
      "us: 4.72\n",
      "know: 4.15\n",
      "could: 4.10\n",
      "like: 3.08\n",
      "went: 2.90\n",
      "even: 2.62\n",
      "go: 2.62\n",
      "say: 2.59\n",
      "time: 2.51\n",
      "armenians: 2.45\n",
      "see: 2.31\n",
      "came: 2.30\n",
      "something: 2.25\n",
      "started: 2.21\n",
      "going: 2.13\n",
      "think: 2.08\n",
      "\n",
      "Topic #5:\n",
      "jpeg: 12.95\n",
      "image: 7.30\n",
      "gif: 5.21\n",
      "file: 5.17\n",
      "images: 3.86\n",
      "format: 3.45\n",
      "version: 2.77\n",
      "quality: 2.61\n",
      "files: 2.51\n",
      "free: 2.40\n",
      "color: 2.36\n",
      "see: 2.15\n",
      "programs: 2.10\n",
      "software: 2.03\n",
      "use: 2.01\n",
      "available: 1.99\n",
      "also: 1.82\n",
      "may: 1.76\n",
      "display: 1.71\n",
      "get: 1.69\n",
      "\n",
      "Topic #6:\n",
      "output: 8.00\n",
      "file: 7.72\n",
      "entry: 4.95\n",
      "oname: 4.01\n",
      "program: 4.01\n",
      "printf: 3.84\n",
      "stream: 3.31\n",
      "char: 3.23\n",
      "buf: 2.91\n",
      "fprintf: 2.88\n",
      "contest: 2.23\n",
      "section: 2.16\n",
      "return: 2.13\n",
      "rules: 2.09\n",
      "filename: 2.06\n",
      "uuencode: 2.04\n",
      "int: 2.03\n",
      "line: 1.97\n",
      "name: 1.72\n",
      "build: 1.71\n",
      "\n",
      "Topic #7:\n",
      "god: 9.15\n",
      "jehovah: 8.25\n",
      "lord: 6.68\n",
      "elohim: 6.09\n",
      "christ: 3.96\n",
      "jesus: 3.76\n",
      "father: 3.24\n",
      "mcconkie: 2.80\n",
      "son: 2.44\n",
      "unto: 2.27\n",
      "ps: 2.10\n",
      "shall: 1.93\n",
      "one: 1.87\n",
      "gods: 1.74\n",
      "said: 1.68\n",
      "bible: 1.57\n",
      "thou: 1.52\n",
      "also: 1.36\n",
      "thee: 1.36\n",
      "spirit: 1.35\n",
      "\n",
      "Topic #8:\n",
      "stephanopoulos: 8.84\n",
      "president: 7.72\n",
      "think: 5.62\n",
      "know: 4.41\n",
      "going: 3.93\n",
      "would: 3.48\n",
      "myers: 3.40\n",
      "said: 2.77\n",
      "made: 2.04\n",
      "well: 1.97\n",
      "something: 1.78\n",
      "believe: 1.74\n",
      "package: 1.71\n",
      "say: 1.65\n",
      "general: 1.62\n",
      "people: 1.53\n",
      "get: 1.48\n",
      "george: 1.47\n",
      "mean: 1.42\n",
      "question: 1.40\n",
      "\n",
      "Topic #9:\n",
      "new: 3.72\n",
      "one: 3.61\n",
      "use: 3.10\n",
      "may: 2.95\n",
      "two: 2.35\n",
      "first: 2.26\n",
      "also: 2.21\n",
      "would: 2.15\n",
      "space: 2.14\n",
      "wire: 1.91\n",
      "system: 1.80\n",
      "wiring: 1.70\n",
      "information: 1.68\n",
      "years: 1.64\n",
      "used: 1.63\n",
      "time: 1.48\n",
      "earth: 1.47\n",
      "number: 1.38\n",
      "hockey: 1.38\n",
      "many: 1.36\n",
      "\n",
      "Topic #10:\n",
      "file: 14.14\n",
      "gun: 4.08\n",
      "control: 2.68\n",
      "bill: 2.35\n",
      "states: 2.02\n",
      "firearms: 2.00\n",
      "united: 1.86\n",
      "house: 1.49\n",
      "handgun: 1.35\n",
      "use: 1.25\n",
      "amendment: 1.22\n",
      "directory: 1.20\n",
      "crime: 1.20\n",
      "law: 1.16\n",
      "january: 1.09\n",
      "american: 1.00\n",
      "senate: 0.98\n",
      "amend: 0.95\n",
      "files: 0.95\n",
      "second: 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNMF with K={topic_counts[0]} Topics\")\n",
    "nmf = NMF(n_components=topic_counts[0], random_state=0, init='nndsvd')\n",
    "nmf.fit(document_term_matrix)\n",
    "display_top_words(nmf, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f63a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF with K=20 Topics\n",
      "Topic #1:\n",
      "max: 39.16\n",
      "bhj: 3.12\n",
      "giz: 3.00\n",
      "gk: 1.51\n",
      "bj: 1.31\n",
      "wm: 1.17\n",
      "qax: 1.05\n",
      "kn: 0.92\n",
      "ax: 0.89\n",
      "nrhj: 0.83\n",
      "ql: 0.78\n",
      "lj: 0.76\n",
      "uy: 0.69\n",
      "biz: 0.69\n",
      "mr: 0.66\n",
      "qq: 0.62\n",
      "ghj: 0.61\n",
      "km: 0.58\n",
      "nuy: 0.58\n",
      "lg: 0.55\n",
      "\n",
      "Topic #2:\n",
      "use: 7.80\n",
      "window: 7.57\n",
      "widget: 6.74\n",
      "available: 6.46\n",
      "also: 6.42\n",
      "get: 6.15\n",
      "subject: 5.80\n",
      "openwindows: 5.34\n",
      "server: 4.96\n",
      "set: 4.43\n",
      "sun: 4.43\n",
      "application: 4.21\n",
      "version: 4.16\n",
      "motif: 4.10\n",
      "file: 3.88\n",
      "xt: 3.54\n",
      "using: 3.46\n",
      "look: 3.40\n",
      "information: 3.36\n",
      "may: 3.35\n",
      "\n",
      "Topic #3:\n",
      "db: 22.39\n",
      "mov: 5.58\n",
      "cs: 3.50\n",
      "bh: 2.97\n",
      "byte: 2.45\n",
      "al: 1.96\n",
      "si: 1.96\n",
      "di: 1.71\n",
      "bl: 1.55\n",
      "bits: 1.51\n",
      "cx: 1.47\n",
      "push: 1.14\n",
      "pop: 1.06\n",
      "one: 1.05\n",
      "inc: 0.98\n",
      "offset: 0.90\n",
      "ptr: 0.77\n",
      "loop: 0.69\n",
      "assembled: 0.69\n",
      "bx: 0.65\n",
      "\n",
      "Topic #4:\n",
      "god: 9.27\n",
      "one: 4.72\n",
      "jesus: 4.60\n",
      "would: 4.25\n",
      "people: 3.96\n",
      "many: 2.60\n",
      "believe: 2.43\n",
      "even: 2.19\n",
      "atheists: 1.98\n",
      "good: 1.92\n",
      "say: 1.91\n",
      "see: 1.90\n",
      "may: 1.89\n",
      "also: 1.85\n",
      "bible: 1.84\n",
      "must: 1.79\n",
      "christian: 1.74\n",
      "like: 1.73\n",
      "matthew: 1.69\n",
      "way: 1.68\n",
      "\n",
      "Topic #5:\n",
      "jpeg: 13.17\n",
      "image: 6.77\n",
      "file: 5.46\n",
      "gif: 5.28\n",
      "images: 3.73\n",
      "format: 3.42\n",
      "version: 2.83\n",
      "quality: 2.65\n",
      "files: 2.57\n",
      "free: 2.39\n",
      "color: 2.36\n",
      "see: 2.21\n",
      "programs: 2.16\n",
      "use: 2.14\n",
      "software: 2.01\n",
      "available: 1.98\n",
      "may: 1.83\n",
      "also: 1.82\n",
      "get: 1.77\n",
      "display: 1.69\n",
      "\n",
      "Topic #6:\n",
      "output: 8.61\n",
      "file: 7.92\n",
      "entry: 5.24\n",
      "oname: 4.34\n",
      "program: 4.28\n",
      "printf: 4.15\n",
      "stream: 3.57\n",
      "char: 3.43\n",
      "buf: 3.12\n",
      "fprintf: 3.11\n",
      "contest: 2.40\n",
      "section: 2.29\n",
      "return: 2.24\n",
      "rules: 2.22\n",
      "filename: 2.21\n",
      "uuencode: 2.20\n",
      "int: 2.14\n",
      "line: 2.10\n",
      "build: 1.83\n",
      "stderr: 1.82\n",
      "\n",
      "Topic #7:\n",
      "jehovah: 10.30\n",
      "lord: 7.70\n",
      "elohim: 7.63\n",
      "god: 7.02\n",
      "christ: 4.01\n",
      "father: 3.92\n",
      "mcconkie: 3.47\n",
      "son: 2.79\n",
      "unto: 2.74\n",
      "jesus: 2.67\n",
      "ps: 2.56\n",
      "said: 2.27\n",
      "shall: 2.10\n",
      "gods: 2.08\n",
      "thou: 1.83\n",
      "thee: 1.68\n",
      "mormon: 1.62\n",
      "thy: 1.54\n",
      "name: 1.51\n",
      "earth: 1.49\n",
      "\n",
      "Topic #8:\n",
      "stephanopoulos: 9.82\n",
      "president: 8.17\n",
      "think: 5.86\n",
      "know: 4.84\n",
      "going: 4.27\n",
      "myers: 3.70\n",
      "would: 3.38\n",
      "said: 3.17\n",
      "made: 2.21\n",
      "well: 2.10\n",
      "something: 1.95\n",
      "package: 1.78\n",
      "believe: 1.75\n",
      "general: 1.75\n",
      "say: 1.68\n",
      "george: 1.62\n",
      "get: 1.60\n",
      "mean: 1.53\n",
      "people: 1.52\n",
      "go: 1.43\n",
      "\n",
      "Topic #9:\n",
      "space: 7.94\n",
      "earth: 7.50\n",
      "planet: 7.25\n",
      "venus: 6.09\n",
      "spacecraft: 6.01\n",
      "solar: 5.82\n",
      "system: 5.38\n",
      "surface: 5.34\n",
      "first: 4.64\n",
      "moon: 4.38\n",
      "atmosphere: 3.88\n",
      "mars: 3.67\n",
      "sun: 3.34\n",
      "one: 3.29\n",
      "kilometers: 3.24\n",
      "miles: 3.12\n",
      "jupiter: 2.92\n",
      "years: 2.91\n",
      "orbit: 2.88\n",
      "planets: 2.88\n",
      "\n",
      "Topic #10:\n",
      "file: 14.44\n",
      "gun: 4.24\n",
      "control: 2.73\n",
      "bill: 2.40\n",
      "firearms: 2.08\n",
      "states: 2.05\n",
      "united: 1.90\n",
      "house: 1.56\n",
      "handgun: 1.41\n",
      "amendment: 1.26\n",
      "crime: 1.20\n",
      "directory: 1.15\n",
      "january: 1.12\n",
      "law: 1.09\n",
      "use: 1.04\n",
      "american: 1.04\n",
      "senate: 1.02\n",
      "get: 1.01\n",
      "amend: 0.99\n",
      "second: 0.98\n",
      "\n",
      "Topic #11:\n",
      "image: 9.28\n",
      "data: 7.04\n",
      "available: 5.17\n",
      "ftp: 3.72\n",
      "graphics: 3.65\n",
      "also: 3.51\n",
      "software: 3.48\n",
      "package: 3.19\n",
      "images: 3.15\n",
      "processing: 2.69\n",
      "send: 2.68\n",
      "analysis: 2.34\n",
      "contact: 2.33\n",
      "program: 2.22\n",
      "format: 2.18\n",
      "files: 2.03\n",
      "version: 1.99\n",
      "mail: 1.94\n",
      "system: 1.86\n",
      "etc: 1.85\n",
      "\n",
      "Topic #12:\n",
      "disk: 7.30\n",
      "drive: 6.80\n",
      "drives: 5.50\n",
      "hard: 5.09\n",
      "system: 4.28\n",
      "bios: 4.26\n",
      "rom: 3.89\n",
      "controller: 3.66\n",
      "card: 2.97\n",
      "feature: 2.82\n",
      "floppy: 2.70\n",
      "supports: 2.33\n",
      "interface: 2.17\n",
      "scsi: 1.83\n",
      "heads: 1.78\n",
      "speed: 1.71\n",
      "cylinders: 1.64\n",
      "systems: 1.58\n",
      "jumper: 1.57\n",
      "data: 1.51\n",
      "\n",
      "Topic #13:\n",
      "hockey: 5.55\n",
      "league: 4.33\n",
      "team: 3.92\n",
      "nhl: 3.82\n",
      "new: 3.80\n",
      "season: 3.22\n",
      "games: 2.79\n",
      "draft: 2.20\n",
      "division: 2.18\n",
      "game: 2.16\n",
      "teams: 1.75\n",
      "mon: 1.68\n",
      "la: 1.61\n",
      "list: 1.58\n",
      "conference: 1.56\n",
      "first: 1.55\n",
      "ahl: 1.54\n",
      "play: 1.53\n",
      "defenseman: 1.50\n",
      "two: 1.50\n",
      "\n",
      "Topic #14:\n",
      "internet: 5.53\n",
      "anonymous: 5.46\n",
      "privacy: 4.67\n",
      "information: 3.93\n",
      "email: 3.49\n",
      "use: 3.05\n",
      "system: 3.03\n",
      "mail: 2.97\n",
      "may: 2.84\n",
      "anonymity: 2.82\n",
      "computer: 2.36\n",
      "posting: 2.33\n",
      "users: 2.09\n",
      "electronic: 1.97\n",
      "address: 1.92\n",
      "usenet: 1.87\n",
      "service: 1.83\n",
      "network: 1.76\n",
      "encryption: 1.74\n",
      "access: 1.69\n",
      "\n",
      "Topic #15:\n",
      "wire: 5.51\n",
      "wiring: 4.95\n",
      "use: 3.79\n",
      "one: 3.51\n",
      "ground: 2.84\n",
      "neutral: 2.75\n",
      "subject: 2.41\n",
      "circuit: 2.33\n",
      "cable: 2.25\n",
      "outlets: 2.20\n",
      "nec: 1.94\n",
      "gfci: 1.91\n",
      "used: 1.80\n",
      "usually: 1.79\n",
      "may: 1.78\n",
      "electrical: 1.73\n",
      "power: 1.69\n",
      "need: 1.69\n",
      "hot: 1.66\n",
      "wires: 1.66\n",
      "\n",
      "Topic #16:\n",
      "health: 4.58\n",
      "cancer: 4.02\n",
      "medical: 3.65\n",
      "hiv: 3.08\n",
      "number: 3.02\n",
      "april: 2.76\n",
      "aids: 2.67\n",
      "use: 2.51\n",
      "patients: 2.36\n",
      "disease: 2.36\n",
      "newsletter: 2.34\n",
      "research: 2.28\n",
      "volume: 2.27\n",
      "page: 2.27\n",
      "hicnet: 2.22\n",
      "national: 2.11\n",
      "drug: 1.79\n",
      "among: 1.75\n",
      "information: 1.73\n",
      "center: 1.58\n",
      "\n",
      "Topic #17:\n",
      "one: 7.30\n",
      "people: 7.03\n",
      "said: 6.90\n",
      "us: 5.96\n",
      "know: 5.21\n",
      "could: 5.18\n",
      "would: 5.18\n",
      "went: 4.07\n",
      "like: 3.59\n",
      "go: 3.42\n",
      "armenians: 3.18\n",
      "came: 3.15\n",
      "started: 3.09\n",
      "apartment: 2.97\n",
      "say: 2.94\n",
      "time: 2.92\n",
      "going: 2.91\n",
      "even: 2.83\n",
      "something: 2.77\n",
      "mamma: 2.57\n",
      "\n",
      "Topic #18:\n",
      "dos: 5.03\n",
      "windows: 4.71\n",
      "software: 3.49\n",
      "system: 3.13\n",
      "mouse: 3.04\n",
      "ms: 3.00\n",
      "graphics: 2.86\n",
      "version: 2.64\n",
      "memory: 2.57\n",
      "higher: 2.44\n",
      "network: 2.41\n",
      "support: 2.32\n",
      "mbytes: 2.22\n",
      "card: 2.14\n",
      "cpu: 2.12\n",
      "ethernet: 2.04\n",
      "space: 2.04\n",
      "features: 1.92\n",
      "operating: 1.91\n",
      "disk: 1.88\n",
      "\n",
      "Topic #19:\n",
      "war: 3.92\n",
      "south: 3.63\n",
      "new: 3.36\n",
      "secret: 3.07\n",
      "would: 2.71\n",
      "military: 2.58\n",
      "nuclear: 2.48\n",
      "rockefeller: 2.29\n",
      "island: 2.21\n",
      "government: 2.14\n",
      "georgia: 2.04\n",
      "russia: 1.97\n",
      "time: 1.88\n",
      "administration: 1.88\n",
      "naval: 1.85\n",
      "russian: 1.73\n",
      "states: 1.56\n",
      "plan: 1.55\n",
      "united: 1.54\n",
      "ships: 1.53\n",
      "\n",
      "Topic #20:\n",
      "turkish: 5.95\n",
      "jews: 5.41\n",
      "adl: 4.56\n",
      "armenian: 3.48\n",
      "turkey: 3.29\n",
      "bullock: 2.51\n",
      "jewish: 2.12\n",
      "armenians: 2.08\n",
      "people: 1.95\n",
      "university: 1.94\n",
      "ottoman: 1.88\n",
      "history: 1.87\n",
      "government: 1.76\n",
      "also: 1.69\n",
      "new: 1.63\n",
      "gerard: 1.62\n",
      "istanbul: 1.58\n",
      "russian: 1.56\n",
      "israel: 1.46\n",
      "turks: 1.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNMF with K={topic_counts[1]} Topics\")\n",
    "nmf = NMF(n_components=topic_counts[1], random_state=0, init='nndsvd')\n",
    "nmf.fit(document_term_matrix)\n",
    "display_top_words(nmf, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821d9657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF with K=50 Topics\n",
      "Topic #1:\n",
      "max: 39.48\n",
      "bhj: 2.12\n",
      "giz: 1.60\n",
      "bj: 1.03\n",
      "gk: 1.00\n",
      "qax: 0.90\n",
      "kn: 0.68\n",
      "qq: 0.53\n",
      "nrhj: 0.51\n",
      "km: 0.48\n",
      "lj: 0.45\n",
      "uy: 0.43\n",
      "biz: 0.41\n",
      "ghj: 0.40\n",
      "yd: 0.40\n",
      "ax: 0.40\n",
      "bhjn: 0.38\n",
      "nuy: 0.33\n",
      "tg: 0.31\n",
      "wwiz: 0.28\n",
      "\n",
      "Topic #2:\n",
      "data: 19.83\n",
      "available: 15.71\n",
      "ftp: 13.31\n",
      "contact: 8.06\n",
      "also: 7.44\n",
      "package: 6.90\n",
      "graphics: 6.45\n",
      "sgi: 6.23\n",
      "image: 6.08\n",
      "software: 5.96\n",
      "research: 5.26\n",
      "fax: 5.10\n",
      "grass: 4.90\n",
      "ibm: 4.78\n",
      "systems: 4.76\n",
      "format: 4.75\n",
      "anonymous: 4.72\n",
      "information: 4.71\n",
      "sun: 4.48\n",
      "visualization: 4.37\n",
      "\n",
      "Topic #3:\n",
      "db: 22.40\n",
      "mov: 5.58\n",
      "cs: 3.51\n",
      "bh: 2.94\n",
      "byte: 2.45\n",
      "al: 1.96\n",
      "si: 1.96\n",
      "di: 1.71\n",
      "bl: 1.55\n",
      "bits: 1.51\n",
      "cx: 1.47\n",
      "push: 1.14\n",
      "pop: 1.06\n",
      "one: 1.04\n",
      "inc: 0.98\n",
      "offset: 0.90\n",
      "ptr: 0.77\n",
      "loop: 0.69\n",
      "assembled: 0.69\n",
      "bx: 0.65\n",
      "\n",
      "Topic #4:\n",
      "said: 7.50\n",
      "one: 6.48\n",
      "us: 6.37\n",
      "know: 4.86\n",
      "could: 4.69\n",
      "went: 4.48\n",
      "people: 4.31\n",
      "came: 3.45\n",
      "started: 3.40\n",
      "apartment: 3.38\n",
      "go: 3.38\n",
      "armenians: 2.95\n",
      "mamma: 2.94\n",
      "something: 2.81\n",
      "told: 2.74\n",
      "going: 2.74\n",
      "says: 2.65\n",
      "saw: 2.64\n",
      "say: 2.59\n",
      "like: 2.53\n",
      "\n",
      "Topic #5:\n",
      "jpeg: 12.70\n",
      "image: 6.30\n",
      "file: 5.25\n",
      "gif: 5.09\n",
      "images: 3.54\n",
      "format: 3.31\n",
      "version: 2.71\n",
      "quality: 2.54\n",
      "files: 2.40\n",
      "free: 2.30\n",
      "color: 2.24\n",
      "see: 2.11\n",
      "programs: 2.03\n",
      "use: 1.99\n",
      "available: 1.95\n",
      "software: 1.87\n",
      "also: 1.76\n",
      "may: 1.73\n",
      "get: 1.67\n",
      "display: 1.61\n",
      "\n",
      "Topic #6:\n",
      "output: 9.85\n",
      "file: 8.99\n",
      "oname: 4.97\n",
      "printf: 4.75\n",
      "program: 4.13\n",
      "stream: 4.09\n",
      "char: 3.87\n",
      "entry: 3.73\n",
      "fprintf: 3.57\n",
      "buf: 3.57\n",
      "return: 2.55\n",
      "filename: 2.45\n",
      "uuencode: 2.44\n",
      "contest: 2.35\n",
      "int: 2.35\n",
      "line: 2.24\n",
      "stderr: 2.09\n",
      "write: 2.02\n",
      "section: 1.88\n",
      "name: 1.85\n",
      "\n",
      "Topic #7:\n",
      "jehovah: 10.83\n",
      "elohim: 8.04\n",
      "lord: 7.77\n",
      "god: 6.45\n",
      "father: 4.01\n",
      "christ: 3.85\n",
      "mcconkie: 3.64\n",
      "son: 2.83\n",
      "unto: 2.82\n",
      "ps: 2.63\n",
      "jesus: 2.46\n",
      "said: 2.33\n",
      "gods: 2.18\n",
      "shall: 2.07\n",
      "thou: 1.88\n",
      "one: 1.77\n",
      "thee: 1.76\n",
      "mormon: 1.69\n",
      "thy: 1.59\n",
      "name: 1.54\n",
      "\n",
      "Topic #8:\n",
      "stephanopoulos: 14.40\n",
      "president: 7.47\n",
      "know: 5.25\n",
      "going: 4.22\n",
      "think: 4.21\n",
      "said: 3.52\n",
      "would: 2.30\n",
      "george: 2.19\n",
      "well: 2.09\n",
      "something: 2.06\n",
      "made: 2.03\n",
      "general: 1.81\n",
      "mean: 1.66\n",
      "time: 1.58\n",
      "groups: 1.47\n",
      "believe: 1.46\n",
      "package: 1.44\n",
      "press: 1.36\n",
      "yes: 1.34\n",
      "go: 1.33\n",
      "\n",
      "Topic #9:\n",
      "planet: 10.66\n",
      "earth: 10.43\n",
      "spacecraft: 8.59\n",
      "venus: 8.56\n",
      "solar: 8.17\n",
      "surface: 7.71\n",
      "system: 6.30\n",
      "moon: 6.27\n",
      "atmosphere: 5.62\n",
      "space: 5.42\n",
      "first: 5.37\n",
      "sun: 4.99\n",
      "mars: 4.94\n",
      "kilometers: 4.72\n",
      "miles: 4.50\n",
      "jupiter: 4.24\n",
      "planets: 4.18\n",
      "one: 4.05\n",
      "years: 3.84\n",
      "mariner: 3.67\n",
      "\n",
      "Topic #10:\n",
      "file: 14.11\n",
      "gun: 4.17\n",
      "control: 2.67\n",
      "bill: 2.36\n",
      "firearms: 2.01\n",
      "states: 1.99\n",
      "united: 1.85\n",
      "house: 1.56\n",
      "handgun: 1.39\n",
      "amendment: 1.20\n",
      "crime: 1.18\n",
      "directory: 1.12\n",
      "january: 1.12\n",
      "law: 1.01\n",
      "senate: 1.01\n",
      "american: 1.00\n",
      "amend: 0.98\n",
      "march: 0.96\n",
      "journal: 0.95\n",
      "second: 0.94\n",
      "\n",
      "Topic #11:\n",
      "image: 21.90\n",
      "data: 6.70\n",
      "processing: 6.12\n",
      "images: 5.66\n",
      "analysis: 4.83\n",
      "software: 4.56\n",
      "tools: 3.87\n",
      "tool: 3.20\n",
      "include: 3.07\n",
      "display: 3.01\n",
      "system: 3.00\n",
      "using: 2.42\n",
      "hips: 2.36\n",
      "program: 2.35\n",
      "also: 2.34\n",
      "provides: 2.32\n",
      "version: 2.31\n",
      "set: 2.29\n",
      "user: 2.18\n",
      "color: 2.13\n",
      "\n",
      "Topic #12:\n",
      "disk: 9.32\n",
      "drives: 7.02\n",
      "hard: 6.34\n",
      "bios: 6.03\n",
      "drive: 5.92\n",
      "rom: 5.57\n",
      "controller: 5.09\n",
      "card: 4.37\n",
      "feature: 4.21\n",
      "system: 3.82\n",
      "supports: 3.57\n",
      "floppy: 3.57\n",
      "interface: 2.76\n",
      "must: 2.29\n",
      "systems: 2.25\n",
      "speed: 2.19\n",
      "cylinders: 2.19\n",
      "heads: 2.17\n",
      "formatting: 2.14\n",
      "interleave: 1.95\n",
      "\n",
      "Topic #13:\n",
      "hockey: 6.43\n",
      "league: 4.97\n",
      "nhl: 4.41\n",
      "team: 4.29\n",
      "new: 4.20\n",
      "season: 3.52\n",
      "games: 3.02\n",
      "draft: 2.54\n",
      "division: 2.46\n",
      "teams: 1.96\n",
      "game: 1.90\n",
      "ahl: 1.80\n",
      "conference: 1.77\n",
      "list: 1.74\n",
      "defenseman: 1.72\n",
      "two: 1.69\n",
      "players: 1.65\n",
      "cup: 1.51\n",
      "echl: 1.51\n",
      "canada: 1.45\n",
      "\n",
      "Topic #14:\n",
      "internet: 8.49\n",
      "anonymous: 8.10\n",
      "privacy: 6.64\n",
      "email: 5.19\n",
      "information: 5.01\n",
      "anonymity: 4.42\n",
      "mail: 3.84\n",
      "may: 3.75\n",
      "posting: 3.25\n",
      "use: 3.20\n",
      "system: 3.15\n",
      "users: 3.02\n",
      "computer: 3.00\n",
      "address: 2.78\n",
      "usenet: 2.78\n",
      "network: 2.70\n",
      "electronic: 2.70\n",
      "service: 2.65\n",
      "user: 2.46\n",
      "identity: 2.11\n",
      "\n",
      "Topic #15:\n",
      "wire: 6.87\n",
      "wiring: 6.18\n",
      "use: 4.12\n",
      "one: 3.80\n",
      "ground: 3.52\n",
      "neutral: 3.43\n",
      "subject: 3.09\n",
      "circuit: 2.90\n",
      "cable: 2.77\n",
      "outlets: 2.75\n",
      "nec: 2.40\n",
      "gfci: 2.38\n",
      "usually: 2.18\n",
      "electrical: 2.14\n",
      "wires: 2.06\n",
      "hot: 2.06\n",
      "may: 2.05\n",
      "power: 1.98\n",
      "need: 1.88\n",
      "cec: 1.88\n",
      "\n",
      "Topic #16:\n",
      "cancer: 8.76\n",
      "hiv: 4.72\n",
      "aids: 4.68\n",
      "medical: 4.63\n",
      "patients: 3.70\n",
      "research: 3.20\n",
      "health: 3.03\n",
      "information: 3.00\n",
      "april: 2.97\n",
      "drug: 2.68\n",
      "disease: 2.48\n",
      "page: 2.47\n",
      "number: 2.46\n",
      "newsletter: 2.46\n",
      "hicnet: 2.45\n",
      "volume: 2.42\n",
      "pages: 2.28\n",
      "treatment: 2.27\n",
      "breast: 2.25\n",
      "clinical: 2.20\n",
      "\n",
      "Topic #17:\n",
      "drive: 10.01\n",
      "master: 4.43\n",
      "slave: 4.29\n",
      "jumper: 3.05\n",
      "drives: 2.54\n",
      "pin: 1.94\n",
      "single: 1.91\n",
      "tape: 1.79\n",
      "jumpers: 1.72\n",
      "scsi: 1.72\n",
      "led: 1.67\n",
      "ide: 1.57\n",
      "ut: 1.54\n",
      "mode: 1.46\n",
      "open: 1.41\n",
      "heads: 1.39\n",
      "using: 1.28\n",
      "closed: 1.28\n",
      "model: 1.16\n",
      "settings: 1.13\n",
      "\n",
      "Topic #18:\n",
      "dos: 5.53\n",
      "windows: 5.12\n",
      "mouse: 3.72\n",
      "ms: 3.68\n",
      "software: 3.46\n",
      "graphics: 3.21\n",
      "system: 2.98\n",
      "higher: 2.97\n",
      "network: 2.88\n",
      "mbytes: 2.77\n",
      "version: 2.72\n",
      "memory: 2.51\n",
      "support: 2.46\n",
      "card: 2.44\n",
      "ethernet: 2.30\n",
      "operating: 2.28\n",
      "space: 2.16\n",
      "features: 2.12\n",
      "disk: 2.10\n",
      "price: 2.07\n",
      "\n",
      "Topic #19:\n",
      "war: 9.49\n",
      "south: 8.76\n",
      "secret: 7.49\n",
      "new: 6.04\n",
      "nuclear: 5.83\n",
      "rockefeller: 5.76\n",
      "military: 5.53\n",
      "island: 5.43\n",
      "georgia: 4.87\n",
      "naval: 4.63\n",
      "time: 3.88\n",
      "ships: 3.84\n",
      "plan: 3.65\n",
      "argentina: 3.33\n",
      "british: 3.22\n",
      "world: 3.18\n",
      "would: 3.15\n",
      "navy: 2.97\n",
      "argentine: 2.69\n",
      "falklands: 2.69\n",
      "\n",
      "Topic #20:\n",
      "jews: 16.40\n",
      "turkish: 15.83\n",
      "turkey: 8.12\n",
      "jewish: 4.44\n",
      "nazis: 4.09\n",
      "ottoman: 3.73\n",
      "book: 3.02\n",
      "war: 3.00\n",
      "greek: 2.92\n",
      "history: 2.51\n",
      "government: 2.35\n",
      "also: 2.32\n",
      "eastern: 2.31\n",
      "europe: 2.26\n",
      "many: 2.23\n",
      "german: 1.98\n",
      "world: 1.94\n",
      "istanbul: 1.93\n",
      "turks: 1.91\n",
      "empire: 1.85\n",
      "\n",
      "Topic #21:\n",
      "widget: 12.06\n",
      "application: 8.14\n",
      "resource: 6.30\n",
      "value: 5.81\n",
      "type: 5.54\n",
      "use: 5.35\n",
      "xt: 5.31\n",
      "converter: 5.08\n",
      "set: 4.99\n",
      "visual: 4.93\n",
      "window: 4.63\n",
      "widgets: 4.43\n",
      "file: 4.31\n",
      "string: 4.23\n",
      "data: 3.93\n",
      "display: 3.82\n",
      "one: 3.66\n",
      "intrinsics: 3.55\n",
      "may: 3.43\n",
      "used: 3.18\n",
      "\n",
      "Topic #22:\n",
      "ah: 8.49\n",
      "air: 6.69\n",
      "bh: 4.53\n",
      "ahf: 3.32\n",
      "mk: 2.98\n",
      "bhj: 2.89\n",
      "ao: 2.79\n",
      "kh: 2.59\n",
      "oj: 2.30\n",
      "vm: 2.13\n",
      "rk: 2.09\n",
      "vw: 2.07\n",
      "ur: 1.94\n",
      "jur: 1.92\n",
      "aoj: 1.91\n",
      "khf: 1.87\n",
      "mj: 1.86\n",
      "kjz: 1.78\n",
      "mv: 1.78\n",
      "rmw: 1.70\n",
      "\n",
      "Topic #23:\n",
      "entry: 8.52\n",
      "entries: 4.92\n",
      "rules: 3.22\n",
      "program: 2.97\n",
      "use: 2.88\n",
      "section: 2.81\n",
      "files: 2.62\n",
      "must: 2.52\n",
      "file: 2.22\n",
      "number: 1.94\n",
      "source: 1.94\n",
      "info: 1.84\n",
      "guidelines: 1.67\n",
      "winners: 1.62\n",
      "one: 1.57\n",
      "build: 1.50\n",
      "may: 1.50\n",
      "year: 1.48\n",
      "contest: 1.43\n",
      "email: 1.43\n",
      "\n",
      "Topic #24:\n",
      "ed: 8.43\n",
      "university: 6.48\n",
      "istanbul: 4.48\n",
      "professor: 3.93\n",
      "history: 3.56\n",
      "new: 2.91\n",
      "ankara: 2.52\n",
      "york: 2.18\n",
      "israel: 1.89\n",
      "turkey: 1.83\n",
      "osmanli: 1.81\n",
      "press: 1.66\n",
      "ermeni: 1.64\n",
      "office: 1.43\n",
      "london: 1.32\n",
      "general: 1.28\n",
      "armenian: 1.27\n",
      "california: 1.27\n",
      "foreign: 1.22\n",
      "genocide: 1.04\n",
      "\n",
      "Topic #25:\n",
      "adl: 9.87\n",
      "bullock: 5.44\n",
      "gerard: 3.52\n",
      "information: 2.65\n",
      "francisco: 2.56\n",
      "san: 2.52\n",
      "fbi: 2.34\n",
      "police: 2.31\n",
      "groups: 1.85\n",
      "israel: 1.78\n",
      "says: 1.53\n",
      "office: 1.52\n",
      "files: 1.51\n",
      "group: 1.46\n",
      "american: 1.39\n",
      "law: 1.39\n",
      "israeli: 1.28\n",
      "also: 1.26\n",
      "gurvitz: 1.24\n",
      "spy: 1.22\n",
      "\n",
      "Topic #26:\n",
      "space: 7.97\n",
      "launch: 7.58\n",
      "satellite: 3.89\n",
      "commercial: 2.92\n",
      "market: 2.42\n",
      "satellites: 2.16\n",
      "us: 2.09\n",
      "year: 1.78\n",
      "data: 1.53\n",
      "nasa: 1.43\n",
      "program: 1.41\n",
      "services: 1.36\n",
      "communications: 1.33\n",
      "launches: 1.32\n",
      "technology: 1.27\n",
      "first: 1.27\n",
      "new: 1.23\n",
      "also: 1.21\n",
      "small: 1.15\n",
      "demand: 1.13\n",
      "\n",
      "Topic #27:\n",
      "openwindows: 6.85\n",
      "use: 4.57\n",
      "also: 3.97\n",
      "see: 3.10\n",
      "sun: 3.07\n",
      "xview: 3.03\n",
      "look: 2.88\n",
      "subject: 2.66\n",
      "get: 2.47\n",
      "window: 2.20\n",
      "file: 2.02\n",
      "open: 1.98\n",
      "programs: 1.93\n",
      "olit: 1.71\n",
      "manual: 1.71\n",
      "fonts: 1.69\n",
      "system: 1.67\n",
      "run: 1.62\n",
      "news: 1.39\n",
      "using: 1.39\n",
      "\n",
      "Topic #28:\n",
      "myers: 12.59\n",
      "president: 5.77\n",
      "think: 5.32\n",
      "dee: 2.97\n",
      "said: 2.58\n",
      "going: 2.46\n",
      "know: 2.20\n",
      "options: 2.02\n",
      "made: 1.94\n",
      "would: 1.70\n",
      "decision: 1.69\n",
      "believe: 1.54\n",
      "package: 1.51\n",
      "today: 1.50\n",
      "something: 1.43\n",
      "yesterday: 1.37\n",
      "say: 1.16\n",
      "table: 1.13\n",
      "white: 1.08\n",
      "house: 1.06\n",
      "\n",
      "Topic #29:\n",
      "jesus: 9.92\n",
      "matthew: 5.01\n",
      "one: 3.18\n",
      "see: 2.65\n",
      "said: 2.33\n",
      "prophecy: 2.28\n",
      "david: 1.73\n",
      "isaiah: 1.67\n",
      "psalm: 1.65\n",
      "messiah: 1.52\n",
      "israel: 1.51\n",
      "lord: 1.39\n",
      "prophet: 1.37\n",
      "people: 1.30\n",
      "day: 1.27\n",
      "three: 1.26\n",
      "course: 1.26\n",
      "king: 1.22\n",
      "also: 1.19\n",
      "days: 1.17\n",
      "\n",
      "Topic #30:\n",
      "pts: 9.49\n",
      "la: 8.34\n",
      "pt: 7.26\n",
      "vs: 5.22\n",
      "calgary: 1.37\n",
      "vancouver: 1.03\n",
      "san: 0.89\n",
      "jose: 0.69\n",
      "winnipeg: 0.69\n",
      "edmonton: 0.67\n",
      "ar: 0.63\n",
      "pm: 0.57\n",
      "chicago: 0.52\n",
      "year: 0.48\n",
      "ny: 0.48\n",
      "detroit: 0.44\n",
      "toronto: 0.42\n",
      "gm: 0.41\n",
      "period: 0.41\n",
      "st: 0.41\n",
      "\n",
      "Topic #31:\n",
      "administration: 5.19\n",
      "president: 4.46\n",
      "russia: 4.18\n",
      "senior: 3.82\n",
      "russian: 3.59\n",
      "official: 3.54\n",
      "think: 3.52\n",
      "government: 2.94\n",
      "program: 2.60\n",
      "american: 2.42\n",
      "funds: 2.15\n",
      "support: 1.98\n",
      "money: 1.90\n",
      "food: 1.88\n",
      "important: 1.85\n",
      "also: 1.85\n",
      "package: 1.84\n",
      "going: 1.78\n",
      "would: 1.75\n",
      "states: 1.63\n",
      "\n",
      "Topic #32:\n",
      "key: 6.84\n",
      "encryption: 5.42\n",
      "chip: 3.39\n",
      "des: 2.92\n",
      "law: 2.75\n",
      "keys: 2.58\n",
      "technology: 2.54\n",
      "government: 2.54\n",
      "use: 2.42\n",
      "clipper: 2.31\n",
      "used: 2.24\n",
      "security: 2.24\n",
      "ripem: 2.19\n",
      "enforcement: 2.04\n",
      "privacy: 2.00\n",
      "data: 1.97\n",
      "algorithm: 1.70\n",
      "two: 1.64\n",
      "information: 1.60\n",
      "new: 1.59\n",
      "\n",
      "Topic #33:\n",
      "send: 5.24\n",
      "graphics: 4.74\n",
      "mail: 4.49\n",
      "ray: 4.02\n",
      "also: 3.33\n",
      "objects: 3.04\n",
      "files: 2.88\n",
      "rayshade: 2.53\n",
      "package: 2.52\n",
      "image: 2.51\n",
      "format: 2.47\n",
      "message: 2.45\n",
      "stuff: 2.41\n",
      "available: 2.36\n",
      "file: 2.32\n",
      "ftp: 2.13\n",
      "etc: 2.12\n",
      "amiga: 2.03\n",
      "many: 2.02\n",
      "images: 2.01\n",
      "\n",
      "Topic #34:\n",
      "mac: 5.04\n",
      "os: 4.54\n",
      "ibm: 4.12\n",
      "pc: 3.62\n",
      "use: 2.95\n",
      "hardware: 2.91\n",
      "ram: 2.66\n",
      "one: 2.57\n",
      "color: 2.56\n",
      "dos: 2.34\n",
      "windows: 2.32\n",
      "cpu: 2.27\n",
      "used: 2.26\n",
      "memory: 2.24\n",
      "standard: 2.19\n",
      "scsi: 2.11\n",
      "macs: 2.10\n",
      "week: 2.04\n",
      "bus: 2.01\n",
      "machines: 1.93\n",
      "\n",
      "Topic #35:\n",
      "appears: 8.18\n",
      "art: 6.52\n",
      "wolverine: 4.29\n",
      "new: 3.04\n",
      "ghost: 2.81\n",
      "annual: 2.73\n",
      "sabretooth: 2.70\n",
      "cover: 2.69\n",
      "liefeld: 2.68\n",
      "hobgoblin: 2.60\n",
      "rider: 2.57\n",
      "appear: 2.54\n",
      "hulk: 2.46\n",
      "punisher: 2.46\n",
      "black: 2.11\n",
      "panther: 1.95\n",
      "app: 1.83\n",
      "rob: 1.70\n",
      "comics: 1.68\n",
      "keown: 1.61\n",
      "\n",
      "Topic #36:\n",
      "larson: 5.57\n",
      "theory: 4.51\n",
      "universe: 4.33\n",
      "physical: 2.99\n",
      "space: 2.39\n",
      "star: 1.99\n",
      "unified: 1.94\n",
      "general: 1.89\n",
      "motion: 1.81\n",
      "books: 1.75\n",
      "physicist: 1.72\n",
      "material: 1.68\n",
      "time: 1.65\n",
      "light: 1.58\n",
      "one: 1.55\n",
      "dewey: 1.51\n",
      "speed: 1.49\n",
      "comprehensive: 1.30\n",
      "book: 1.26\n",
      "physicists: 1.23\n",
      "\n",
      "Topic #37:\n",
      "system: 7.90\n",
      "files: 4.66\n",
      "disk: 3.87\n",
      "software: 3.37\n",
      "file: 2.51\n",
      "questions: 2.44\n",
      "get: 2.37\n",
      "stuffit: 2.35\n",
      "mac: 2.31\n",
      "hard: 2.19\n",
      "need: 2.08\n",
      "ftp: 2.06\n",
      "macintosh: 2.06\n",
      "use: 1.76\n",
      "available: 1.73\n",
      "problem: 1.63\n",
      "find: 1.60\n",
      "question: 1.57\n",
      "faq: 1.49\n",
      "apple: 1.48\n",
      "\n",
      "Topic #38:\n",
      "bos: 4.26\n",
      "buf: 3.88\n",
      "det: 3.87\n",
      "van: 3.85\n",
      "tor: 3.83\n",
      "la: 3.80\n",
      "chi: 3.69\n",
      "que: 3.67\n",
      "nyi: 3.64\n",
      "nj: 3.62\n",
      "pit: 3.54\n",
      "stl: 3.47\n",
      "cal: 3.17\n",
      "nyr: 3.15\n",
      "mon: 3.10\n",
      "sj: 2.95\n",
      "tb: 2.89\n",
      "win: 2.86\n",
      "edm: 2.82\n",
      "min: 2.79\n",
      "\n",
      "Topic #39:\n",
      "armenian: 6.82\n",
      "armenians: 4.30\n",
      "azerbaijan: 4.12\n",
      "russian: 3.39\n",
      "armenia: 2.46\n",
      "people: 1.75\n",
      "ar: 1.75\n",
      "may: 1.57\n",
      "baku: 1.51\n",
      "soldiers: 1.45\n",
      "turkish: 1.37\n",
      "turks: 1.34\n",
      "villages: 1.27\n",
      "one: 1.27\n",
      "turan: 1.19\n",
      "genocide: 1.17\n",
      "azeri: 1.14\n",
      "population: 1.11\n",
      "army: 1.09\n",
      "republic: 1.07\n",
      "\n",
      "Topic #40:\n",
      "would: 11.72\n",
      "one: 3.08\n",
      "like: 2.97\n",
      "could: 2.56\n",
      "think: 2.02\n",
      "good: 1.70\n",
      "get: 1.46\n",
      "know: 1.35\n",
      "much: 1.32\n",
      "time: 1.23\n",
      "really: 1.21\n",
      "even: 1.14\n",
      "since: 1.07\n",
      "way: 1.04\n",
      "say: 0.98\n",
      "point: 0.97\n",
      "problem: 0.96\n",
      "better: 0.95\n",
      "anyone: 0.92\n",
      "make: 0.84\n",
      "\n",
      "Topic #41:\n",
      "available: 4.96\n",
      "window: 3.78\n",
      "subject: 3.30\n",
      "server: 3.16\n",
      "version: 3.10\n",
      "information: 2.96\n",
      "motif: 2.77\n",
      "get: 2.68\n",
      "widget: 2.19\n",
      "also: 2.17\n",
      "offers: 1.81\n",
      "export: 1.77\n",
      "program: 1.66\n",
      "sun: 1.65\n",
      "includes: 1.62\n",
      "set: 1.56\n",
      "manager: 1.41\n",
      "source: 1.38\n",
      "use: 1.29\n",
      "several: 1.28\n",
      "\n",
      "Topic #42:\n",
      "people: 10.01\n",
      "work: 2.58\n",
      "think: 2.08\n",
      "right: 1.94\n",
      "want: 1.91\n",
      "jobs: 1.80\n",
      "young: 1.57\n",
      "things: 1.53\n",
      "know: 1.46\n",
      "lot: 1.42\n",
      "going: 1.40\n",
      "well: 1.36\n",
      "make: 1.29\n",
      "country: 1.26\n",
      "say: 1.26\n",
      "good: 1.23\n",
      "government: 1.16\n",
      "president: 1.14\n",
      "many: 1.12\n",
      "get: 1.11\n",
      "\n",
      "Topic #43:\n",
      "health: 5.00\n",
      "use: 4.35\n",
      "among: 2.99\n",
      "number: 2.62\n",
      "tobacco: 2.40\n",
      "states: 2.11\n",
      "medical: 2.11\n",
      "reported: 2.06\n",
      "april: 2.03\n",
      "cdc: 1.85\n",
      "national: 1.85\n",
      "children: 1.82\n",
      "years: 1.80\n",
      "newsletter: 1.79\n",
      "age: 1.75\n",
      "disease: 1.75\n",
      "smokeless: 1.68\n",
      "volume: 1.68\n",
      "page: 1.65\n",
      "public: 1.63\n",
      "\n",
      "Topic #44:\n",
      "god: 10.99\n",
      "christ: 2.49\n",
      "us: 1.92\n",
      "love: 1.53\n",
      "jesus: 1.42\n",
      "psalms: 1.32\n",
      "lord: 1.31\n",
      "man: 1.27\n",
      "bible: 1.21\n",
      "church: 1.13\n",
      "sin: 0.90\n",
      "life: 0.87\n",
      "prayers: 0.81\n",
      "faith: 0.79\n",
      "ra: 0.78\n",
      "people: 0.75\n",
      "shall: 0.72\n",
      "kingdom: 0.70\n",
      "hell: 0.68\n",
      "also: 0.67\n",
      "\n",
      "Topic #45:\n",
      "kuwait: 10.11\n",
      "first: 3.09\n",
      "sheikh: 2.52\n",
      "iraq: 1.77\n",
      "british: 1.68\n",
      "kuwaiti: 1.60\n",
      "ottoman: 1.13\n",
      "sabah: 1.09\n",
      "history: 1.03\n",
      "arabia: 0.91\n",
      "oil: 0.90\n",
      "gulf: 0.90\n",
      "abdulla: 0.84\n",
      "government: 0.69\n",
      "pelly: 0.67\n",
      "basra: 0.67\n",
      "time: 0.67\n",
      "following: 0.64\n",
      "arab: 0.63\n",
      "relations: 0.62\n",
      "\n",
      "Topic #46:\n",
      "one: 4.15\n",
      "atheists: 4.11\n",
      "argument: 3.03\n",
      "many: 2.98\n",
      "believe: 2.68\n",
      "true: 2.63\n",
      "atheism: 2.60\n",
      "religious: 2.35\n",
      "may: 2.34\n",
      "god: 2.29\n",
      "example: 2.29\n",
      "religion: 2.10\n",
      "must: 1.97\n",
      "fallacy: 1.89\n",
      "something: 1.83\n",
      "evidence: 1.78\n",
      "even: 1.75\n",
      "belief: 1.72\n",
      "conclusion: 1.53\n",
      "christian: 1.52\n",
      "\n",
      "Topic #47:\n",
      "giz: 6.89\n",
      "wm: 6.58\n",
      "bhj: 4.50\n",
      "ql: 3.40\n",
      "gk: 2.57\n",
      "ax: 2.30\n",
      "fij: 2.26\n",
      "pl: 2.23\n",
      "mr: 1.76\n",
      "rlk: 1.72\n",
      "sl: 1.69\n",
      "fyn: 1.62\n",
      "nrhj: 1.57\n",
      "st: 1.51\n",
      "lj: 1.49\n",
      "biz: 1.37\n",
      "bj: 1.36\n",
      "mq: 1.29\n",
      "uy: 1.29\n",
      "lg: 1.27\n",
      "\n",
      "Topic #48:\n",
      "period: 3.98\n",
      "play: 3.25\n",
      "power: 3.03\n",
      "game: 2.97\n",
      "flyers: 2.63\n",
      "pp: 2.10\n",
      "puck: 2.04\n",
      "first: 2.00\n",
      "second: 1.87\n",
      "got: 1.72\n",
      "goal: 1.53\n",
      "right: 1.37\n",
      "third: 1.25\n",
      "get: 1.22\n",
      "scorer: 1.16\n",
      "shots: 1.12\n",
      "shot: 1.10\n",
      "recchi: 1.04\n",
      "scoring: 1.02\n",
      "kings: 1.02\n",
      "\n",
      "Topic #49:\n",
      "section: 3.52\n",
      "firearm: 2.91\n",
      "military: 2.59\n",
      "weapon: 2.59\n",
      "shall: 2.30\n",
      "license: 2.23\n",
      "dangerous: 1.88\n",
      "person: 1.74\n",
      "ordnance: 1.68\n",
      "division: 1.55\n",
      "state: 1.54\n",
      "application: 1.38\n",
      "means: 1.36\n",
      "use: 1.27\n",
      "law: 1.26\n",
      "following: 1.25\n",
      "device: 1.20\n",
      "applicant: 1.19\n",
      "issued: 1.14\n",
      "act: 1.06\n",
      "\n",
      "Topic #50:\n",
      "dod: 6.17\n",
      "like: 1.73\n",
      "one: 1.69\n",
      "denizens: 1.60\n",
      "motorcycle: 1.59\n",
      "list: 1.41\n",
      "well: 1.39\n",
      "doom: 1.34\n",
      "good: 1.27\n",
      "terrible: 1.22\n",
      "kotl: 1.14\n",
      "muck: 1.14\n",
      "get: 1.10\n",
      "time: 1.09\n",
      "ride: 1.07\n",
      "club: 1.06\n",
      "bmw: 1.04\n",
      "know: 0.98\n",
      "name: 0.94\n",
      "number: 0.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNMF with K={topic_counts[2]} Topics\")\n",
    "nmf = NMF(n_components=topic_counts[2], random_state=0, init='nndsvd')\n",
    "nmf.fit(document_term_matrix)\n",
    "display_top_words(nmf, feature_names, number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ad5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_directory = 'DUC2001/'\n",
    "\n",
    "def extract_text_from_document(file_path):\n",
    "    \"\"\"\n",
    "    Reads an HTML document from the given file path and extracts the textual content\n",
    "    contained within <text> tags.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The file path to the HTML document.\n",
    "        \n",
    "    Returns:\n",
    "        str: A single string with all text extracted from <text> tags.\n",
    "    \"\"\"\n",
    "    # Open the file with UTF-8 encoding and read its content\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Locate all <text> tags in the document\n",
    "    text_tags = soup.find_all('text')\n",
    "    \n",
    "    # Extract text from each <text> tag and join them into one string\n",
    "    extracted_text = ' '.join([tag.get_text() for tag in text_tags])\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# List to hold the extracted text from each document\n",
    "document_texts = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file_name in os.listdir(documents_directory):\n",
    "    file_path = os.path.join(documents_directory, file_name)\n",
    "    # Check if the path is a file (skip directories)\n",
    "    if os.path.isfile(file_path):\n",
    "        # Extract text using the helper function\n",
    "        text = extract_text_from_document(file_path)\n",
    "        document_texts.append(text)\n",
    "\n",
    "# Preprocess each document using the preprocess_text function (assumed to be defined elsewhere)\n",
    "preprocessed_documents = [preprocess_document(text) for text in document_texts]\n",
    "\n",
    "# Initialize a CountVectorizer to convert text documents into a term frequency matrix\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the CountVectorizer to the preprocessed documents and transform them into a matrix\n",
    "term_frequency_matrix = count_vectorizer.fit_transform(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737edaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA with K=10 Topics for DUC 2001\n",
      "Topic #1:\n",
      "said: 315.58\n",
      "mr: 170.05\n",
      "slovenia: 162.10\n",
      "bank: 145.43\n",
      "shining: 122.98\n",
      "world: 114.08\n",
      "path: 112.81\n",
      "president: 109.74\n",
      "new: 99.28\n",
      "would: 94.30\n",
      "year: 92.50\n",
      "government: 92.23\n",
      "last: 91.88\n",
      "also: 89.24\n",
      "nafta: 89.10\n",
      "people: 88.13\n",
      "yugoslavia: 81.96\n",
      "says: 80.70\n",
      "one: 74.63\n",
      "countries: 72.40\n",
      "\n",
      "Topic #2:\n",
      "us: 27.18\n",
      "french: 24.19\n",
      "drought: 23.87\n",
      "caribbean: 21.08\n",
      "said: 20.19\n",
      "france: 19.52\n",
      "year: 17.74\n",
      "farmers: 17.58\n",
      "farm: 16.30\n",
      "would: 13.75\n",
      "prices: 13.71\n",
      "could: 13.23\n",
      "region: 12.95\n",
      "house: 11.95\n",
      "says: 11.91\n",
      "lebanon: 11.10\n",
      "land: 10.84\n",
      "president: 10.60\n",
      "basin: 9.10\n",
      "exports: 9.10\n",
      "\n",
      "Topic #3:\n",
      "fire: 314.40\n",
      "said: 308.93\n",
      "eclipse: 146.10\n",
      "forest: 137.93\n",
      "fires: 126.69\n",
      "national: 105.00\n",
      "firefighters: 95.67\n",
      "acres: 87.96\n",
      "people: 80.36\n",
      "area: 75.53\n",
      "service: 71.27\n",
      "one: 70.56\n",
      "officials: 70.45\n",
      "sun: 68.56\n",
      "tornado: 68.10\n",
      "jackson: 67.93\n",
      "park: 61.18\n",
      "california: 59.26\n",
      "police: 56.36\n",
      "department: 53.91\n",
      "\n",
      "Topic #4:\n",
      "said: 280.20\n",
      "police: 198.91\n",
      "tunnel: 93.73\n",
      "time: 79.07\n",
      "taylor: 77.10\n",
      "right: 76.66\n",
      "first: 75.90\n",
      "officers: 72.97\n",
      "world: 71.51\n",
      "second: 65.45\n",
      "would: 64.62\n",
      "two: 61.44\n",
      "third: 58.87\n",
      "one: 56.90\n",
      "new: 55.02\n",
      "race: 52.65\n",
      "also: 50.20\n",
      "last: 49.51\n",
      "gun: 48.58\n",
      "city: 48.13\n",
      "\n",
      "Topic #5:\n",
      "thomas: 180.58\n",
      "would: 143.11\n",
      "term: 122.70\n",
      "state: 96.52\n",
      "limits: 93.96\n",
      "court: 90.41\n",
      "people: 81.07\n",
      "years: 74.03\n",
      "congress: 69.75\n",
      "new: 56.53\n",
      "said: 50.20\n",
      "one: 49.75\n",
      "says: 48.34\n",
      "year: 47.82\n",
      "rights: 47.22\n",
      "black: 46.12\n",
      "political: 45.88\n",
      "party: 43.63\n",
      "supreme: 43.59\n",
      "government: 43.49\n",
      "\n",
      "Topic #6:\n",
      "said: 439.72\n",
      "oil: 214.97\n",
      "exxon: 185.10\n",
      "diamond: 138.10\n",
      "johnson: 137.77\n",
      "would: 127.81\n",
      "de: 118.93\n",
      "valdez: 112.10\n",
      "spill: 112.10\n",
      "beers: 111.10\n",
      "diamonds: 97.10\n",
      "million: 92.78\n",
      "census: 90.10\n",
      "one: 88.04\n",
      "people: 86.73\n",
      "could: 82.59\n",
      "illegal: 81.91\n",
      "year: 73.06\n",
      "says: 69.41\n",
      "state: 69.08\n",
      "\n",
      "Topic #7:\n",
      "disease: 118.92\n",
      "said: 102.59\n",
      "bse: 56.10\n",
      "tuberculosis: 56.09\n",
      "cattle: 52.16\n",
      "cases: 51.17\n",
      "says: 42.16\n",
      "cjd: 37.10\n",
      "sheep: 37.10\n",
      "year: 35.83\n",
      "scientists: 35.71\n",
      "british: 34.93\n",
      "would: 33.44\n",
      "one: 32.88\n",
      "police: 32.24\n",
      "health: 31.88\n",
      "government: 30.55\n",
      "cow: 30.10\n",
      "beef: 28.03\n",
      "new: 26.40\n",
      "\n",
      "Topic #8:\n",
      "said: 258.38\n",
      "hurricane: 215.47\n",
      "drought: 103.45\n",
      "diabetes: 95.19\n",
      "nra: 92.10\n",
      "year: 90.82\n",
      "people: 89.36\n",
      "percent: 77.84\n",
      "would: 72.09\n",
      "hurricanes: 70.70\n",
      "one: 70.31\n",
      "last: 70.27\n",
      "storm: 66.83\n",
      "florida: 61.35\n",
      "tb: 60.63\n",
      "police: 59.22\n",
      "center: 57.94\n",
      "new: 54.48\n",
      "department: 54.02\n",
      "storms: 53.94\n",
      "\n",
      "Topic #9:\n",
      "welfare: 127.75\n",
      "reform: 46.16\n",
      "earthquake: 37.16\n",
      "president: 29.34\n",
      "would: 26.57\n",
      "benefits: 20.23\n",
      "governors: 20.08\n",
      "mr: 19.14\n",
      "marathon: 19.00\n",
      "year: 18.96\n",
      "programs: 18.46\n",
      "clinton: 18.36\n",
      "recipients: 17.10\n",
      "said: 16.35\n",
      "public: 16.26\n",
      "work: 15.98\n",
      "prediction: 15.50\n",
      "japan: 15.21\n",
      "region: 15.11\n",
      "bill: 14.91\n",
      "\n",
      "Topic #10:\n",
      "said: 237.85\n",
      "crash: 127.10\n",
      "air: 107.36\n",
      "plane: 105.51\n",
      "aircraft: 66.87\n",
      "crashed: 58.08\n",
      "one: 56.86\n",
      "two: 51.97\n",
      "force: 50.14\n",
      "flight: 49.59\n",
      "jet: 47.98\n",
      "engine: 44.92\n",
      "pilot: 42.02\n",
      "base: 38.40\n",
      "people: 36.16\n",
      "spokesman: 35.15\n",
      "reported: 33.37\n",
      "accident: 33.19\n",
      "military: 33.17\n",
      "wednesday: 31.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_top_words = 20\n",
    "topic_counts = [10, 20, 50]\n",
    "\n",
    "print(f\"\\nLDA with K={topic_counts[0]} Topics for DUC 2001\")\n",
    "lda_duc = LatentDirichletAllocation(n_components=topic_counts[0], random_state=0)\n",
    "lda_duc.fit(term_frequency_matrix)\n",
    "display_top_words(lda_duc, count_vectorizer.get_feature_names_out(), number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dbdffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA with K=20 Topics for DUC 2001\n",
      "Topic #1:\n",
      "said: 260.31\n",
      "johnson: 167.85\n",
      "bank: 136.38\n",
      "world: 114.54\n",
      "mr: 113.20\n",
      "would: 77.85\n",
      "new: 71.20\n",
      "says: 70.82\n",
      "countries: 70.59\n",
      "president: 65.60\n",
      "government: 64.59\n",
      "year: 63.61\n",
      "last: 61.80\n",
      "people: 56.44\n",
      "lewis: 54.94\n",
      "also: 54.67\n",
      "debt: 53.91\n",
      "ben: 47.54\n",
      "two: 46.11\n",
      "disease: 45.98\n",
      "\n",
      "Topic #2:\n",
      "us: 23.56\n",
      "caribbean: 20.95\n",
      "french: 16.82\n",
      "said: 14.53\n",
      "region: 11.85\n",
      "lebanon: 11.05\n",
      "terrorist: 9.72\n",
      "basin: 9.05\n",
      "france: 8.97\n",
      "johnson: 8.16\n",
      "washington: 7.93\n",
      "attack: 7.78\n",
      "mexico: 7.09\n",
      "uta: 7.05\n",
      "parity: 7.05\n",
      "bomb: 7.05\n",
      "nafta: 6.92\n",
      "explosion: 6.80\n",
      "canada: 6.64\n",
      "wednesday: 6.41\n",
      "\n",
      "Topic #3:\n",
      "said: 86.98\n",
      "eclipse: 41.74\n",
      "fire: 40.30\n",
      "jackson: 33.24\n",
      "people: 33.21\n",
      "police: 31.20\n",
      "area: 25.19\n",
      "one: 20.58\n",
      "disease: 19.47\n",
      "cjd: 19.05\n",
      "tuesday: 18.23\n",
      "national: 18.09\n",
      "long: 17.98\n",
      "saturday: 17.72\n",
      "acres: 17.62\n",
      "says: 17.44\n",
      "spokesman: 17.10\n",
      "beach: 17.07\n",
      "coca: 17.05\n",
      "officials: 17.04\n",
      "\n",
      "Topic #4:\n",
      "said: 102.29\n",
      "nra: 92.05\n",
      "gun: 87.79\n",
      "right: 70.82\n",
      "police: 62.53\n",
      "would: 53.95\n",
      "arms: 49.87\n",
      "amendment: 48.24\n",
      "second: 45.78\n",
      "guns: 44.03\n",
      "bill: 42.80\n",
      "one: 36.35\n",
      "militia: 36.25\n",
      "people: 35.54\n",
      "first: 33.23\n",
      "bear: 31.89\n",
      "state: 30.96\n",
      "control: 30.43\n",
      "weapons: 30.27\n",
      "rights: 29.23\n",
      "\n",
      "Topic #5:\n",
      "term: 115.89\n",
      "would: 110.34\n",
      "limits: 91.45\n",
      "state: 72.47\n",
      "people: 56.53\n",
      "years: 51.94\n",
      "park: 47.61\n",
      "fire: 46.58\n",
      "one: 41.35\n",
      "yellowstone: 39.27\n",
      "welfare: 32.92\n",
      "year: 31.78\n",
      "says: 31.28\n",
      "court: 31.19\n",
      "forest: 30.60\n",
      "congress: 29.78\n",
      "could: 29.48\n",
      "new: 27.41\n",
      "also: 26.33\n",
      "per: 24.88\n",
      "\n",
      "Topic #6:\n",
      "diamond: 137.05\n",
      "said: 126.41\n",
      "de: 119.95\n",
      "beers: 111.05\n",
      "diamonds: 97.05\n",
      "census: 90.05\n",
      "would: 77.23\n",
      "illegal: 76.97\n",
      "people: 66.29\n",
      "aliens: 66.05\n",
      "year: 58.06\n",
      "house: 57.22\n",
      "states: 56.73\n",
      "one: 50.49\n",
      "market: 50.15\n",
      "says: 48.98\n",
      "million: 48.68\n",
      "south: 47.47\n",
      "cso: 42.05\n",
      "seats: 40.05\n",
      "\n",
      "Topic #7:\n",
      "police: 59.62\n",
      "said: 40.25\n",
      "department: 26.06\n",
      "air: 19.24\n",
      "officer: 18.10\n",
      "smith: 17.05\n",
      "ventilation: 17.05\n",
      "building: 17.05\n",
      "disease: 15.94\n",
      "civil: 15.78\n",
      "brutality: 15.73\n",
      "officers: 15.53\n",
      "black: 15.36\n",
      "say: 15.31\n",
      "government: 13.76\n",
      "state: 13.54\n",
      "may: 13.05\n",
      "poor: 12.91\n",
      "case: 12.86\n",
      "people: 12.55\n",
      "\n",
      "Topic #8:\n",
      "said: 146.19\n",
      "diabetes: 96.05\n",
      "tuberculosis: 84.31\n",
      "police: 68.57\n",
      "people: 65.33\n",
      "tb: 61.05\n",
      "percent: 45.62\n",
      "gates: 44.79\n",
      "disease: 44.76\n",
      "new: 44.48\n",
      "would: 41.91\n",
      "one: 41.90\n",
      "aids: 41.69\n",
      "cases: 40.17\n",
      "may: 39.84\n",
      "year: 39.61\n",
      "health: 38.21\n",
      "years: 35.12\n",
      "mr: 35.05\n",
      "path: 33.89\n",
      "\n",
      "Topic #9:\n",
      "earthquake: 83.04\n",
      "said: 31.03\n",
      "quake: 25.05\n",
      "area: 24.32\n",
      "earthquakes: 24.05\n",
      "damage: 21.83\n",
      "magnitude: 19.01\n",
      "scale: 18.60\n",
      "richter: 17.05\n",
      "president: 16.82\n",
      "welfare: 15.95\n",
      "chile: 14.05\n",
      "year: 14.01\n",
      "prediction: 13.92\n",
      "san: 13.91\n",
      "japan: 13.86\n",
      "along: 12.49\n",
      "california: 12.08\n",
      "marathon: 12.05\n",
      "tokai: 12.05\n",
      "\n",
      "Topic #10:\n",
      "said: 162.87\n",
      "crash: 125.57\n",
      "plane: 108.69\n",
      "air: 94.06\n",
      "aircraft: 64.87\n",
      "crashed: 56.45\n",
      "flight: 51.97\n",
      "force: 49.06\n",
      "jet: 46.30\n",
      "one: 41.46\n",
      "pilot: 40.87\n",
      "base: 38.94\n",
      "two: 37.40\n",
      "spokesman: 33.05\n",
      "accident: 31.08\n",
      "military: 30.30\n",
      "united: 29.95\n",
      "miles: 28.74\n",
      "crew: 26.96\n",
      "training: 24.33\n",
      "\n",
      "Topic #11:\n",
      "oil: 213.00\n",
      "said: 208.72\n",
      "exxon: 185.05\n",
      "valdez: 112.05\n",
      "spill: 112.05\n",
      "coast: 59.37\n",
      "tanker: 57.05\n",
      "cleanup: 56.05\n",
      "alaska: 52.98\n",
      "guard: 47.97\n",
      "sound: 46.59\n",
      "miles: 44.60\n",
      "ship: 44.05\n",
      "million: 43.86\n",
      "would: 37.14\n",
      "could: 34.86\n",
      "officials: 32.63\n",
      "state: 31.22\n",
      "also: 30.27\n",
      "william: 29.92\n",
      "\n",
      "Topic #12:\n",
      "slovenia: 161.83\n",
      "yugoslavia: 81.74\n",
      "slovene: 44.05\n",
      "federal: 40.16\n",
      "croatia: 37.54\n",
      "slovenian: 35.05\n",
      "republic: 34.86\n",
      "yugoslav: 34.05\n",
      "serbia: 31.05\n",
      "republics: 27.03\n",
      "independence: 26.17\n",
      "said: 25.77\n",
      "state: 22.49\n",
      "foreign: 21.05\n",
      "relations: 17.72\n",
      "kucan: 17.05\n",
      "ljubljana: 17.05\n",
      "new: 15.07\n",
      "belgrade: 15.05\n",
      "also: 14.49\n",
      "\n",
      "Topic #13:\n",
      "world: 62.92\n",
      "third: 53.70\n",
      "bank: 35.58\n",
      "says: 35.09\n",
      "exposure: 32.05\n",
      "boston: 31.06\n",
      "million: 30.11\n",
      "disease: 29.04\n",
      "british: 28.61\n",
      "one: 28.58\n",
      "group: 27.84\n",
      "common: 27.84\n",
      "new: 27.35\n",
      "said: 26.67\n",
      "beef: 25.56\n",
      "year: 24.52\n",
      "sun: 24.42\n",
      "total: 23.70\n",
      "banks: 23.18\n",
      "loans: 22.49\n",
      "\n",
      "Topic #14:\n",
      "welfare: 105.66\n",
      "says: 36.94\n",
      "reform: 36.24\n",
      "jackson: 32.05\n",
      "dickey: 26.05\n",
      "work: 20.93\n",
      "one: 20.02\n",
      "benefits: 18.66\n",
      "new: 18.52\n",
      "police: 17.05\n",
      "hatch: 17.04\n",
      "recipients: 17.01\n",
      "system: 15.51\n",
      "said: 15.29\n",
      "children: 14.96\n",
      "bill: 14.49\n",
      "development: 14.21\n",
      "mr: 13.72\n",
      "percent: 13.57\n",
      "would: 13.32\n",
      "\n",
      "Topic #15:\n",
      "marathon: 92.92\n",
      "eclipse: 83.34\n",
      "race: 79.96\n",
      "said: 60.24\n",
      "miles: 46.12\n",
      "sun: 37.52\n",
      "time: 36.74\n",
      "first: 34.31\n",
      "runners: 28.05\n",
      "women: 27.60\n",
      "run: 27.46\n",
      "boston: 26.45\n",
      "city: 26.09\n",
      "finished: 25.22\n",
      "party: 25.05\n",
      "gandhi: 25.05\n",
      "last: 23.02\n",
      "year: 21.98\n",
      "new: 21.96\n",
      "second: 20.06\n",
      "\n",
      "Topic #16:\n",
      "thomas: 15.87\n",
      "fujita: 15.05\n",
      "said: 14.58\n",
      "plo: 14.05\n",
      "seniority: 14.05\n",
      "american: 12.74\n",
      "voters: 11.55\n",
      "congress: 11.54\n",
      "would: 11.35\n",
      "incumbents: 11.14\n",
      "states: 11.12\n",
      "house: 11.08\n",
      "right: 10.60\n",
      "goldwin: 9.75\n",
      "people: 9.72\n",
      "tornadoes: 9.63\n",
      "government: 9.59\n",
      "one: 9.01\n",
      "may: 8.96\n",
      "system: 8.87\n",
      "\n",
      "Topic #17:\n",
      "hurricane: 210.23\n",
      "said: 105.89\n",
      "storm: 62.53\n",
      "thomas: 58.89\n",
      "hurricanes: 54.50\n",
      "florida: 54.32\n",
      "winds: 46.61\n",
      "mph: 46.27\n",
      "sheets: 43.95\n",
      "storms: 39.69\n",
      "center: 38.65\n",
      "tropical: 35.25\n",
      "dollars: 30.96\n",
      "atlantic: 30.59\n",
      "damage: 30.20\n",
      "gilbert: 30.03\n",
      "hugo: 29.18\n",
      "court: 27.31\n",
      "andrew: 26.96\n",
      "coast: 26.55\n",
      "\n",
      "Topic #18:\n",
      "said: 135.79\n",
      "drought: 118.64\n",
      "year: 87.47\n",
      "farmers: 64.30\n",
      "tornado: 63.75\n",
      "one: 56.80\n",
      "path: 55.12\n",
      "people: 52.14\n",
      "billion: 48.39\n",
      "nafta: 48.27\n",
      "last: 46.00\n",
      "shining: 45.81\n",
      "mr: 45.32\n",
      "state: 41.18\n",
      "would: 41.18\n",
      "north: 40.58\n",
      "tornadoes: 40.27\n",
      "states: 39.71\n",
      "president: 39.63\n",
      "weather: 38.90\n",
      "\n",
      "Topic #19:\n",
      "said: 299.63\n",
      "fire: 222.67\n",
      "forest: 101.78\n",
      "national: 95.94\n",
      "fires: 94.96\n",
      "firefighters: 87.15\n",
      "taylor: 75.05\n",
      "acres: 69.61\n",
      "service: 56.52\n",
      "officials: 56.28\n",
      "engine: 44.05\n",
      "california: 40.58\n",
      "hospital: 38.11\n",
      "year: 37.26\n",
      "department: 37.02\n",
      "last: 36.41\n",
      "health: 36.41\n",
      "pneumonia: 36.05\n",
      "season: 35.86\n",
      "park: 35.09\n",
      "\n",
      "Topic #20:\n",
      "said: 161.75\n",
      "tunnel: 95.05\n",
      "police: 94.14\n",
      "thomas: 83.01\n",
      "french: 48.21\n",
      "officers: 45.05\n",
      "british: 44.50\n",
      "two: 41.75\n",
      "department: 38.27\n",
      "one: 37.12\n",
      "city: 36.93\n",
      "years: 35.89\n",
      "black: 34.32\n",
      "time: 33.98\n",
      "law: 33.25\n",
      "people: 33.16\n",
      "would: 33.13\n",
      "link: 30.36\n",
      "rail: 30.05\n",
      "say: 27.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLDA with K={topic_counts[1]} Topics for DUC 2001\")\n",
    "lda_duc = LatentDirichletAllocation(n_components=topic_counts[1], random_state=0)\n",
    "lda_duc.fit(term_frequency_matrix)\n",
    "display_top_words(lda_duc, count_vectorizer.get_feature_names_out(), number_of_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e862830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA with K=50 Topics for DUC 2001\n",
      "Topic #1:\n",
      "said: 98.33\n",
      "president: 40.32\n",
      "military: 34.70\n",
      "government: 33.81\n",
      "two: 27.29\n",
      "mr: 25.99\n",
      "people: 24.23\n",
      "baker: 22.56\n",
      "party: 22.50\n",
      "federal: 21.74\n",
      "house: 21.46\n",
      "pizarro: 21.02\n",
      "police: 20.05\n",
      "may: 20.00\n",
      "forces: 19.56\n",
      "officials: 18.72\n",
      "morote: 18.02\n",
      "presidential: 17.45\n",
      "political: 17.42\n",
      "country: 17.37\n",
      "\n",
      "Topic #2:\n",
      "french: 20.00\n",
      "france: 11.98\n",
      "lebanon: 11.02\n",
      "terrorist: 7.98\n",
      "attack: 7.96\n",
      "uta: 7.02\n",
      "washington: 6.65\n",
      "officials: 5.80\n",
      "wednesday: 5.57\n",
      "hoffman: 5.02\n",
      "intelligence: 5.01\n",
      "explosion: 4.91\n",
      "plane: 4.53\n",
      "forces: 4.48\n",
      "airport: 4.40\n",
      "said: 4.23\n",
      "shiite: 4.02\n",
      "chad: 4.02\n",
      "bomb: 4.02\n",
      "obeid: 4.02\n",
      "\n",
      "Topic #3:\n",
      "said: 58.87\n",
      "eclipse: 47.03\n",
      "fire: 23.07\n",
      "shining: 21.20\n",
      "people: 20.70\n",
      "sun: 20.53\n",
      "guerrillas: 19.54\n",
      "path: 18.69\n",
      "police: 18.32\n",
      "coca: 17.02\n",
      "area: 16.99\n",
      "army: 15.99\n",
      "percent: 15.28\n",
      "officials: 14.26\n",
      "valley: 14.00\n",
      "huallaga: 13.02\n",
      "upper: 12.83\n",
      "rebels: 12.63\n",
      "forest: 12.59\n",
      "two: 12.24\n",
      "\n",
      "Topic #4:\n",
      "gun: 25.72\n",
      "yellowstone: 22.31\n",
      "park: 22.29\n",
      "police: 20.10\n",
      "fires: 16.14\n",
      "bill: 15.50\n",
      "also: 14.54\n",
      "public: 14.45\n",
      "could: 12.34\n",
      "nra: 11.90\n",
      "even: 11.62\n",
      "control: 11.44\n",
      "still: 11.39\n",
      "brady: 11.22\n",
      "suspect: 11.04\n",
      "many: 10.92\n",
      "winter: 10.57\n",
      "new: 10.24\n",
      "city: 9.93\n",
      "guns: 9.88\n",
      "\n",
      "Topic #5:\n",
      "would: 63.77\n",
      "said: 62.54\n",
      "johnson: 49.45\n",
      "people: 45.88\n",
      "state: 37.40\n",
      "welfare: 30.64\n",
      "years: 28.60\n",
      "could: 22.76\n",
      "drugs: 22.07\n",
      "two: 21.71\n",
      "per: 21.41\n",
      "ben: 21.04\n",
      "cent: 20.56\n",
      "also: 20.39\n",
      "countries: 19.89\n",
      "think: 17.67\n",
      "oecd: 17.02\n",
      "one: 16.79\n",
      "age: 16.50\n",
      "cost: 15.62\n",
      "\n",
      "Topic #6:\n",
      "census: 56.43\n",
      "said: 45.01\n",
      "illegal: 43.75\n",
      "house: 41.55\n",
      "aliens: 40.27\n",
      "states: 38.12\n",
      "would: 37.85\n",
      "one: 27.87\n",
      "seats: 25.66\n",
      "people: 25.25\n",
      "counting: 22.74\n",
      "bureau: 22.53\n",
      "count: 20.17\n",
      "state: 19.24\n",
      "congress: 17.30\n",
      "million: 16.06\n",
      "constitution: 15.97\n",
      "could: 15.94\n",
      "new: 14.52\n",
      "residents: 14.49\n",
      "\n",
      "Topic #7:\n",
      "police: 26.02\n",
      "air: 18.86\n",
      "ventilation: 17.02\n",
      "building: 15.97\n",
      "said: 13.30\n",
      "rescue: 12.02\n",
      "rights: 11.75\n",
      "operation: 11.68\n",
      "says: 11.21\n",
      "kates: 9.02\n",
      "percent: 8.83\n",
      "say: 8.69\n",
      "brutality: 8.02\n",
      "flu: 8.02\n",
      "civil: 8.00\n",
      "may: 7.18\n",
      "tuberculosis: 7.02\n",
      "spread: 7.02\n",
      "buildings: 7.01\n",
      "workers: 6.87\n",
      "\n",
      "Topic #8:\n",
      "nra: 59.60\n",
      "police: 41.45\n",
      "would: 30.26\n",
      "gates: 25.15\n",
      "said: 24.19\n",
      "guns: 19.21\n",
      "mr: 18.43\n",
      "drug: 18.37\n",
      "hammer: 16.52\n",
      "sahel: 16.02\n",
      "gun: 15.92\n",
      "one: 15.73\n",
      "ban: 15.54\n",
      "deconcini: 13.95\n",
      "bill: 13.90\n",
      "assault: 13.09\n",
      "people: 13.01\n",
      "chief: 12.69\n",
      "los: 12.55\n",
      "angeles: 12.51\n",
      "\n",
      "Topic #9:\n",
      "disease: 4.02\n",
      "encephalopathies: 3.02\n",
      "condition: 3.02\n",
      "sheep: 3.02\n",
      "scrapie: 3.02\n",
      "spongiform: 3.02\n",
      "cattle: 3.02\n",
      "three: 3.02\n",
      "diagnosed: 2.02\n",
      "government: 2.02\n",
      "agriculture: 2.02\n",
      "found: 2.02\n",
      "confirmed: 2.02\n",
      "species: 2.02\n",
      "since: 2.02\n",
      "mr: 2.02\n",
      "said: 2.02\n",
      "cases: 2.02\n",
      "cats: 1.02\n",
      "years: 1.02\n",
      "\n",
      "Topic #10:\n",
      "said: 95.63\n",
      "air: 78.52\n",
      "crash: 62.97\n",
      "aircraft: 50.49\n",
      "force: 46.24\n",
      "plane: 44.66\n",
      "crashed: 34.73\n",
      "base: 30.28\n",
      "two: 29.45\n",
      "pilot: 29.21\n",
      "jet: 23.81\n",
      "training: 21.34\n",
      "military: 20.69\n",
      "west: 20.33\n",
      "leland: 19.02\n",
      "crew: 18.65\n",
      "spokesman: 17.92\n",
      "miles: 17.77\n",
      "flight: 17.77\n",
      "accident: 17.30\n",
      "\n",
      "Topic #11:\n",
      "oil: 207.45\n",
      "exxon: 185.02\n",
      "said: 167.10\n",
      "valdez: 112.02\n",
      "spill: 112.02\n",
      "tanker: 55.02\n",
      "cleanup: 55.02\n",
      "alaska: 51.18\n",
      "coast: 49.86\n",
      "guard: 46.99\n",
      "sound: 46.59\n",
      "million: 40.41\n",
      "ship: 39.99\n",
      "miles: 35.75\n",
      "state: 33.78\n",
      "could: 30.59\n",
      "officials: 29.67\n",
      "william: 29.43\n",
      "would: 28.03\n",
      "prince: 27.02\n",
      "\n",
      "Topic #12:\n",
      "slovenia: 158.54\n",
      "yugoslavia: 81.84\n",
      "slovene: 43.55\n",
      "croatia: 38.32\n",
      "slovenian: 35.02\n",
      "republic: 34.80\n",
      "yugoslav: 34.02\n",
      "serbia: 31.02\n",
      "federal: 29.74\n",
      "said: 27.61\n",
      "republics: 27.02\n",
      "state: 22.03\n",
      "independence: 21.96\n",
      "foreign: 21.40\n",
      "relations: 18.11\n",
      "kucan: 17.02\n",
      "ljubljana: 17.02\n",
      "belgrade: 15.00\n",
      "army: 13.03\n",
      "serbian: 13.02\n",
      "\n",
      "Topic #13:\n",
      "right: 54.25\n",
      "amendment: 39.29\n",
      "militia: 36.78\n",
      "gun: 34.48\n",
      "arms: 34.42\n",
      "second: 31.42\n",
      "people: 31.28\n",
      "would: 25.28\n",
      "congress: 23.23\n",
      "says: 22.04\n",
      "bear: 21.90\n",
      "state: 17.69\n",
      "world: 17.40\n",
      "one: 17.27\n",
      "rights: 15.82\n",
      "constitution: 14.83\n",
      "sun: 14.82\n",
      "time: 14.42\n",
      "first: 14.33\n",
      "free: 13.25\n",
      "\n",
      "Topic #14:\n",
      "jackson: 30.07\n",
      "says: 26.61\n",
      "dickey: 25.35\n",
      "hatch: 17.02\n",
      "one: 14.42\n",
      "village: 13.02\n",
      "car: 11.94\n",
      "browning: 10.91\n",
      "earthquake: 10.39\n",
      "quake: 10.19\n",
      "percent: 10.02\n",
      "boatwright: 10.02\n",
      "like: 8.32\n",
      "loans: 8.02\n",
      "savings: 8.02\n",
      "women: 8.02\n",
      "two: 7.96\n",
      "officer: 7.03\n",
      "bank: 7.02\n",
      "police: 6.37\n",
      "\n",
      "Topic #15:\n",
      "eclipse: 29.02\n",
      "gandhi: 25.02\n",
      "said: 24.04\n",
      "party: 22.50\n",
      "india: 17.02\n",
      "congress: 15.17\n",
      "fire: 13.22\n",
      "new: 11.25\n",
      "political: 10.68\n",
      "minister: 10.02\n",
      "years: 9.19\n",
      "tamil: 9.02\n",
      "prime: 9.02\n",
      "garden: 9.02\n",
      "city: 8.66\n",
      "many: 8.46\n",
      "house: 8.43\n",
      "sun: 8.06\n",
      "landscaping: 8.02\n",
      "home: 8.02\n",
      "\n",
      "Topic #16:\n",
      "fujita: 15.02\n",
      "plo: 14.02\n",
      "american: 10.88\n",
      "people: 10.44\n",
      "said: 10.34\n",
      "tornadoes: 9.25\n",
      "law: 8.48\n",
      "assassination: 8.02\n",
      "arafat: 7.02\n",
      "united: 7.01\n",
      "states: 6.99\n",
      "get: 6.96\n",
      "attacks: 6.02\n",
      "right: 6.00\n",
      "document: 5.02\n",
      "government: 4.95\n",
      "also: 4.85\n",
      "one: 4.64\n",
      "like: 4.63\n",
      "may: 4.44\n",
      "\n",
      "Topic #17:\n",
      "thomas: 170.47\n",
      "court: 76.84\n",
      "black: 46.43\n",
      "said: 44.58\n",
      "supreme: 35.33\n",
      "rights: 35.29\n",
      "clarence: 30.60\n",
      "senate: 29.62\n",
      "civil: 27.66\n",
      "law: 25.04\n",
      "nomination: 22.02\n",
      "box: 19.02\n",
      "confirmation: 17.78\n",
      "judge: 17.36\n",
      "views: 16.99\n",
      "affirmative: 16.98\n",
      "conservative: 16.44\n",
      "chairman: 16.35\n",
      "man: 16.14\n",
      "hearings: 15.90\n",
      "\n",
      "Topic #18:\n",
      "said: 37.68\n",
      "tornadoes: 29.79\n",
      "tornado: 27.79\n",
      "people: 21.10\n",
      "one: 20.55\n",
      "may: 18.51\n",
      "house: 17.19\n",
      "national: 15.67\n",
      "last: 13.82\n",
      "weather: 13.62\n",
      "year: 13.19\n",
      "miles: 12.79\n",
      "since: 12.73\n",
      "plans: 11.80\n",
      "week: 10.91\n",
      "average: 10.70\n",
      "says: 10.63\n",
      "nation: 10.49\n",
      "storms: 10.31\n",
      "north: 10.24\n",
      "\n",
      "Topic #19:\n",
      "said: 108.32\n",
      "crash: 54.40\n",
      "plane: 50.56\n",
      "engine: 45.02\n",
      "one: 24.88\n",
      "united: 24.25\n",
      "flight: 23.72\n",
      "safety: 20.43\n",
      "crashed: 20.20\n",
      "two: 18.92\n",
      "board: 18.65\n",
      "problems: 18.36\n",
      "jet: 18.25\n",
      "faa: 18.02\n",
      "accident: 17.83\n",
      "airport: 17.49\n",
      "northwest: 17.02\n",
      "aviation: 17.02\n",
      "engines: 15.90\n",
      "ground: 15.80\n",
      "\n",
      "Topic #20:\n",
      "said: 80.94\n",
      "fire: 54.15\n",
      "police: 52.91\n",
      "los: 24.96\n",
      "department: 24.78\n",
      "officers: 23.83\n",
      "chief: 21.29\n",
      "protesters: 20.02\n",
      "say: 19.88\n",
      "years: 19.09\n",
      "areas: 19.07\n",
      "water: 18.44\n",
      "even: 18.06\n",
      "would: 17.91\n",
      "brush: 17.89\n",
      "angeles: 17.38\n",
      "hills: 17.01\n",
      "people: 16.60\n",
      "one: 16.55\n",
      "last: 15.70\n",
      "\n",
      "Topic #21:\n",
      "hurricane: 124.84\n",
      "said: 113.35\n",
      "hurricanes: 64.06\n",
      "storm: 43.37\n",
      "season: 39.33\n",
      "atlantic: 38.93\n",
      "storms: 38.79\n",
      "mph: 36.39\n",
      "tropical: 35.16\n",
      "winds: 34.98\n",
      "center: 30.59\n",
      "last: 27.52\n",
      "national: 26.37\n",
      "year: 25.64\n",
      "gray: 24.72\n",
      "would: 24.29\n",
      "one: 23.24\n",
      "people: 22.98\n",
      "sheets: 21.54\n",
      "miami: 21.44\n",
      "\n",
      "Topic #22:\n",
      "tunnel: 32.55\n",
      "french: 22.90\n",
      "first: 20.23\n",
      "british: 19.27\n",
      "workers: 17.76\n",
      "two: 17.64\n",
      "side: 13.63\n",
      "france: 12.34\n",
      "time: 12.26\n",
      "europe: 11.62\n",
      "britain: 11.18\n",
      "channel: 11.14\n",
      "billion: 11.01\n",
      "lyng: 10.13\n",
      "said: 9.79\n",
      "usda: 9.42\n",
      "miles: 9.16\n",
      "goldwin: 8.97\n",
      "service: 8.82\n",
      "virginia: 8.69\n",
      "\n",
      "Topic #23:\n",
      "path: 76.58\n",
      "shining: 76.46\n",
      "guzman: 44.88\n",
      "war: 38.01\n",
      "people: 24.75\n",
      "committee: 21.91\n",
      "central: 21.87\n",
      "party: 19.48\n",
      "meeting: 18.76\n",
      "abimael: 17.02\n",
      "said: 16.26\n",
      "feliciano: 16.02\n",
      "government: 15.13\n",
      "also: 14.40\n",
      "members: 13.34\n",
      "issajenko: 12.02\n",
      "gonzalo: 12.02\n",
      "order: 11.97\n",
      "leadership: 11.90\n",
      "peace: 11.85\n",
      "\n",
      "Topic #24:\n",
      "crash: 7.39\n",
      "base: 5.24\n",
      "dfaa: 5.02\n",
      "okinawa: 4.02\n",
      "kadena: 4.02\n",
      "forces: 3.99\n",
      "air: 3.92\n",
      "said: 3.79\n",
      "military: 3.47\n",
      "crashed: 3.04\n",
      "taylor: 3.02\n",
      "office: 3.02\n",
      "management: 3.02\n",
      "safe: 3.02\n",
      "bases: 3.00\n",
      "briefing: 3.00\n",
      "investigation: 2.96\n",
      "fighter: 2.61\n",
      "clinic: 2.02\n",
      "physicians: 2.02\n",
      "\n",
      "Topic #25:\n",
      "said: 44.51\n",
      "says: 35.54\n",
      "state: 35.17\n",
      "area: 26.52\n",
      "eclipse: 23.80\n",
      "one: 23.78\n",
      "year: 23.11\n",
      "earthquake: 22.99\n",
      "north: 22.64\n",
      "aid: 21.59\n",
      "house: 21.53\n",
      "mexico: 20.65\n",
      "may: 20.34\n",
      "california: 20.11\n",
      "along: 18.57\n",
      "last: 18.56\n",
      "would: 18.23\n",
      "region: 16.49\n",
      "farmers: 15.42\n",
      "new: 15.42\n",
      "\n",
      "Topic #26:\n",
      "johnson: 121.01\n",
      "lewis: 42.88\n",
      "said: 40.35\n",
      "francis: 39.30\n",
      "world: 28.75\n",
      "steroids: 24.45\n",
      "record: 24.31\n",
      "ben: 23.42\n",
      "athletes: 22.73\n",
      "sport: 19.91\n",
      "olympics: 19.74\n",
      "track: 18.79\n",
      "steroid: 17.30\n",
      "field: 16.38\n",
      "drugs: 15.79\n",
      "gold: 15.28\n",
      "positive: 14.71\n",
      "use: 14.21\n",
      "toronto: 13.74\n",
      "run: 13.44\n",
      "\n",
      "Topic #27:\n",
      "said: 278.25\n",
      "fire: 182.98\n",
      "police: 151.19\n",
      "forest: 110.74\n",
      "fires: 84.71\n",
      "firefighters: 76.96\n",
      "national: 72.94\n",
      "acres: 71.13\n",
      "department: 70.17\n",
      "officers: 66.41\n",
      "service: 53.11\n",
      "report: 44.46\n",
      "one: 43.47\n",
      "officials: 41.51\n",
      "chief: 40.84\n",
      "officer: 40.75\n",
      "commission: 39.44\n",
      "city: 36.12\n",
      "office: 33.50\n",
      "burned: 33.07\n",
      "\n",
      "Topic #28:\n",
      "mr: 19.04\n",
      "daley: 16.02\n",
      "said: 14.02\n",
      "hurricane: 12.02\n",
      "clinton: 9.02\n",
      "nafta: 8.02\n",
      "chicago: 7.02\n",
      "political: 6.14\n",
      "agreement: 6.08\n",
      "models: 6.02\n",
      "forecasting: 6.02\n",
      "trade: 5.06\n",
      "forecasters: 5.02\n",
      "satellites: 5.02\n",
      "satellite: 5.02\n",
      "path: 5.02\n",
      "hugo: 5.02\n",
      "information: 5.02\n",
      "comes: 4.93\n",
      "used: 4.91\n",
      "\n",
      "Topic #29:\n",
      "said: 67.60\n",
      "illegal: 33.91\n",
      "census: 33.61\n",
      "would: 28.03\n",
      "aliens: 25.77\n",
      "senate: 22.93\n",
      "federal: 22.53\n",
      "states: 20.34\n",
      "people: 19.06\n",
      "population: 17.96\n",
      "california: 17.95\n",
      "count: 17.85\n",
      "action: 17.51\n",
      "county: 17.25\n",
      "city: 16.38\n",
      "seats: 14.02\n",
      "officials: 13.63\n",
      "million: 12.01\n",
      "bureau: 11.48\n",
      "aid: 11.02\n",
      "\n",
      "Topic #30:\n",
      "welfare: 125.34\n",
      "reform: 43.43\n",
      "work: 28.77\n",
      "president: 25.60\n",
      "would: 23.41\n",
      "benefits: 19.48\n",
      "recipients: 16.97\n",
      "clinton: 16.61\n",
      "administration: 16.55\n",
      "programs: 16.11\n",
      "children: 15.48\n",
      "system: 14.42\n",
      "bill: 14.42\n",
      "house: 13.77\n",
      "training: 12.79\n",
      "families: 12.75\n",
      "jobs: 11.74\n",
      "school: 11.36\n",
      "new: 11.19\n",
      "years: 9.95\n",
      "\n",
      "Topic #31:\n",
      "marathon: 104.66\n",
      "race: 80.35\n",
      "miles: 40.41\n",
      "boston: 35.84\n",
      "first: 32.74\n",
      "run: 31.71\n",
      "time: 30.95\n",
      "runners: 29.02\n",
      "kelley: 27.82\n",
      "last: 26.86\n",
      "finished: 26.80\n",
      "women: 25.74\n",
      "second: 25.29\n",
      "third: 22.82\n",
      "year: 22.45\n",
      "running: 21.14\n",
      "ran: 20.56\n",
      "said: 18.06\n",
      "course: 17.73\n",
      "finish: 17.49\n",
      "\n",
      "Topic #32:\n",
      "said: 102.19\n",
      "tuberculosis: 78.02\n",
      "people: 55.73\n",
      "tb: 52.02\n",
      "new: 39.48\n",
      "aids: 38.02\n",
      "cases: 37.99\n",
      "one: 36.58\n",
      "tornado: 36.02\n",
      "reported: 33.67\n",
      "disease: 29.09\n",
      "health: 23.68\n",
      "percent: 23.32\n",
      "county: 23.27\n",
      "year: 21.30\n",
      "injured: 20.02\n",
      "states: 18.29\n",
      "among: 18.26\n",
      "two: 18.00\n",
      "damage: 17.94\n",
      "\n",
      "Topic #33:\n",
      "world: 42.01\n",
      "third: 41.90\n",
      "exposure: 30.02\n",
      "bank: 29.98\n",
      "common: 22.37\n",
      "taylor: 22.15\n",
      "boston: 22.02\n",
      "assets: 21.02\n",
      "reserve: 21.02\n",
      "banks: 19.02\n",
      "equity: 18.02\n",
      "liz: 16.02\n",
      "loans: 15.02\n",
      "said: 12.34\n",
      "cover: 11.94\n",
      "provision: 10.02\n",
      "additional: 10.02\n",
      "actual: 10.00\n",
      "coverage: 10.00\n",
      "necessary: 9.77\n",
      "\n",
      "Topic #34:\n",
      "mine: 29.75\n",
      "diamond: 22.44\n",
      "beers: 17.73\n",
      "de: 17.66\n",
      "diamonds: 17.35\n",
      "carats: 15.93\n",
      "mr: 15.27\n",
      "south: 14.03\n",
      "venetia: 14.02\n",
      "per: 11.99\n",
      "cent: 11.98\n",
      "dollars: 11.45\n",
      "year: 11.40\n",
      "output: 10.43\n",
      "production: 9.77\n",
      "world: 9.16\n",
      "tonnes: 9.02\n",
      "river: 9.02\n",
      "mining: 8.91\n",
      "also: 8.18\n",
      "\n",
      "Topic #35:\n",
      "diabetes: 95.85\n",
      "said: 19.14\n",
      "disease: 19.11\n",
      "health: 18.54\n",
      "insulin: 17.02\n",
      "latinos: 17.02\n",
      "exercise: 12.01\n",
      "diet: 11.97\n",
      "type: 11.30\n",
      "care: 10.69\n",
      "american: 10.37\n",
      "get: 10.20\n",
      "latino: 10.18\n",
      "ii: 9.88\n",
      "davidson: 9.02\n",
      "body: 7.87\n",
      "likely: 7.67\n",
      "go: 7.03\n",
      "obesity: 7.02\n",
      "people: 6.98\n",
      "\n",
      "Topic #36:\n",
      "tunnel: 61.01\n",
      "eclipse: 39.93\n",
      "rail: 27.24\n",
      "link: 26.39\n",
      "british: 23.62\n",
      "total: 20.74\n",
      "said: 20.69\n",
      "billion: 20.37\n",
      "project: 20.19\n",
      "french: 19.34\n",
      "says: 17.75\n",
      "eurotunnel: 16.86\n",
      "sun: 16.80\n",
      "london: 16.08\n",
      "miles: 15.50\n",
      "britain: 14.84\n",
      "time: 13.89\n",
      "million: 13.00\n",
      "three: 12.31\n",
      "channel: 12.28\n",
      "\n",
      "Topic #37:\n",
      "people: 15.91\n",
      "tuberculosis: 10.02\n",
      "sgt: 10.02\n",
      "tb: 9.02\n",
      "bacteria: 9.02\n",
      "drug: 8.02\n",
      "ramstein: 8.02\n",
      "said: 7.43\n",
      "study: 7.02\n",
      "aids: 7.02\n",
      "huey: 6.02\n",
      "wednesday: 5.73\n",
      "hiv: 5.02\n",
      "virus: 5.02\n",
      "years: 4.92\n",
      "doctors: 4.02\n",
      "percent: 4.02\n",
      "infected: 4.02\n",
      "risk: 4.02\n",
      "also: 3.65\n",
      "\n",
      "Topic #38:\n",
      "drought: 117.19\n",
      "said: 91.27\n",
      "year: 65.75\n",
      "farmers: 44.70\n",
      "percent: 33.50\n",
      "farm: 31.09\n",
      "billion: 29.41\n",
      "crop: 28.65\n",
      "department: 28.60\n",
      "last: 26.23\n",
      "million: 25.15\n",
      "states: 24.85\n",
      "agriculture: 24.83\n",
      "weather: 21.58\n",
      "fire: 21.12\n",
      "could: 20.17\n",
      "would: 19.38\n",
      "areas: 18.78\n",
      "land: 18.08\n",
      "wheat: 17.58\n",
      "\n",
      "Topic #39:\n",
      "florida: 35.52\n",
      "dollars: 32.17\n",
      "hurricane: 30.66\n",
      "would: 27.49\n",
      "andrew: 26.91\n",
      "insurance: 23.84\n",
      "limits: 21.93\n",
      "losses: 21.91\n",
      "damage: 21.25\n",
      "yesterday: 21.08\n",
      "louisiana: 20.56\n",
      "us: 20.09\n",
      "term: 18.62\n",
      "claims: 17.34\n",
      "state: 15.99\n",
      "industry: 15.97\n",
      "insurers: 15.02\n",
      "seniority: 14.02\n",
      "one: 12.99\n",
      "however: 12.30\n",
      "\n",
      "Topic #40:\n",
      "country: 10.03\n",
      "trade: 6.72\n",
      "europe: 5.92\n",
      "slovenes: 4.41\n",
      "says: 4.25\n",
      "debate: 4.00\n",
      "yesterday: 3.96\n",
      "perot: 3.92\n",
      "exchange: 3.86\n",
      "slovenia: 3.50\n",
      "independence: 3.05\n",
      "skoberne: 3.02\n",
      "veselinovic: 3.02\n",
      "free: 2.92\n",
      "rest: 2.91\n",
      "one: 2.87\n",
      "certain: 2.87\n",
      "pact: 2.75\n",
      "going: 2.74\n",
      "western: 2.71\n",
      "\n",
      "Topic #41:\n",
      "bank: 70.76\n",
      "said: 57.70\n",
      "taylor: 49.82\n",
      "mr: 45.31\n",
      "pneumonia: 33.00\n",
      "miss: 30.21\n",
      "countries: 28.02\n",
      "world: 27.76\n",
      "hospital: 27.51\n",
      "says: 25.86\n",
      "doctors: 21.97\n",
      "development: 20.31\n",
      "poverty: 19.65\n",
      "john: 18.24\n",
      "health: 16.61\n",
      "condition: 16.40\n",
      "actress: 16.02\n",
      "preston: 15.02\n",
      "statement: 14.74\n",
      "third: 14.47\n",
      "\n",
      "Topic #42:\n",
      "diamond: 113.95\n",
      "de: 103.76\n",
      "beers: 93.23\n",
      "diamonds: 78.65\n",
      "market: 39.85\n",
      "mr: 35.27\n",
      "year: 31.38\n",
      "cartel: 30.83\n",
      "south: 29.13\n",
      "world: 28.03\n",
      "says: 27.98\n",
      "sales: 27.60\n",
      "cent: 23.06\n",
      "cso: 21.83\n",
      "per: 21.43\n",
      "rough: 21.27\n",
      "said: 19.70\n",
      "prices: 19.54\n",
      "million: 18.71\n",
      "last: 18.70\n",
      "\n",
      "Topic #43:\n",
      "nafta: 88.72\n",
      "us: 58.40\n",
      "mr: 44.42\n",
      "trade: 30.66\n",
      "mexico: 26.08\n",
      "clinton: 22.73\n",
      "botswana: 22.52\n",
      "said: 21.50\n",
      "would: 20.62\n",
      "caribbean: 20.02\n",
      "administration: 16.66\n",
      "agreement: 16.57\n",
      "cso: 15.44\n",
      "jobs: 14.36\n",
      "labour: 14.02\n",
      "cent: 13.72\n",
      "hispanic: 13.02\n",
      "canada: 12.34\n",
      "week: 12.34\n",
      "free: 11.84\n",
      "\n",
      "Topic #44:\n",
      "hurricane: 48.56\n",
      "sheets: 22.50\n",
      "said: 21.67\n",
      "gilbert: 19.13\n",
      "pressure: 15.24\n",
      "center: 14.30\n",
      "category: 13.02\n",
      "winds: 12.93\n",
      "mph: 9.65\n",
      "director: 8.32\n",
      "storm: 7.65\n",
      "inches: 7.58\n",
      "major: 7.02\n",
      "storms: 6.89\n",
      "mississippi: 6.15\n",
      "damage: 6.13\n",
      "right: 6.02\n",
      "dealing: 6.02\n",
      "amendment: 6.02\n",
      "zimmer: 6.02\n",
      "\n",
      "Topic #45:\n",
      "disease: 87.93\n",
      "bse: 56.02\n",
      "cattle: 46.70\n",
      "british: 30.56\n",
      "cow: 28.52\n",
      "cases: 23.11\n",
      "feed: 22.54\n",
      "agriculture: 20.89\n",
      "ministry: 20.80\n",
      "sheep: 19.69\n",
      "humans: 19.02\n",
      "scientists: 18.88\n",
      "health: 18.22\n",
      "farmers: 17.21\n",
      "animals: 16.43\n",
      "ban: 16.07\n",
      "mad: 15.59\n",
      "cows: 14.67\n",
      "transmitted: 14.02\n",
      "cjd: 13.67\n",
      "\n",
      "Topic #46:\n",
      "fire: 32.70\n",
      "park: 32.64\n",
      "year: 29.60\n",
      "one: 27.53\n",
      "years: 26.06\n",
      "says: 25.46\n",
      "yellowstone: 23.74\n",
      "cjd: 23.37\n",
      "forest: 21.28\n",
      "disease: 19.58\n",
      "governors: 18.02\n",
      "people: 16.39\n",
      "brain: 16.02\n",
      "percent: 15.70\n",
      "trees: 15.60\n",
      "new: 14.68\n",
      "despain: 14.02\n",
      "sheep: 13.13\n",
      "may: 12.24\n",
      "since: 11.95\n",
      "\n",
      "Topic #47:\n",
      "said: 43.61\n",
      "police: 26.34\n",
      "morgan: 24.02\n",
      "jordanian: 22.02\n",
      "officer: 20.02\n",
      "searle: 18.02\n",
      "assassination: 17.02\n",
      "officers: 16.02\n",
      "black: 15.02\n",
      "security: 14.30\n",
      "group: 13.48\n",
      "barnes: 12.02\n",
      "frc: 12.02\n",
      "military: 10.71\n",
      "drug: 10.02\n",
      "man: 10.02\n",
      "fundamentalist: 10.02\n",
      "official: 9.86\n",
      "information: 9.48\n",
      "jordan: 9.02\n",
      "\n",
      "Topic #48:\n",
      "earthquake: 62.68\n",
      "said: 48.73\n",
      "damage: 22.73\n",
      "year: 20.56\n",
      "earthquakes: 17.34\n",
      "percent: 16.40\n",
      "scale: 16.09\n",
      "magnitude: 15.94\n",
      "quake: 14.57\n",
      "miles: 14.29\n",
      "chile: 14.02\n",
      "recorded: 13.46\n",
      "area: 13.35\n",
      "san: 12.64\n",
      "last: 12.21\n",
      "may: 12.10\n",
      "center: 12.09\n",
      "hispanics: 12.08\n",
      "buildings: 11.97\n",
      "richter: 11.95\n",
      "\n",
      "Topic #49:\n",
      "term: 96.35\n",
      "limits: 68.26\n",
      "would: 38.99\n",
      "incumbents: 28.02\n",
      "congress: 27.95\n",
      "voters: 26.77\n",
      "house: 23.70\n",
      "political: 23.43\n",
      "new: 22.51\n",
      "limit: 22.37\n",
      "state: 20.14\n",
      "says: 19.20\n",
      "office: 18.98\n",
      "legislative: 17.84\n",
      "system: 16.98\n",
      "democratic: 16.55\n",
      "party: 16.29\n",
      "one: 14.91\n",
      "public: 13.70\n",
      "congressional: 13.69\n",
      "\n",
      "Topic #50:\n",
      "bank: 67.26\n",
      "world: 45.80\n",
      "debt: 44.31\n",
      "new: 34.92\n",
      "countries: 34.64\n",
      "shining: 31.97\n",
      "path: 31.87\n",
      "peace: 27.60\n",
      "third: 23.23\n",
      "conable: 23.02\n",
      "poverty: 21.39\n",
      "year: 19.62\n",
      "fujimori: 18.99\n",
      "also: 18.97\n",
      "october: 18.38\n",
      "says: 17.94\n",
      "war: 17.03\n",
      "guzman: 17.02\n",
      "government: 15.95\n",
      "loans: 14.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLDA with K={topic_counts[2]} Topics for DUC 2001\")\n",
    "lda_duc = LatentDirichletAllocation(n_components=topic_counts[2], random_state=0)\n",
    "lda_duc.fit(term_frequency_matrix)\n",
    "display_top_words(lda_duc, count_vectorizer.get_feature_names_out(), number_of_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68268462",
   "metadata": {},
   "source": [
    "# PROBLEM 2: Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589397cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Define the directory containing the document files\n",
    "DOCUMENT_DIRECTORY = 'DUC2001/'\n",
    "\n",
    "def extract_sentences_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from an HTML file's <text> tags, converts the content to lowercase,\n",
    "    tokenizes it into sentences, and returns the list of sentences.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The path to the HTML file.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of sentences extracted from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Parse the HTML and extract text from <text> tags\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    text_elements = soup.find_all('text')\n",
    "    combined_text = ' '.join(element.get_text() for element in text_elements).lower()\n",
    "    \n",
    "    # Tokenize the combined text into sentences\n",
    "    sentences = sent_tokenize(combined_text)\n",
    "    return sentences\n",
    "\n",
    "def calculate_word_frequencies(sentences):\n",
    "    \"\"\"\n",
    "    Calculates the normalized frequency of each word in a list of sentences.\n",
    "    \n",
    "    Parameters:\n",
    "        sentences (list): A list of sentences.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping each word to its normalized frequency.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(' '.join(sentences))\n",
    "    word_counts = {}\n",
    "    \n",
    "    # Count occurrences of each word\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    \n",
    "    total_words = sum(word_counts.values())\n",
    "    # Normalize the counts by the total number of words\n",
    "    word_frequencies = {word: count / total_words for word, count in word_counts.items()}\n",
    "    return word_frequencies\n",
    "\n",
    "def calculate_kl_divergence(summary_freq, document_freq):\n",
    "    \"\"\"\n",
    "    Computes the Kullback-Leibler (KL) divergence between the summary and document word frequency distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        summary_freq (dict): The word frequency distribution from the summary.\n",
    "        document_freq (dict): The word frequency distribution from the full document.\n",
    "    \n",
    "    Returns:\n",
    "        float: The KL divergence score.\n",
    "    \"\"\"\n",
    "    divergence = 0\n",
    "    for word, freq in summary_freq.items():\n",
    "        if word in document_freq:\n",
    "            divergence += freq * np.log(freq / document_freq[word])\n",
    "    return divergence\n",
    "\n",
    "def choose_best_sentence(sentences, document_freq, current_summary_sentences):\n",
    "    \"\"\"\n",
    "    Iterates over the document's sentences to find the sentence which, when added to \n",
    "    the current summary, minimizes the KL divergence compared to the document's distribution.\n",
    "    \n",
    "    Parameters:\n",
    "        sentences (list): The full list of document sentences.\n",
    "        document_freq (dict): The word frequency distribution for the entire document.\n",
    "        current_summary_sentences (list): The list of sentences already selected for the summary.\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The selected sentence that best reduces divergence, or None if no sentence improves the summary.\n",
    "    \"\"\"\n",
    "    best_sentence = None\n",
    "    min_divergence = float('inf')\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Skip if the sentence is already in the summary\n",
    "        if sentence in current_summary_sentences:\n",
    "            continue\n",
    "        \n",
    "        # Create a temporary summary including the new sentence\n",
    "        temp_summary = current_summary_sentences + [sentence]\n",
    "        temp_summary_freq = calculate_word_frequencies(temp_summary)\n",
    "        divergence = calculate_kl_divergence(temp_summary_freq, document_freq)\n",
    "        \n",
    "        # Update the best sentence if the current one yields a lower divergence\n",
    "        if divergence < min_divergence:\n",
    "            min_divergence = divergence\n",
    "            best_sentence = sentence\n",
    "    \n",
    "    return best_sentence\n",
    "\n",
    "def generate_kl_summary(document_sentences, num_summary_sentences):\n",
    "    \"\"\"\n",
    "    Generates a summary by iteratively selecting sentences to minimize the KL divergence \n",
    "    between the summary and the document's word frequency distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        document_sentences (list): A list of all sentences from the document.\n",
    "        num_summary_sentences (int): The target number of sentences to include in the summary.\n",
    "    \n",
    "    Returns:\n",
    "        str: The summary as a single concatenated string of selected sentences.\n",
    "    \"\"\"\n",
    "    document_freq = calculate_word_frequencies(document_sentences)\n",
    "    summary_sentences = []\n",
    "    \n",
    "    while len(summary_sentences) < num_summary_sentences:\n",
    "        best_sentence = choose_best_sentence(document_sentences, document_freq, summary_sentences)\n",
    "        if best_sentence:\n",
    "            summary_sentences.append(best_sentence)\n",
    "        else:\n",
    "            # Stop if no more sentences contribute to reducing divergence\n",
    "            break\n",
    "    \n",
    "    return ' '.join(summary_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97275267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all documents in the directory: read files and extract sentences from each\n",
    "documents = {}\n",
    "\n",
    "for filename in os.listdir(DOCUMENT_DIRECTORY):\n",
    "    file_path = os.path.join(DOCUMENT_DIRECTORY, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        documents[filename] = extract_sentences_from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b0220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of AP880816-0234:\n",
      "the rodrigo franco command, which has vowed to kill a shining\n",
      "path member or sympathizer for every person slain by guerrillas,\n",
      "issued the threat against district attorney carlos escobar on\n",
      "monday, according to his office in andean city of ayacucho. officials said the rebel raids occurred sunday, at a police post\n",
      "and telephone relay station near the jungle city of pucallpa, 325\n",
      "miles northeast of lima. escobar is investigating charges that troops rounded up dozens\n",
      "of peasants, accused them of being shining path members and killed\n",
      "them. the\n",
      "government says more than 15,000 people have been killed and puts\n",
      "the property damage at $10 billion. \n",
      "   a death squad opposed to the shining path\n",
      "guerrillas has threatened to kill a district attorney if he\n",
      "investigates charges that soldiers massacred dozens of peasants,\n",
      "his office said tuesday.\n",
      "\n",
      "Summary of AP890714-0129:\n",
      "firefighters on thursday said they had contained the 2,000-acre\n",
      "livermore fire west of fort collins, colo., in roosevelt national\n",
      "forest, the last of three major fires in colorado to be encircled by\n",
      "firefighters. ``they were in good shape,'' said toby martinez, a u.s. forest\n",
      "service range and wildlife staff officer for the gila national\n",
      "forest. \n",
      "   rain and higher humidity helped firefighters whip blazes in six\n",
      "western states, and a new mexico fire that polluted a creek with ash\n",
      "forced biologists to rescue hundreds of endangered fish in\n",
      "long-handled nets. the fire, which raged\n",
      "for four days and destroyed 14 unoccupied structures, was contained\n",
      "wednesday and officials predicted it would be controlled soon. a brush fire accidentally started by marine corps\n",
      "tracer fire continued burning out of control today after charring at\n",
      "least 3,000 acres at camp pendleton, a base spokesman said.\n",
      "\n",
      "Summary of AP900424-0035:\n",
      "while it is unusual to put a pneumonia patient on a ventilator,\n",
      "it does not mean that person is near death, said dr. john g.\n",
      "mohler, a university of southern california lung disease expert who\n",
      "emphasized he had no direct knowledge of miss taylor's condition. she appeared at the 1961 academy awards with a bandage\n",
      "over her scar as she accepted the ``butterfield 8'' oscar. miss taylor has been plagued with health problems for years,\n",
      "particularly back troubles from filming of ``national velvet' in\n",
      "1945, when she fell off a horse. her\n",
      "condition worsened and she was transferred april 16 to st. john's\n",
      "and moved into intensive care on friday. \n",
      "   a seriously ill elizabeth taylor\n",
      "battled pneumonia at her hospital, her breathing assisted by a\n",
      "ventilator, doctors say.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of document keys to test\n",
    "test_document_keys = [\"AP880816-0234\", \"AP890714-0129\", \"AP900424-0035\"]\n",
    "\n",
    "# Dictionary to store the KL summary for each test document\n",
    "kl_summary_output = {}\n",
    "\n",
    "# Loop through each document key, generate a summary with 5 sentences, and print the result.\n",
    "for doc_key in test_document_keys:\n",
    "    # Generate a summary using the 'generate_kl_summary' function on the document sentences\n",
    "    summary = generate_kl_summary(documents[doc_key], 5)\n",
    "    kl_summary_output[doc_key] = summary\n",
    "    print(f\"Summary of {doc_key}:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fed33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Combine the list of sentences from each document into a single string representing the full document.\n",
    "full_documents = [' '.join(sentences) for sentences in documents.values()]\n",
    "\n",
    "# Initialize a CountVectorizer to convert the documents into a term-frequency matrix,\n",
    "# automatically removing common English stop words.\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "document_term_matrix = count_vectorizer.fit_transform(full_documents)\n",
    "\n",
    "# Initialize and train the LDA model with 10 topics. The random state is set for reproducibility.\n",
    "num_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
    "lda_model.fit(document_term_matrix)\n",
    "\n",
    "# Retrieve the vocabulary (feature names) from the CountVectorizer,\n",
    "# which will be used to interpret the topics.\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Compute the topic distribution for each document.\n",
    "# Each row represents a document and each column corresponds to a topic.\n",
    "document_topic_distribution = lda_model.transform(document_term_matrix)\n",
    "\n",
    "# Compute the normalized topic-word distributions.\n",
    "# This converts the raw counts in the LDA components into probabilities for each topic.\n",
    "topic_word_distribution = lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f9b4a",
   "metadata": {},
   "source": [
    "## Generating LDA-based Word Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lda_word_distribution(doc_topic_dist, topic_word_dist, vocabulary):\n",
    "    \"\"\"\n",
    "    Generate a word probability distribution for a document by combining its topic distribution\n",
    "    with the topic-word distributions from the LDA model.\n",
    "    \n",
    "    Args:\n",
    "        doc_topic_dist (array-like): A 1D array representing the topic probabilities for the document.\n",
    "        topic_word_dist (2D array): A 2D array where each row is a topic's normalized word distribution.\n",
    "        vocabulary (array-like): List of feature names corresponding to the word columns.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary that maps each word in the vocabulary to its probability in the document.\n",
    "    \"\"\"\n",
    "    # Compute word probabilities by taking the dot product of the document's topic distribution with the LDA topic-word matrix.\n",
    "    word_probs = np.dot(doc_topic_dist, topic_word_dist)\n",
    "    \n",
    "    # Create a dictionary mapping each word to its corresponding probability.\n",
    "    word_probability_distribution = {word: prob for word, prob in zip(vocabulary, word_probs)}\n",
    "    return word_probability_distribution\n",
    "\n",
    "\n",
    "def generate_lda_summary(doc_index, num_summary_sentences, doc_topic_distributions, topic_word_distributions,\n",
    "                         vocabulary, all_document_sentences):\n",
    "    \"\"\"\n",
    "    Generate a summary for a given document based on its LDA-based word distribution. The summary is built iteratively,\n",
    "    adding one sentence at a time until it reaches the desired number of sentences. Each sentence is selected using a\n",
    "    greedy approach that minimizes the divergence between the summary's word distribution and the document's word distribution.\n",
    "    \n",
    "    Args:\n",
    "        doc_index (int): The index (or key-based order) of the target document.\n",
    "        num_summary_sentences (int): The desired number of sentences in the summary.\n",
    "        doc_topic_distributions (2D array): Matrix with each row representing a document's topic distribution.\n",
    "        topic_word_distributions (2D array): Matrix with each row corresponding to a topic's normalized word distribution.\n",
    "        vocabulary (array-like): List of feature names (typically from the vectorizer).\n",
    "        all_document_sentences (dict or list): Collection of document sentences. If a dict is provided, its values \n",
    "            (assumed to be lists of sentences) will be converted to a list.\n",
    "            \n",
    "    Returns:\n",
    "        str: A concatenated string containing the selected summary sentences.\n",
    "    \"\"\"\n",
    "    # Extract the topic distribution for the specific document.\n",
    "    document_topic_dist = doc_topic_distributions[doc_index]\n",
    "    \n",
    "    # Generate the document word distribution using the LDA model output.\n",
    "    document_word_distribution = generate_lda_word_distribution(document_topic_dist, \n",
    "                                                                topic_word_distributions, \n",
    "                                                                vocabulary)\n",
    "    \n",
    "    # Retrieve the full list of sentences for the target document.\n",
    "    if isinstance(all_document_sentences, dict):\n",
    "        document_sentences = list(all_document_sentences.values())[doc_index]\n",
    "    else:\n",
    "        document_sentences = all_document_sentences[doc_index]\n",
    "    \n",
    "    selected_sentences = []\n",
    "    \n",
    "    # Iteratively select sentences until the summary reaches the target length.\n",
    "    while len(selected_sentences) < num_summary_sentences:\n",
    "        # The helper function `choose_best_sentence` should select a sentence which, when added to the summary,\n",
    "        # minimizes the divergence between the summary's word distribution and the full document's word distribution.\n",
    "        best_sentence = choose_best_sentence(document_sentences, document_word_distribution, selected_sentences)\n",
    "        if best_sentence:\n",
    "            selected_sentences.append(best_sentence)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Return the summary as a single string.\n",
    "    return ' '.join(selected_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e49f52",
   "metadata": {},
   "source": [
    "## Listing All Processed Document Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5e2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of AP880816-0234:\n",
      "he is suspected of being the\n",
      "shining path second-in-command and is in jail on terrorism charges. the\n",
      "government says more than 15,000 people have been killed and puts\n",
      "the property damage at $10 billion. it became known in july when it claimed responsibility for\n",
      "killing the lawyer for osman morote. the rodrigo franco group is named for an official of the\n",
      "government party killed the shining path killed last year. police said members of shining path, a maoist group, killed two\n",
      "policemen and wounded three in jungle raids.\n",
      "\n",
      "Summary of AP890714-0129:\n",
      "``for now, anyway, we are\n",
      "getting some relief.'' ``my experience is that we'd see green grass again if we get\n",
      "enough moisture, say a half-inch of rain,'' he said. the fire was contained monday and should\n",
      "be controlled within four days, ms. garcia said. the storms\n",
      "dampened a fire in bridger-teton national forest that had burned\n",
      "nearly 3,500 acres. seven 20-person crews fighting the fire were to be reduced to\n",
      "three crews, officials said.\n",
      "\n",
      "Summary of AP900424-0035:\n",
      "she's not well. ``it is serious, but they are really pleased with her progress. ``she is seriously ill,'' her doctors said in a statement. ``it may be that because she is such a prominent person, they\n",
      "are taking a conservative course,'' he added. the 58-year-old actress, who won best-actress oscars for\n",
      "``butterfield 8'' and ``who's afraid of virginia woolf,'' has been\n",
      "hospitalized more than two weeks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of document keys from the existing documents dictionary.\n",
    "document_keys = list(documents.keys())\n",
    "\n",
    "# Dictionary to store the generated LDA-based summaries.\n",
    "lda_summaries = {}\n",
    "\n",
    "# List of test document keys for which the LDA summary will be generated.\n",
    "test_document_keys = [\"AP880816-0234\", \"AP890714-0129\", \"AP900424-0035\"]\n",
    "\n",
    "# Loop through each test document key to generate and display its summary.\n",
    "for doc_key in test_document_keys:\n",
    "    # Find the index of the document using its key.\n",
    "    doc_index = document_keys.index(doc_key)\n",
    "    \n",
    "    # Generate an LDA-based summary consisting of 5 sentences.\n",
    "    # The function generate_lda_summary is assumed to accept the following parameters:\n",
    "    #   - doc_index: the index of the target document,\n",
    "    #   - num_summary_sentences: target number of summary sentences,\n",
    "    #   - doc_topic_distributions: the document-topic distribution matrix (e.g. document_topic_distribution),\n",
    "    #   - topic_word_distributions: the topic-word distribution matrix (e.g. topic_word_distribution),\n",
    "    #   - vocabulary: feature names list from the vectorizer (e.g. feature_names), and\n",
    "    #   - all_document_sentences: the dictionary or list of all document sentences (e.g. docs_sentences).\n",
    "    summary = generate_lda_summary(doc_index, 5, \n",
    "                                   document_topic_distribution, \n",
    "                                   topic_word_distribution, \n",
    "                                   feature_names, \n",
    "                                   documents)\n",
    "    \n",
    "    # Save the summary in the dictionary with the document key.\n",
    "    lda_summaries[doc_key] = summary\n",
    "    \n",
    "    # Print the summary for the document.\n",
    "    print(f\"Summary of {doc_key}:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd81c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Combine the list of sentences for each document into a single full-text string.\n",
    "# 'docs_sentences' is assumed to be a dictionary where each key maps to a list of sentences for that document.\n",
    "full_documents = [' '.join(sentences) for sentences in documents.values()]\n",
    "\n",
    "# Instantiate a CountVectorizer to transform the documents into a document-term frequency matrix,\n",
    "# while also removing common English stop words.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "document_term_matrix = vectorizer.fit_transform(full_documents)\n",
    "\n",
    "# Set the desired number of topics.\n",
    "num_topics = 10\n",
    "\n",
    "# Initialize the LDA model with the specified number of topics and a fixed random state for reproducibility.\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
    "\n",
    "# Fit the LDA model on the document-term matrix.\n",
    "lda_model.fit(document_term_matrix)\n",
    "\n",
    "# Retrieve the feature (word) names from the vectorizer.\n",
    "feature_names = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c5b3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the topic distribution for each document.\n",
    "# Each row of `document_topic_distribution` corresponds to a document,\n",
    "# and each column corresponds to the probability of that document belonging to a particular topic.\n",
    "document_topic_distribution = lda_model.transform(document_term_matrix)\n",
    "\n",
    "# Compute the normalized topic-word distributions.\n",
    "# 'lda_model.components_' contains the raw counts for each word under each topic.\n",
    "# To convert these counts into probabilities, we divide each topic's raw counts\n",
    "# by the total count of words for that topic.\n",
    "topic_word_distribution = lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e21734c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of AP880816-0234:\n",
      "he is suspected of being the\n",
      "shining path second-in-command and is in jail on terrorism charges. the\n",
      "government says more than 15,000 people have been killed and puts\n",
      "the property damage at $10 billion. it became known in july when it claimed responsibility for\n",
      "killing the lawyer for osman morote. the rodrigo franco group is named for an official of the\n",
      "government party killed the shining path killed last year. police said members of shining path, a maoist group, killed two\n",
      "policemen and wounded three in jungle raids.\n",
      "\n",
      "Summary of AP890714-0129:\n",
      "``for now, anyway, we are\n",
      "getting some relief.'' ``my experience is that we'd see green grass again if we get\n",
      "enough moisture, say a half-inch of rain,'' he said. the fire was contained monday and should\n",
      "be controlled within four days, ms. garcia said. the storms\n",
      "dampened a fire in bridger-teton national forest that had burned\n",
      "nearly 3,500 acres. seven 20-person crews fighting the fire were to be reduced to\n",
      "three crews, officials said.\n",
      "\n",
      "Summary of AP900424-0035:\n",
      "she's not well. ``it is serious, but they are really pleased with her progress. ``she is seriously ill,'' her doctors said in a statement. ``it may be that because she is such a prominent person, they\n",
      "are taking a conservative course,'' he added. the 58-year-old actress, who won best-actress oscars for\n",
      "``butterfield 8'' and ``who's afraid of virginia woolf,'' has been\n",
      "hospitalized more than two weeks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of document keys from the docs_sentences dictionary.\n",
    "document_keys = list(documents.keys())\n",
    "\n",
    "# Dictionary to store the generated LDA-based summaries.\n",
    "lda_summaries = {}\n",
    "\n",
    "# List of test document keys for which to generate summaries.\n",
    "test_document_keys = [\"AP880816-0234\", \"AP890714-0129\", \"AP900424-0035\"]\n",
    "\n",
    "# Loop over each document key, generate the summary, and display it.\n",
    "for doc_key in test_document_keys:\n",
    "    # Retrieve the index of the document by key.\n",
    "    doc_index = document_keys.index(doc_key)\n",
    "    \n",
    "    # Generate an LDA-based summary consisting of 5 sentences.\n",
    "    # The generate_lda_summary function is assumed to have the following signature:\n",
    "    # generate_lda_summary(doc_index, num_summary_sentences, document_topic_distribution, \n",
    "    #                      topic_word_distribution, vocabulary, document_sentences_collection)\n",
    "    summary = generate_lda_summary(doc_index, 5, \n",
    "                                   document_topic_distribution, \n",
    "                                   topic_word_distribution, \n",
    "                                   feature_names, \n",
    "                                   documents)\n",
    "    \n",
    "    # Store the summary in the dictionary with the document key.\n",
    "    lda_summaries[doc_key] = summary\n",
    "    \n",
    "    # Print the summary for the document.\n",
    "    print(f\"Summary of {doc_key}:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934073fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define the directory that contains the gold summary files.\n",
    "summaries_dir = r'DUC2001/Summaries'\n",
    "\n",
    "# Dictionary to store the extracted gold summaries.\n",
    "gold_summaries = {}\n",
    "\n",
    "def extract_abstract(content):\n",
    "    \"\"\"\n",
    "    Extract the abstract section from a document's content.\n",
    "\n",
    "    The function looks for text that starts after 'Abstract:' and ends before 'Introduction:'.\n",
    "    It then trims any extra whitespace and converts the text to lowercase.\n",
    "\n",
    "    Parameters:\n",
    "        content (str): The complete text content of a file.\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The extracted abstract in lowercase if found; otherwise, None.\n",
    "    \"\"\"\n",
    "    # Use a regular expression to capture text between \"Abstract:\" and \"Introduction:\"\n",
    "    match = re.search(r'Abstract:(.*?)Introduction:', content, re.DOTALL)\n",
    "    if match:\n",
    "        abstract_text = match.group(1).strip().lower()\n",
    "        return abstract_text\n",
    "    return None\n",
    "\n",
    "# Loop through all files in the summaries directory.\n",
    "for filename in os.listdir(summaries_dir):\n",
    "    file_path = os.path.join(summaries_dir, filename)\n",
    "    \n",
    "    # Ensure we process only files (skip subdirectories, if any)\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file's content with proper encoding.\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Extract the abstract section from the file content.\n",
    "        abstract_text = extract_abstract(content)\n",
    "        if abstract_text:\n",
    "            # Use the filename (without its extension) as the document identifier, converted to uppercase.\n",
    "            doc_id = os.path.splitext(filename)[0].upper()\n",
    "            gold_summaries[doc_id] = abstract_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "925b64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge_scores(system_summaries, gold_summaries):\n",
    "    \"\"\"\n",
    "    Calculate the ROUGE scores of system-generated summaries against gold (reference) summaries.\n",
    "\n",
    "    Parameters:\n",
    "        system_summaries (dict): A dictionary mapping document IDs to system-generated summaries.\n",
    "        gold_summaries (dict): A dictionary mapping document IDs to reference (gold) summaries.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains the document ID and a dictionary of ROUGE scores.\n",
    "              The score dictionary includes 'rouge1', 'rouge2', and 'rougeL' scores.\n",
    "    \"\"\"\n",
    "    # Initialize the ROUGE scorer with required metrics and enable stemming.\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = []\n",
    "\n",
    "    # Iterate through each system-generated summary.\n",
    "    for doc_id, system_summary in system_summaries.items():\n",
    "        if doc_id in gold_summaries:\n",
    "            # Retrieve the corresponding gold summary.\n",
    "            gold_summary = gold_summaries[doc_id]\n",
    "            # Calculate ROUGE scores comparing the gold summary to the system summary.\n",
    "            score = scorer.score(gold_summary, system_summary)\n",
    "            scores.append((doc_id, score))\n",
    "        else:\n",
    "            print(f\"Gold summary not found for document {doc_id}. Skipping evaluation.\")\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Calculate ROUGE scores for summaries generated by two different methods.\n",
    "rouge_scores_kla = calculate_rouge_scores(kl_summary_output, gold_summaries)\n",
    "rouge_scores_lda = calculate_rouge_scores(lda_summaries, gold_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f72e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for KLA summaries:\n",
      "Document ID  ROUGE-1 F1   ROUGE-2 F1   ROUGE-L F1   ROUGE-1 Precision ROUGE-2 Precision ROUGE-L Precision ROUGE-1 Recall ROUGE-2 Recall ROUGE-L Recall\n",
      "AP880816-0234 0.6017       0.2991       0.3729       0.5221            0.2593            0.3235            0.7100        0.3535        0.4400       \n",
      "AP890714-0129 0.5469       0.3128       0.3429       0.4589            0.2621            0.2877            0.6768        0.3878        0.4242       \n",
      "AP900424-0035 0.4255       0.1459       0.1532       0.3846            0.1318            0.1385            0.4762        0.1635        0.1714       \n",
      "ROUGE scores for LDA summaries:\n",
      "Document ID  ROUGE-1 F1   ROUGE-2 F1   ROUGE-L F1   ROUGE-1 Precision ROUGE-2 Precision ROUGE-L Precision ROUGE-1 Recall ROUGE-2 Recall ROUGE-L Recall\n",
      "AP880816-0234 0.5340       0.1905       0.2199       0.5604            0.2000            0.2308            0.5100        0.1818        0.2100       \n",
      "AP890714-0129 0.2584       0.0114       0.1461       0.2911            0.0128            0.1646            0.2323        0.0102        0.1313       \n",
      "AP900424-0035 0.3182       0.1609       0.1818       0.3944            0.2000            0.2254            0.2667        0.1346        0.1524       \n"
     ]
    }
   ],
   "source": [
    "def print_rouge_scores(scores, summary_type):\n",
    "    \"\"\"\n",
    "    Prints formatted ROUGE scores for a set of system-generated summaries compared to gold summaries.\n",
    "    \n",
    "    Parameters:\n",
    "        scores (list): A list of tuples. Each tuple contains a document ID and a dictionary \n",
    "                       of ROUGE score objects (with attributes fmeasure, precision, and recall).\n",
    "        summary_type (str): A label for the type of summaries (e.g., \"KLA\", \"LDA\") being evaluated.\n",
    "    \"\"\"\n",
    "    # Print header indicating the summary type.\n",
    "    print(f\"ROUGE scores for {summary_type} summaries:\")\n",
    "    \n",
    "    # Define the header row with fixed column widths.\n",
    "    header = (\"{:<12} {:<12} {:<12} {:<12} {:<17} {:<17} {:<17} \"\n",
    "              \"{:<13} {:<13} {:<13}\").format(\n",
    "        \"Document ID\", \"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\",\n",
    "        \"ROUGE-1 Precision\", \"ROUGE-2 Precision\", \"ROUGE-L Precision\",\n",
    "        \"ROUGE-1 Recall\", \"ROUGE-2 Recall\", \"ROUGE-L Recall\"\n",
    "    )\n",
    "    print(header)\n",
    "\n",
    "    # Iterate through each document's scores and print in a formatted row.\n",
    "    for doc_id, score in scores:\n",
    "        row = (\"{:<12} {:<12.4f} {:<12.4f} {:<12.4f} {:<17.4f} {:<17.4f} {:<17.4f} \"\n",
    "               \"{:<13.4f} {:<13.4f} {:<13.4f}\").format(\n",
    "            doc_id,\n",
    "            score['rouge1'].fmeasure,\n",
    "            score['rouge2'].fmeasure,\n",
    "            score['rougeL'].fmeasure,\n",
    "            score['rouge1'].precision,\n",
    "            score['rouge2'].precision,\n",
    "            score['rougeL'].precision,\n",
    "            score['rouge1'].recall,\n",
    "            score['rouge2'].recall,\n",
    "            score['rougeL'].recall\n",
    "        )\n",
    "        print(row)\n",
    "\n",
    "\n",
    "# Print the ROUGE scores for each method using the refactored print function.\n",
    "print_rouge_scores(rouge_scores_kla, \"KLA\")\n",
    "print_rouge_scores(rouge_scores_lda, \"LDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7afb205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 18846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the complete 20 newsgroups dataset while removing headers, footers, and quotes.\n",
    "# This ensures that only the main content of each newsgroup post is retained.\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Extract the list of document texts from the fetched data.\n",
    "documents = newsgroups.data\n",
    "\n",
    "# Print the total number of documents in the dataset.\n",
    "print(\"Number of documents:\", len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45a0404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed documents: 18846\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess_documents(documents):\n",
    "    \"\"\"\n",
    "    Preprocesses a list of documents by converting each document to lowercase and tokenizing it into sentences.\n",
    "    \n",
    "    Parameters:\n",
    "        documents (list of str): A list of raw document texts.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are document indices (integers) and the values are lists of tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the sentences for each document.\n",
    "    docs_sentences = {}\n",
    "    \n",
    "    # Iterate over the documents with an index.\n",
    "    for index, document in enumerate(documents):\n",
    "        # Convert the document to lowercase and tokenize into sentences.\n",
    "        sentences = sent_tokenize(document.lower())\n",
    "        # Store the list of sentences in the dictionary using the index as the key.\n",
    "        docs_sentences[index] = sentences\n",
    "    \n",
    "    return docs_sentences\n",
    "\n",
    "# Preprocess the 20 Newsgroups documents and store the result.\n",
    "docs_sentences_20ng = preprocess_documents(documents)\n",
    "\n",
    "# Print the total number of preprocessed documents.\n",
    "print(\"Number of preprocessed documents:\", len(docs_sentences_20ng))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37f44b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Document 0:\n",
      "bowman should let jagr have a lot of\n",
      "fun in the next couple of games since the pens are going to beat the pulp out of jersey anyway. however, i am going to put an end\n",
      "to non-pittsburghers' relief with a bit of praise for the pens. \n",
      "\n",
      "i am sure some bashers of pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent pens massacre of the devils. jagr just showed you why\n",
      "he is much better than his regular season stats. i was very disappointed not to see the islanders lose the final\n",
      "regular season game.\n",
      "\n",
      "Summary for Document 1:\n",
      "does anyone have suggestions/ideas on:\n",
      "\n",
      "  - diamond stealth pro local bus\n",
      "\n",
      "  - orchid farenheit 1280\n",
      "\n",
      "  - ati graphics ultra pro\n",
      "\n",
      "  - any other high-performance vlb card\n",
      "\n",
      "\n",
      "please post or email. my brother is in the market for a high-performance video card that supports\n",
      "vesa local bus with 1-2mb ram. thank you! - matt\n",
      "\n",
      "Summary for Document 2:\n",
      "shall the azeri women and children going to pay the price with\n",
      "\t\t\t\t\t\t    **************\n",
      "\tbeing raped, killed and tortured by the armenians?????????? what ever you say\n",
      "\"regional killer\", if you don't like the person then shoot him that's your policy.....l\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "\tconfused????? i\n",
      "        turkey's government has announced that it's giving weapons  <-----------i\n",
      "        to azerbadjan since armenia started to attack azerbadjan\t\t\n",
      "        it self, not the karabag province. that was new....\n",
      "\tthe area will be \"greater\" after some years, like your \"holocaust\" numbers......\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t*****\n",
      "\tis't july in usa now????? ohhh i forgot, this is how armenians fight, nobody has forgot\n",
      "\tyou killings, rapings and torture against the kurds and turks once\n",
      "\tupon a time!\n",
      "\n",
      "Summary for Document 3:\n",
      "it's the scsi card doing the dma transfers not the disks...\n",
      "\n",
      "the scsi card can do dma transfers containing data from any of the scsi devices\n",
      "it is attached when it wants to. on an ide bus when you start a transfer the bus is busy until the disk has seeked\n",
      "the data and transfered it. this is typically a 10-20ms second lock out for other\n",
      "processes wanting the bus irrespective of transfer time. while each device is seeking the data the\n",
      "bus is free for other commands and data transfers. this is typically used in a multi-tasking os to\n",
      "start transfers on several devices.\n",
      "\n",
      "Summary for Document 4:\n",
      "( i have seen formatters for <$20\n",
      "buit have no idea if they will work)\n",
      " \n",
      "2)     i have another ancient device, this one a tape drive for which\n",
      "the back utility freezes the system if i try to use it. my understanding is that i have to upsate the driver with a more modern\n",
      "one in order to gain compatability with system 7.0.1.  does anyone know\n",
      "of an inexpensive program to do this? the drive is a\n",
      "jasmine direct tape (bought used for $150 w/ 6 tapes, techmar\n",
      "mechanism). essentially i have the same question as above, anyone know\n",
      "of an inexpensive beckup utility i can use with system 7.0.1 1)    i have an old jasmine drive which i cannot use with my new system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the first five preprocessed documents (represented as lists of sentences).\n",
    "for doc_index in range(5):\n",
    "    # Retrieve the preprocessed sentences for the current document.\n",
    "    document_sentences = docs_sentences_20ng[doc_index]\n",
    "    \n",
    "    # Generate a summary containing 5 sentences using the kl_summary function.\n",
    "    # This function should select the most representative sentences using KL divergence.\n",
    "    summary = generate_kl_summary(document_sentences, 5)\n",
    "    \n",
    "    # Print the summary along with a header indicating the document index.\n",
    "    print(f\"Summary for Document {doc_index}:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8da877d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Document 0:\n",
      "! however, i am going to put an end\n",
      "to non-pittsburghers' relief with a bit of praise for the pens. jagr just showed you why\n",
      "he is much better than his regular season stats. man, they\n",
      "are killing those devils worse than i thought. he is also a lot\n",
      "fo fun to watch in the playoffs.\n",
      "\n",
      "Summary for Document 1:\n",
      "my brother is in the market for a high-performance video card that supports\n",
      "vesa local bus with 1-2mb ram. thank you! does anyone have suggestions/ideas on:\n",
      "\n",
      "  - diamond stealth pro local bus\n",
      "\n",
      "  - orchid farenheit 1280\n",
      "\n",
      "  - ati graphics ultra pro\n",
      "\n",
      "  - any other high-performance vlb card\n",
      "\n",
      "\n",
      "please post or email. - matt\n",
      "\n",
      "Summary for Document 2:\n",
      "****************\n",
      "\t\t\t\t\t\t    ******************\n",
      "\t\t\t    ***************\n",
      "\n",
      "\n",
      "\tnothing of the mentioned is true, but let say it's true. if there is one that's confused then that's you! you don't know what you are talking about. shoot down with what? mediterranean????\n",
      "\n",
      "Summary for Document 3:\n",
      "it's the scsi card doing the dma transfers not the disks...\n",
      "\n",
      "the scsi card can do dma transfers containing data from any of the scsi devices\n",
      "it is attached when it wants to. on an ide bus when you start a transfer the bus is busy until the disk has seeked\n",
      "the data and transfered it. this is typically used in a multi-tasking os to\n",
      "start transfers on several devices. when the devices are\n",
      "ready to transfer the data they can aquire the bus and send the data. while each device is seeking the data the\n",
      "bus is free for other commands and data transfers.\n",
      "\n",
      "Summary for Document 4:\n",
      "1)    i have an old jasmine drive which i cannot use with my new system. ( i have seen formatters for <$20\n",
      "buit have no idea if they will work)\n",
      " \n",
      "2)     i have another ancient device, this one a tape drive for which\n",
      "the back utility freezes the system if i try to use it. my understanding is that i have to upsate the driver with a more modern\n",
      "one in order to gain compatability with system 7.0.1.  does anyone know\n",
      "of an inexpensive program to do this? essentially i have the same question as above, anyone know\n",
      "of an inexpensive beckup utility i can use with system 7.0.1 the drive is a\n",
      "jasmine direct tape (bought used for $150 w/ 6 tapes, techmar\n",
      "mechanism).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Convert each document (list of sentences) into a single full-text string.\n",
    "# Here, docs_sentences_20ng is assumed to be a dictionary where keys are document indices \n",
    "# and values are lists of sentences.\n",
    "documents_full_text = [' '.join(sentences) for sentences in docs_sentences_20ng.values()]\n",
    "\n",
    "# Instantiate a CountVectorizer to convert documents into a document-term matrix, \n",
    "# automatically removing common English stop words.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "document_term_matrix = vectorizer.fit_transform(documents_full_text)\n",
    "\n",
    "# Initialize the LDA model with 10 topics and a fixed random state for reproducibility.\n",
    "num_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
    "lda_model.fit(document_term_matrix)\n",
    "\n",
    "# Obtain the topic distribution for each document.\n",
    "doc_topic_distributions_20ng = lda_model.transform(document_term_matrix)\n",
    "\n",
    "# Compute the normalized topic-word distribution matrix.\n",
    "# Each row corresponds to a topic and sums to 1.\n",
    "topic_word_distributions_20ng = lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Retrieve the vocabulary (feature names) from the vectorizer.\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Generate and print LDA-based summaries for the first 5 documents.\n",
    "for i in range(5):\n",
    "    # Generate a summary using 5 sentences from the i-th document.\n",
    "    # The generate_lda_summary function is assumed to select sentences based on LDA-derived word distributions.\n",
    "    summary = generate_lda_summary(i, 5,\n",
    "                                   doc_topic_distributions_20ng,\n",
    "                                   topic_word_distributions_20ng,\n",
    "                                   vocabulary,\n",
    "                                   docs_sentences_20ng)\n",
    "    \n",
    "    # Print a header with the document index and the summary.\n",
    "    print(f\"Summary for Document {i}:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c9c232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_topic_frequencies(topic_distribution: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize a topic distribution so that its elements sum to 1.\n",
    "    \n",
    "    If the total count is zero, returns an array of zeros with the same shape.\n",
    "    \n",
    "    Parameters:\n",
    "        topic_distribution (np.ndarray): An array representing unnormalized topic counts.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Normalized topic distribution (sums to 1).\n",
    "    \"\"\"\n",
    "    total_count = np.sum(topic_distribution)\n",
    "    if total_count == 0:\n",
    "        return np.zeros_like(topic_distribution)\n",
    "    return topic_distribution / total_count\n",
    "\n",
    "def kl_divergence_topics(summary_dist: np.ndarray, doc_dist: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Kullback-Leibler (KL) divergence between two topic distributions.\n",
    "    \n",
    "    Only terms where both distributions have positive values contribute to the divergence.\n",
    "    \n",
    "    Parameters:\n",
    "        summary_dist (np.ndarray): The topic distribution for the summary.\n",
    "        doc_dist (np.ndarray): The topic distribution for the document.\n",
    "    \n",
    "    Returns:\n",
    "        float: The computed KL divergence.\n",
    "    \"\"\"\n",
    "    divergence_value = 0.0\n",
    "    for i in range(len(summary_dist)):\n",
    "        if summary_dist[i] > 0 and doc_dist[i] > 0:\n",
    "            divergence_value += summary_dist[i] * np.log(summary_dist[i] / doc_dist[i])\n",
    "    return divergence_value\n",
    "\n",
    "def select_sentence_based_on_topic(doc_sentences: list,\n",
    "                                   doc_dist: np.ndarray,\n",
    "                                   summary_sentences: list,\n",
    "                                   doc_index: int,\n",
    "                                   doc_topic_distributions: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Select the sentence that, when added to the current summary, minimizes the KL divergence \n",
    "    between the summary's topic distribution and the document's topic distribution.\n",
    "    \n",
    "    Parameters:\n",
    "        doc_sentences (list): List of sentences in the document.\n",
    "        doc_dist (np.ndarray): Normalized topic distribution of the document.\n",
    "        summary_sentences (list): Currently selected summary sentences.\n",
    "        doc_index (int): Index of the document in doc_topic_distributions.\n",
    "        doc_topic_distributions (np.ndarray): Matrix of topic distributions for all documents.\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The sentence that minimizes divergence when added, or None if no sentence qualifies.\n",
    "    \"\"\"\n",
    "    min_divergence = float('inf')\n",
    "    selected_sentence = None\n",
    "\n",
    "    for sentence in doc_sentences:\n",
    "        if sentence in summary_sentences:\n",
    "            continue  # Skip sentences already in the summary\n",
    "        \n",
    "        # Create a temporary summary that includes the new sentence.\n",
    "        temp_summary = summary_sentences + [sentence]\n",
    "        \n",
    "        # Compute the average topic distribution for the temporary summary.\n",
    "        # Note: As implemented, this uses the same document topic distribution for every sentence.\n",
    "        # If per-sentence topic distributions are available, consider using them instead.\n",
    "        temp_summary_topics = np.mean([doc_topic_distributions[doc_index] for _ in temp_summary], axis=0)\n",
    "        \n",
    "        # Normalize the temporary summary topic distribution.\n",
    "        temp_summary_topics = compute_topic_frequencies(temp_summary_topics)\n",
    "        \n",
    "        # Compute the KL divergence between the temporary summary's topics and the document's topics.\n",
    "        divergence = kl_divergence_topics(temp_summary_topics, doc_dist)\n",
    "        \n",
    "        # Update the best (lowest divergence) sentence choice.\n",
    "        if divergence < min_divergence:\n",
    "            min_divergence = divergence\n",
    "            selected_sentence = sentence\n",
    "            \n",
    "    return selected_sentence\n",
    "\n",
    "def kl_summary_20NG(doc_index: int,\n",
    "                    num_sentences: int,\n",
    "                    doc_topic_distributions: np.ndarray,\n",
    "                    docs_sentences: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary for a document from the 20 Newsgroups dataset by selecting sentences \n",
    "    that minimize the divergence between the summary's and document's topic distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        doc_index (int): The index of the target document.\n",
    "        num_sentences (int): The desired number of sentences in the summary.\n",
    "        doc_topic_distributions (np.ndarray): Matrix of topic distributions for all documents.\n",
    "        docs_sentences (dict): Mapping from document indices to lists of preprocessed sentences.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated summary as a single concatenated string.\n",
    "    \"\"\"\n",
    "    # Retrieve and normalize the document's topic distribution.\n",
    "    doc_dist = compute_topic_frequencies(doc_topic_distributions[doc_index])\n",
    "    \n",
    "    summary_sentences = []\n",
    "    # Retrieve the sentences for the document using its index.\n",
    "    doc_sentences = list(docs_sentences.values())[doc_index]\n",
    "    \n",
    "    # Iteratively add sentences to the summary until the desired number is reached.\n",
    "    while len(summary_sentences) < num_sentences:\n",
    "        sentence = select_sentence_based_on_topic(doc_sentences, doc_dist, summary_sentences, \n",
    "                                                  doc_index, doc_topic_distributions)\n",
    "        if sentence:\n",
    "            summary_sentences.append(sentence)\n",
    "        else:\n",
    "            break  # Stop if no additional sentence can reduce the divergence\n",
    "    \n",
    "    return ' '.join(summary_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbcb98f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Document Index 8:\n",
      "\n",
      "Original Document Sentences:\n",
      " - \n",
      "\n",
      "\n",
      "yeah, it's the second one.\n",
      " - and i believe that price too.\n",
      " - i've been trying\n",
      "to get a good look at it on the bruin-sabre telecasts, and wow!\n",
      " - does it ever\n",
      "look good.\n",
      " - whoever did that paint job knew what they were doing.\n",
      " - and given\n",
      "fuhr's play since he got it, i bet the bruins are wishing he didn't have it:)\n",
      "\n",
      "Generated Summary:\n",
      "\n",
      "\n",
      "\n",
      "yeah, it's the second one. and i believe that price too. i've been trying\n",
      "to get a good look at it on the bruin-sabre telecasts, and wow! does it ever\n",
      "look good. whoever did that paint job knew what they were doing.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary for Document Index 3:\n",
      "\n",
      "Original Document Sentences:\n",
      " - \n",
      "think!\n",
      " - it's the scsi card doing the dma transfers not the disks...\n",
      "\n",
      "the scsi card can do dma transfers containing data from any of the scsi devices\n",
      "it is attached when it wants to.\n",
      " - an important feature of scsi is the ability to detach a device.\n",
      " - this frees the\n",
      "scsi bus for other devices.\n",
      " - this is typically used in a multi-tasking os to\n",
      "start transfers on several devices.\n",
      " - while each device is seeking the data the\n",
      "bus is free for other commands and data transfers.\n",
      " - when the devices are\n",
      "ready to transfer the data they can aquire the bus and send the data.\n",
      " - on an ide bus when you start a transfer the bus is busy until the disk has seeked\n",
      "the data and transfered it.\n",
      " - this is typically a 10-20ms second lock out for other\n",
      "processes wanting the bus irrespective of transfer time.\n",
      "\n",
      "Generated Summary:\n",
      "\n",
      "think! it's the scsi card doing the dma transfers not the disks...\n",
      "\n",
      "the scsi card can do dma transfers containing data from any of the scsi devices\n",
      "it is attached when it wants to. an important feature of scsi is the ability to detach a device. this frees the\n",
      "scsi bus for other devices. this is typically used in a multi-tasking os to\n",
      "start transfers on several devices.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary for Document Index 5:\n",
      "\n",
      "Original Document Sentences:\n",
      " - \n",
      "\n",
      "back in high school i worked as a lab assistant for a bunch of experimental\n",
      "psychologists at bell labs.\n",
      " - when they were doing visual perception and\n",
      "memory experiments, they used vector-type displays, with 1-millisecond\n",
      "refresh rates common.\n",
      " - so your case of 1/200th sec is quite practical, and the experimenters were\n",
      "probably sure that it was 5 milliseconds, not 4 or 6 either.\n",
      " - steve\n",
      "\n",
      "Generated Summary:\n",
      "\n",
      "\n",
      "back in high school i worked as a lab assistant for a bunch of experimental\n",
      "psychologists at bell labs. when they were doing visual perception and\n",
      "memory experiments, they used vector-type displays, with 1-millisecond\n",
      "refresh rates common. so your case of 1/200th sec is quite practical, and the experimenters were\n",
      "probably sure that it was 5 milliseconds, not 4 or 6 either. steve\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of document indices for which to generate summaries.\n",
    "selected_doc_indices = [8, 3, 5]\n",
    "\n",
    "# Iterate over each selected document index.\n",
    "for doc_index in selected_doc_indices:\n",
    "    # Generate a summary for the current document using 5 sentences.\n",
    "    # 'kl_summary_20NG' uses the document's topic distribution and the document's sentences\n",
    "    # to select the most representative sentences based on KL divergence.\n",
    "    summary = kl_summary_20NG(doc_index, 5, doc_topic_distributions_20ng, docs_sentences_20ng)\n",
    "    \n",
    "    # Print information about the current document.\n",
    "    print(f\"Summary for Document Index {doc_index}:\\n\")\n",
    "    \n",
    "    # Optionally, print the full list of preprocessed sentences for context.\n",
    "    print(\"Original Document Sentences:\")\n",
    "    for sentence in docs_sentences_20ng[doc_index]:\n",
    "        print(f\" - {sentence}\")\n",
    "    \n",
    "    # Print the generated summary.\n",
    "    print(\"\\nGenerated Summary:\")\n",
    "    print(summary)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
